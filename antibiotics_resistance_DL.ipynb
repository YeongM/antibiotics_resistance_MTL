{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04193b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\tensorflow-cuda\\lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, mean_squared_error, accuracy_score, mean_absolute_error, precision_score, recall_score, f1_score\n",
    "from pickle import dump\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "769cbd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital1 = 'Anam_hospital'\n",
    "hospital2 = 'Guro_hospital'\n",
    "hospital3 = 'Ansan_hospital'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933f71b",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af7e1f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_del(X, y):\n",
    "    na_index = np.where(np.isnan(y))[0]\n",
    "    del_na_X = np.delete(X, na_index,axis=0)\n",
    "    del_na_y = np.delete(y, na_index)\n",
    "    \n",
    "    return del_na_X, del_na_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f8f7d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performacne_model(Real_Test_y, y_pred, y_pred_prob):\n",
    "    accuracy= accuracy_score(Real_Test_y, y_pred)\n",
    "    precision = precision_score(Real_Test_y, y_pred)\n",
    "    recall = recall_score(Real_Test_y, y_pred)\n",
    "    f1 = f1_score(Real_Test_y, y_pred)\n",
    "    auc = roc_auc_score(Real_Test_y, y_pred_prob)\n",
    "    prc = average_precision_score(Real_Test_y, y_pred_prob)\n",
    "    confusion = confusion_matrix(Real_Test_y, y_pred)\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, auc, prc, confusion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb6cbd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Deep Learning code\n",
    "class MLP_Layer3():\n",
    "    def base_node1(self, x, node1, drop_out_rate1):\n",
    "        x = Dense(node1)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(drop_out_rate1)(x)\n",
    "        return x\n",
    "    \n",
    "    def base_node2(self, x, node2, drop_out_rate2):\n",
    "        x = Dense(node2)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(drop_out_rate2)(x)\n",
    "        return x\n",
    "\n",
    "    def build_branch(self, x, node1, drop_out_rate1, node2, drop_out_rate2, node3, drop_out_rate3):   \n",
    "        x= self.base_node1(x, node1, drop_out_rate1)\n",
    "        x= self.base_node2(x, node2, drop_out_rate2)\n",
    "        x = Dense(node3)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(drop_out_rate3)(x)\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation(\"sigmoid\", name=\"output\")(x)\n",
    "        return x\n",
    "    \n",
    "    def assemble_full_model(self, feature, node1=64, drop_out_rate1=0.1, node2=64, drop_out_rate2=0.1,node3=64, drop_out_rate3=0.1):\n",
    "        input_shape = (feature,)\n",
    "        inputs = Input(shape=input_shape)\n",
    "        branch = self.build_branch(inputs, node1, drop_out_rate1, node2, drop_out_rate2, node3, drop_out_rate3)\n",
    "        model = Model(inputs=inputs,\n",
    "                     outputs = branch,\n",
    "                     name=\"anti_net\")\n",
    "        return model\n",
    "    \n",
    "def model2_builder(node1=64, drop_out_rate1=0.1, node2=64, drop_out_rate2=0.1, node3=64, drop_out_rate3=0.1):\n",
    "    loss_dict ={'output': 'binary_crossentropy'}\n",
    "    metrics_dict = {'output': 'accuracy'}\n",
    "\n",
    "    model = MLP_Layer3().assemble_full_model(feature_size, node1, drop_out_rate1, node2, drop_out_rate2, node3, drop_out_rate3)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss_dict,\n",
    "                  metrics=metrics_dict)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "331e4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performacne_model(Real_Test_y, y_pred, y_pred_prob):\n",
    "    accuracy= accuracy_score(Real_Test_y, y_pred)\n",
    "    precision = precision_score(Real_Test_y, y_pred)\n",
    "    recall = recall_score(Real_Test_y, y_pred)\n",
    "    f1 = f1_score(Real_Test_y, y_pred)\n",
    "    auc = roc_auc_score(Real_Test_y, y_pred_prob)\n",
    "    prc = average_precision_score(Real_Test_y, y_pred_prob)\n",
    "    confusion = confusion_matrix(Real_Test_y, y_pred)\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, auc, prc, confusion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf77fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP2_tuning_predict(Train_X_sc_MI, Train_y, Real_Test_X_sc, Real_Test_y, External_Test_X1, External_Test_y1):\n",
    "    node1 = [64, 256]\n",
    "    node2 = [64, 256]\n",
    "    node3 = [64, 256]\n",
    "    drop_out_rate1 = [0.1,0.3]\n",
    "    drop_out_rate2 = [0.1,0.3]\n",
    "    drop_out_rate3 = [0.1,0.3]\n",
    "   \n",
    "    param_grid2 = {'node1': node1,'node2': node2,'node3': node3,'drop_out_rate1': drop_out_rate1,'drop_out_rate2': drop_out_rate2,'drop_out_rate3': drop_out_rate3}\n",
    "\n",
    "    model = KerasClassifier(build_fn=model2_builder, verbose=0)\n",
    "\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid2, cv=5)\n",
    "    gscv = grid.fit(Train_X_sc_MI, Train_y)\n",
    "\n",
    "    y_pred = gscv.predict(Real_Test_X_sc)\n",
    "    y_pred_prob = gscv.predict_proba(Real_Test_X_sc)[:, 1]\n",
    "    performance = performacne_model(Real_Test_y, y_pred, y_pred_prob)\n",
    "\n",
    "    external_y_pred1 = gscv.predict(External_Test_X1)\n",
    "    external_y_pred_prob1 = gscv.predict_proba(External_Test_X1)[:, 1]\n",
    "    external_performance1 = performacne_model(External_Test_y1, external_y_pred1, external_y_pred_prob1)\n",
    "    \n",
    "    return performance, external_performance1, gscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55b1aa02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906/906 [==============================] - 1s 942us/step\n",
      "906/906 [==============================] - 1s 921us/step\n",
      "1189/1189 [==============================] - 1s 991us/step\n",
      "1189/1189 [==============================] - 1s 932us/step\n",
      "293/293 [==============================] - 0s 1ms/step\n",
      "293/293 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 1s 934us/step\n",
      "666/666 [==============================] - 1s 1ms/step\n",
      "870/870 [==============================] - 1s 885us/step\n",
      "870/870 [==============================] - 1s 841us/step\n",
      "120/120 [==============================] - 0s 921us/step\n",
      "120/120 [==============================] - 0s 846us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908/908 [==============================] - 1s 837us/step\n",
      "908/908 [==============================] - 1s 890us/step\n",
      "1133/1133 [==============================] - 1s 923us/step\n",
      "1133/1133 [==============================] - 1s 961us/step\n",
      "209/209 [==============================] - 0s 891us/step\n",
      "209/209 [==============================] - 0s 973us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1387/1387 [==============================] - 1s 891us/step\n",
      "1387/1387 [==============================] - 1s 1ms/step\n",
      "1740/1740 [==============================] - 2s 948us/step\n",
      "1740/1740 [==============================] - 2s 1ms/step\n",
      "373/373 [==============================] - 0s 938us/step\n",
      "373/373 [==============================] - 0s 973us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976/976 [==============================] - 1s 895us/step\n",
      "976/976 [==============================] - 1s 1ms/step\n",
      "1331/1331 [==============================] - 1s 1ms/step\n",
      "1331/1331 [==============================] - 1s 972us/step\n",
      "263/263 [==============================] - 0s 919us/step\n",
      "263/263 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037/1037 [==============================] - 1s 1ms/step\n",
      "1037/1037 [==============================] - 1s 982us/step\n",
      "1354/1354 [==============================] - 1s 961us/step\n",
      "1354/1354 [==============================] - 1s 1ms/step\n",
      "282/282 [==============================] - 0s 942us/step\n",
      "282/282 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437/437 [==============================] - 0s 936us/step\n",
      "437/437 [==============================] - 0s 876us/step\n",
      "351/351 [==============================] - 0s 894us/step\n",
      "351/351 [==============================] - 0s 916us/step\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "72/72 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325/1325 [==============================] - 1s 898us/step\n",
      "1325/1325 [==============================] - 1s 984us/step\n",
      "1479/1479 [==============================] - 1s 962us/step\n",
      "1479/1479 [==============================] - 1s 966us/step\n",
      "360/360 [==============================] - 0s 943us/step\n",
      "360/360 [==============================] - 0s 943us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 1s 958us/step\n",
      "785/785 [==============================] - 1s 919us/step\n",
      "871/871 [==============================] - 1s 939us/step\n",
      "871/871 [==============================] - 1s 970us/step\n",
      "177/177 [==============================] - 0s 1ms/step\n",
      "177/177 [==============================] - 0s 1ms/step\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909/909 [==============================] - 1s 872us/step\n",
      "909/909 [==============================] - 1s 925us/step\n",
      "1189/1189 [==============================] - 1s 963us/step\n",
      "1189/1189 [==============================] - 1s 930us/step\n",
      "293/293 [==============================] - 0s 967us/step\n",
      "293/293 [==============================] - 0s 947us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662/662 [==============================] - 1s 951us/step\n",
      "662/662 [==============================] - 1s 957us/step\n",
      "870/870 [==============================] - 1s 978us/step\n",
      "870/870 [==============================] - 1s 989us/step\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "120/120 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910/910 [==============================] - 1s 935us/step\n",
      "910/910 [==============================] - 1s 934us/step\n",
      "1133/1133 [==============================] - 1s 990us/step\n",
      "1133/1133 [==============================] - 1s 974us/step\n",
      "209/209 [==============================] - 0s 992us/step\n",
      "209/209 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1381/1381 [==============================] - 1s 948us/step\n",
      "1381/1381 [==============================] - 1s 882us/step\n",
      "1740/1740 [==============================] - 2s 991us/step\n",
      "1740/1740 [==============================] - 2s 919us/step\n",
      "373/373 [==============================] - 0s 868us/step\n",
      "373/373 [==============================] - 0s 894us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974/974 [==============================] - 1s 926us/step\n",
      "974/974 [==============================] - 1s 946us/step\n",
      "1331/1331 [==============================] - 1s 1ms/step\n",
      "1331/1331 [==============================] - 1s 974us/step\n",
      "263/263 [==============================] - 0s 981us/step\n",
      "263/263 [==============================] - 0s 982us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034/1034 [==============================] - 1s 950us/step\n",
      "1034/1034 [==============================] - 1s 923us/step\n",
      "1354/1354 [==============================] - 1s 972us/step\n",
      "1354/1354 [==============================] - 1s 1ms/step\n",
      "282/282 [==============================] - 0s 1ms/step\n",
      "282/282 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423/423 [==============================] - 0s 891us/step\n",
      "423/423 [==============================] - 0s 892us/step\n",
      "351/351 [==============================] - 0s 977us/step\n",
      "351/351 [==============================] - 0s 1ms/step\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "72/72 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317/1317 [==============================] - 1s 863us/step\n",
      "1317/1317 [==============================] - 1s 861us/step\n",
      "1479/1479 [==============================] - 1s 945us/step\n",
      "1479/1479 [==============================] - 1s 889us/step\n",
      "360/360 [==============================] - 0s 919us/step\n",
      "360/360 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775/775 [==============================] - 1s 964us/step\n",
      "775/775 [==============================] - 1s 946us/step\n",
      "871/871 [==============================] - 1s 967us/step\n",
      "871/871 [==============================] - 1s 1ms/step\n",
      "177/177 [==============================] - 0s 1ms/step\n",
      "177/177 [==============================] - 0s 1ms/step\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 [==============================] - 1s 979us/step\n",
      "941/941 [==============================] - 1s 933us/step\n",
      "1189/1189 [==============================] - 1s 978us/step\n",
      "1189/1189 [==============================] - 1s 1ms/step\n",
      "293/293 [==============================] - 0s 981us/step\n",
      "293/293 [==============================] - 0s 998us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 1s 877us/step\n",
      "665/665 [==============================] - 1s 938us/step\n",
      "870/870 [==============================] - 1s 857us/step\n",
      "870/870 [==============================] - 1s 964us/step\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "120/120 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "939/939 [==============================] - 1s 1ms/step\n",
      "939/939 [==============================] - 1s 953us/step\n",
      "1133/1133 [==============================] - 1s 1ms/step\n",
      "1133/1133 [==============================] - 1s 1ms/step\n",
      "209/209 [==============================] - 0s 1ms/step\n",
      "209/209 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1410/1410 [==============================] - 1s 1ms/step\n",
      "1410/1410 [==============================] - 1s 1ms/step\n",
      "1740/1740 [==============================] - 2s 1ms/step\n",
      "1740/1740 [==============================] - 2s 1ms/step\n",
      "373/373 [==============================] - 0s 1ms/step\n",
      "373/373 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010/1010 [==============================] - 1s 941us/step\n",
      "1010/1010 [==============================] - 1s 1000us/step\n",
      "1331/1331 [==============================] - 1s 986us/step\n",
      "1331/1331 [==============================] - 1s 1ms/step\n",
      "263/263 [==============================] - 0s 1ms/step\n",
      "263/263 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1067/1067 [==============================] - 1s 1ms/step\n",
      "1067/1067 [==============================] - 1s 938us/step\n",
      "1354/1354 [==============================] - 1s 916us/step\n",
      "1354/1354 [==============================] - 1s 1ms/step\n",
      "282/282 [==============================] - 0s 1ms/step\n",
      "282/282 [==============================] - 0s 990us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436/436 [==============================] - 0s 981us/step\n",
      "436/436 [==============================] - 1s 1ms/step\n",
      "351/351 [==============================] - 0s 1ms/step\n",
      "351/351 [==============================] - 0s 1ms/step\n",
      "72/72 [==============================] - 0s 998us/step\n",
      "72/72 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1345/1345 [==============================] - 1s 978us/step\n",
      "1345/1345 [==============================] - 1s 1ms/step\n",
      "1479/1479 [==============================] - 2s 1ms/step\n",
      "1479/1479 [==============================] - 2s 1ms/step\n",
      "360/360 [==============================] - 0s 1ms/step\n",
      "360/360 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_50892\\247538212.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model2_builder, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780/780 [==============================] - 1s 872us/step\n",
      "780/780 [==============================] - 1s 1ms/step\n",
      "871/871 [==============================] - 1s 927us/step\n",
      "871/871 [==============================] - 1s 911us/step\n",
      "177/177 [==============================] - 0s 969us/step\n",
      "177/177 [==============================] - 0s 953us/step\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "external_count=0\n",
    "target_name = ['tgc','m','fgc','f','cp','c','a','ag','g']\n",
    "perform = ['accuracy','precision','recall','f1','auc','prc']\n",
    "target_list =['train_length','valid_length','test_length']\n",
    "for t in target_name:\n",
    "    for p in perform:\n",
    "        target_list.append(f'{t}_{p}')\n",
    "performance_result_df = pd.DataFrame(columns=target_list)\n",
    "performance_external_result_df1 = pd.DataFrame(columns=target_list)\n",
    "\n",
    "for seed in range(count, 30):\n",
    "    print(seed)\n",
    "    Train_X_MI = np.load('Preprocessed training data X in .npy format')\n",
    "    Train_y = np.load('Preprocessed training data y in .npy format')\n",
    "    Test_X_MI= np.load('Preprocessed internal test data X in .npy format')\n",
    "    Test_y = np.load('Preprocessed internal test data y in .npy format')\n",
    "    external_test_X1 = np.load('Preprocessed external test data X in .npy format')\n",
    "    external_test_y1 = np.load('Preprocessed external test data y in .npy format')\n",
    "    \n",
    "    tgc_train_y = Train_y[:,0]\n",
    "    m_train_y = Train_y[:,1]\n",
    "    fgc_train_y = Train_y[:,2]\n",
    "    f_train_y = Train_y[:,3]\n",
    "    cp_train_y = Train_y[:,4]\n",
    "    c_train_y = Train_y[:,5]\n",
    "    a_train_y = Train_y[:,6]\n",
    "    ag_train_y = Train_y[:,7]\n",
    "    g_train_y = Train_y[:,8]\n",
    "\n",
    "    tgc_test_y = Test_y[:,0]\n",
    "    m_test_y = Test_y[:,1]\n",
    "    fgc_test_y = Test_y[:,2]\n",
    "    f_test_y = Test_y[:,3]\n",
    "    cp_test_y = Test_y[:,4]\n",
    "    c_test_y = Test_y[:,5]\n",
    "    a_test_y = Test_y[:,6]\n",
    "    ag_test_y = Test_y[:,7]\n",
    "    g_test_y = Test_y[:,8]\n",
    "\n",
    "    external_tgc_test_y1 = external_test_y1[:,0]\n",
    "    external_m_test_y1 = external_test_y1[:,1]\n",
    "    external_fgc_test_y1 = external_test_y1[:,2]\n",
    "    external_f_test_y1 = external_test_y1[:,3]\n",
    "    external_cp_test_y1 = external_test_y1[:,4]\n",
    "    external_c_test_y1 = external_test_y1[:,5]\n",
    "    external_a_test_y1 = external_test_y1[:,6]\n",
    "    external_ag_test_y1 = external_test_y1[:,7]\n",
    "    external_g_test_y1 = external_test_y1[:,8]\n",
    "\n",
    "    train_y_list = [tgc_train_y,m_train_y,fgc_train_y,f_train_y,cp_train_y,c_train_y,a_train_y,ag_train_y,g_train_y]\n",
    "    test_y_list = [tgc_test_y,m_test_y,fgc_test_y,f_test_y,cp_test_y,c_test_y,a_test_y,ag_test_y,g_test_y]\n",
    "    external_test_y1_list = [external_tgc_test_y1,external_m_test_y1,external_fgc_test_y1,external_f_test_y1,external_cp_test_y1,external_c_test_y1,external_a_test_y1,external_ag_test_y1,external_g_test_y1]\n",
    "\n",
    "    Train_index, Val_index = train_test_split(range(len(Train_X_MI)), test_size=0.3, random_state=seed)\n",
    "    X_val = Train_X_MI[Val_index]\n",
    "    Y_val_tgc = train_y_list[0][Val_index]\n",
    "    Y_val_m = train_y_list[1][Val_index]\n",
    "    Y_val_fgc = train_y_list[2][Val_index]\n",
    "    Y_val_f = train_y_list[3][Val_index]\n",
    "    Y_val_cp = train_y_list[4][Val_index]\n",
    "    Y_val_c = train_y_list[5][Val_index]\n",
    "    Y_val_a = train_y_list[6][Val_index]\n",
    "    Y_val_ag = train_y_list[7][Val_index]\n",
    "    Y_val_g = train_y_list[8][Val_index]\n",
    "\n",
    "\n",
    "    X_train = Train_X_MI[Train_index]\n",
    "    Y_train_tgc = train_y_list[0][Train_index]\n",
    "    Y_train_m = train_y_list[1][Train_index]\n",
    "    Y_train_fgc = train_y_list[2][Train_index]\n",
    "    Y_train_f = train_y_list[3][Train_index]\n",
    "    Y_train_cp = train_y_list[4][Train_index]\n",
    "    Y_train_c = train_y_list[5][Train_index]\n",
    "    Y_train_a = train_y_list[6][Train_index]\n",
    "    Y_train_ag = train_y_list[7][Train_index]\n",
    "    Y_train_g = train_y_list[8][Train_index]\n",
    "\n",
    "    X_test = Test_X_MI\n",
    "    Y_test_tgc = test_y_list[0]\n",
    "    Y_test_m = test_y_list[1]\n",
    "    Y_test_fgc = test_y_list[2]\n",
    "    Y_test_f = test_y_list[3]\n",
    "    Y_test_cp = test_y_list[4]\n",
    "    Y_test_c = test_y_list[5]\n",
    "    Y_test_a = test_y_list[6]\n",
    "    Y_test_ag = test_y_list[7]\n",
    "    Y_test_g = test_y_list[8]\n",
    "\n",
    "    Y_test_tgc = test_y_list[0]\n",
    "    Y_test_m = test_y_list[1]\n",
    "    Y_test_fgc = test_y_list[2]\n",
    "    Y_test_f = test_y_list[3]\n",
    "    Y_test_cp = test_y_list[4]\n",
    "    Y_test_c = test_y_list[5]\n",
    "    Y_test_a = test_y_list[6]\n",
    "    Y_test_ag = test_y_list[7]\n",
    "    Y_test_g = test_y_list[8]\n",
    "\n",
    "    external_Y_test1_tgc = external_test_y1_list[0]\n",
    "    external_Y_test1_m = external_test_y1_list[1]\n",
    "    external_Y_test1_fgc = external_test_y1_list[2]\n",
    "    external_Y_test1_f = external_test_y1_list[3]\n",
    "    external_Y_test1_cp = external_test_y1_list[4]\n",
    "    external_Y_test1_c = external_test_y1_list[5]\n",
    "    external_Y_test1_a = external_test_y1_list[6]\n",
    "    external_Y_test1_ag = external_test_y1_list[7]\n",
    "    external_Y_test1_g = external_test_y1_list[8]\n",
    "\n",
    "    feature_size = X_train.shape[1]\n",
    "\n",
    "    Y_train =[Y_train_tgc,Y_train_m,Y_train_fgc,Y_train_f,Y_train_cp,Y_train_c,Y_train_a,Y_train_ag,Y_train_g]\n",
    "    Y_val =[Y_val_tgc,Y_val_m,Y_val_fgc,Y_val_f,Y_val_cp,Y_val_c,Y_val_a,Y_val_ag,Y_val_g]\n",
    "    Y_test =[Y_test_tgc,Y_test_m,Y_test_fgc,Y_test_f,Y_test_cp,Y_test_c,Y_test_a,Y_test_ag,Y_test_g]\n",
    "    external_Y_test1 =[external_Y_test1_tgc,external_Y_test1_m,external_Y_test1_fgc,external_Y_test1_f,external_Y_test1_cp,external_Y_test1_c,external_Y_test1_a,external_Y_test1_ag,external_Y_test1_g]\n",
    "\n",
    "    performance_result_df.loc[count,'train_length'] = len(X_train)\n",
    "    performance_result_df.loc[count,'valid_length'] = len(X_val)\n",
    "    performance_result_df.loc[count,'test_length'] = len(X_test)\n",
    "\n",
    "    tmp_train_X = []\n",
    "    tmp_val_X = []\n",
    "    tmp_test_X = []\n",
    "    tmp_external_X1 = []\n",
    "    tmp_train_y = []\n",
    "    tmp_val_y = []\n",
    "    tmp_test_y = []\n",
    "    tmp_external_y1 = []\n",
    "\n",
    "    for i,(train, val, test, external_test1) in enumerate(zip(Y_train, Y_val, Y_test, external_Y_test1)):\n",
    "        tmp_X, tmp_y = nan_del(X_train, train)\n",
    "        tmp_train_X.append(tmp_X)\n",
    "        tmp_train_y.append(tmp_y)\n",
    "\n",
    "        tmp_X, tmp_y = nan_del(X_val, val)\n",
    "        tmp_val_X.append(tmp_X)\n",
    "        tmp_val_y.append(tmp_y)\n",
    "\n",
    "        tmp_X, tmp_y = nan_del(X_test, test)\n",
    "        tmp_test_X.append(tmp_X)\n",
    "        tmp_test_y.append(tmp_y)\n",
    "\n",
    "        tmp_X, tmp_y = nan_del(external_test_X1, external_test1)\n",
    "        tmp_external_X1.append(tmp_X)\n",
    "        tmp_external_y1.append(tmp_y)\n",
    "        \n",
    "\n",
    "    for i in range(len(target_name)):\n",
    "        tmp_val_train_X = np.concatenate([tmp_train_X[i], tmp_val_X[i]],axis=0)\n",
    "        tmp_val_train_y = np.concatenate([tmp_train_y[i], tmp_val_y[i]])\n",
    "        \n",
    "        # Layer 3\n",
    "        internal_performance, external_performance1, model_info = MLP2_tuning_predict(tmp_val_train_X, tmp_val_train_y, tmp_test_X[i], tmp_test_y[i], tmp_external_X1[i], tmp_external_y1[i])\n",
    "        filename = 'Model save path in .h5 format'\n",
    "        model_info.best_estimator_.model.save(filename)\n",
    "        for j, performance_name in enumerate(perform):\n",
    "            target_feature = target_name[i]+'_'+performance_name\n",
    "            performance_result_df.loc[count, target_feature] = internal_performance[j]\n",
    "            performance_external_result_df1.loc[count, target_feature] = external_performance1[j]\n",
    "        del model_info\n",
    "        \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "040357c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_length</th>\n",
       "      <th>valid_length</th>\n",
       "      <th>test_length</th>\n",
       "      <th>tgc_accuracy</th>\n",
       "      <th>tgc_precision</th>\n",
       "      <th>tgc_recall</th>\n",
       "      <th>tgc_f1</th>\n",
       "      <th>tgc_auc</th>\n",
       "      <th>tgc_prc</th>\n",
       "      <th>m_accuracy</th>\n",
       "      <th>m_precision</th>\n",
       "      <th>m_recall</th>\n",
       "      <th>m_f1</th>\n",
       "      <th>m_auc</th>\n",
       "      <th>m_prc</th>\n",
       "      <th>fgc_accuracy</th>\n",
       "      <th>fgc_precision</th>\n",
       "      <th>fgc_recall</th>\n",
       "      <th>fgc_f1</th>\n",
       "      <th>fgc_auc</th>\n",
       "      <th>fgc_prc</th>\n",
       "      <th>f_accuracy</th>\n",
       "      <th>f_precision</th>\n",
       "      <th>f_recall</th>\n",
       "      <th>f_f1</th>\n",
       "      <th>f_auc</th>\n",
       "      <th>f_prc</th>\n",
       "      <th>cp_accuracy</th>\n",
       "      <th>cp_precision</th>\n",
       "      <th>cp_recall</th>\n",
       "      <th>cp_f1</th>\n",
       "      <th>cp_auc</th>\n",
       "      <th>cp_prc</th>\n",
       "      <th>c_accuracy</th>\n",
       "      <th>c_precision</th>\n",
       "      <th>c_recall</th>\n",
       "      <th>c_f1</th>\n",
       "      <th>c_auc</th>\n",
       "      <th>c_prc</th>\n",
       "      <th>a_accuracy</th>\n",
       "      <th>a_precision</th>\n",
       "      <th>a_recall</th>\n",
       "      <th>a_f1</th>\n",
       "      <th>a_auc</th>\n",
       "      <th>a_prc</th>\n",
       "      <th>ag_accuracy</th>\n",
       "      <th>ag_precision</th>\n",
       "      <th>ag_recall</th>\n",
       "      <th>ag_f1</th>\n",
       "      <th>ag_auc</th>\n",
       "      <th>ag_prc</th>\n",
       "      <th>g_accuracy</th>\n",
       "      <th>g_precision</th>\n",
       "      <th>g_recall</th>\n",
       "      <th>g_f1</th>\n",
       "      <th>g_auc</th>\n",
       "      <th>g_prc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74769.0</td>\n",
       "      <td>32044.0</td>\n",
       "      <td>45734.0</td>\n",
       "      <td>0.725230</td>\n",
       "      <td>0.765263</td>\n",
       "      <td>0.837800</td>\n",
       "      <td>0.799890</td>\n",
       "      <td>0.787206</td>\n",
       "      <td>0.871580</td>\n",
       "      <td>0.735114</td>\n",
       "      <td>0.741921</td>\n",
       "      <td>0.969663</td>\n",
       "      <td>0.840640</td>\n",
       "      <td>0.759956</td>\n",
       "      <td>0.884111</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>0.738109</td>\n",
       "      <td>0.651374</td>\n",
       "      <td>0.692035</td>\n",
       "      <td>0.785744</td>\n",
       "      <td>0.754571</td>\n",
       "      <td>0.704631</td>\n",
       "      <td>0.732449</td>\n",
       "      <td>0.830941</td>\n",
       "      <td>0.778593</td>\n",
       "      <td>0.762033</td>\n",
       "      <td>0.828507</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.791395</td>\n",
       "      <td>0.749039</td>\n",
       "      <td>0.769635</td>\n",
       "      <td>0.791235</td>\n",
       "      <td>0.851700</td>\n",
       "      <td>0.753475</td>\n",
       "      <td>0.736937</td>\n",
       "      <td>0.641677</td>\n",
       "      <td>0.686016</td>\n",
       "      <td>0.803421</td>\n",
       "      <td>0.744071</td>\n",
       "      <td>0.757683</td>\n",
       "      <td>0.694795</td>\n",
       "      <td>0.338087</td>\n",
       "      <td>0.454846</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.526606</td>\n",
       "      <td>0.679072</td>\n",
       "      <td>0.728596</td>\n",
       "      <td>0.484586</td>\n",
       "      <td>0.582052</td>\n",
       "      <td>0.706944</td>\n",
       "      <td>0.676271</td>\n",
       "      <td>0.864314</td>\n",
       "      <td>0.630664</td>\n",
       "      <td>0.348420</td>\n",
       "      <td>0.448860</td>\n",
       "      <td>0.764959</td>\n",
       "      <td>0.449019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74602.0</td>\n",
       "      <td>31973.0</td>\n",
       "      <td>45972.0</td>\n",
       "      <td>0.727444</td>\n",
       "      <td>0.780433</td>\n",
       "      <td>0.815493</td>\n",
       "      <td>0.797578</td>\n",
       "      <td>0.790523</td>\n",
       "      <td>0.877775</td>\n",
       "      <td>0.733549</td>\n",
       "      <td>0.752680</td>\n",
       "      <td>0.941815</td>\n",
       "      <td>0.836692</td>\n",
       "      <td>0.763202</td>\n",
       "      <td>0.893957</td>\n",
       "      <td>0.736775</td>\n",
       "      <td>0.745318</td>\n",
       "      <td>0.645437</td>\n",
       "      <td>0.691791</td>\n",
       "      <td>0.784149</td>\n",
       "      <td>0.758504</td>\n",
       "      <td>0.715456</td>\n",
       "      <td>0.761656</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.778189</td>\n",
       "      <td>0.773543</td>\n",
       "      <td>0.846373</td>\n",
       "      <td>0.727012</td>\n",
       "      <td>0.784068</td>\n",
       "      <td>0.756943</td>\n",
       "      <td>0.770267</td>\n",
       "      <td>0.788682</td>\n",
       "      <td>0.848994</td>\n",
       "      <td>0.754852</td>\n",
       "      <td>0.760970</td>\n",
       "      <td>0.612958</td>\n",
       "      <td>0.678991</td>\n",
       "      <td>0.803138</td>\n",
       "      <td>0.752631</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>0.680672</td>\n",
       "      <td>0.318741</td>\n",
       "      <td>0.434171</td>\n",
       "      <td>0.683314</td>\n",
       "      <td>0.511012</td>\n",
       "      <td>0.678509</td>\n",
       "      <td>0.698350</td>\n",
       "      <td>0.538551</td>\n",
       "      <td>0.608128</td>\n",
       "      <td>0.707125</td>\n",
       "      <td>0.670287</td>\n",
       "      <td>0.861431</td>\n",
       "      <td>0.686105</td>\n",
       "      <td>0.242001</td>\n",
       "      <td>0.357800</td>\n",
       "      <td>0.773070</td>\n",
       "      <td>0.464832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74182.0</td>\n",
       "      <td>31793.0</td>\n",
       "      <td>46572.0</td>\n",
       "      <td>0.735526</td>\n",
       "      <td>0.792204</td>\n",
       "      <td>0.821153</td>\n",
       "      <td>0.806419</td>\n",
       "      <td>0.793667</td>\n",
       "      <td>0.884395</td>\n",
       "      <td>0.736284</td>\n",
       "      <td>0.745905</td>\n",
       "      <td>0.963600</td>\n",
       "      <td>0.840891</td>\n",
       "      <td>0.762210</td>\n",
       "      <td>0.889334</td>\n",
       "      <td>0.733491</td>\n",
       "      <td>0.749466</td>\n",
       "      <td>0.648023</td>\n",
       "      <td>0.695063</td>\n",
       "      <td>0.786833</td>\n",
       "      <td>0.763719</td>\n",
       "      <td>0.718724</td>\n",
       "      <td>0.758949</td>\n",
       "      <td>0.815652</td>\n",
       "      <td>0.786280</td>\n",
       "      <td>0.772986</td>\n",
       "      <td>0.849616</td>\n",
       "      <td>0.733344</td>\n",
       "      <td>0.790064</td>\n",
       "      <td>0.774229</td>\n",
       "      <td>0.782066</td>\n",
       "      <td>0.795943</td>\n",
       "      <td>0.856260</td>\n",
       "      <td>0.750080</td>\n",
       "      <td>0.761897</td>\n",
       "      <td>0.618267</td>\n",
       "      <td>0.682609</td>\n",
       "      <td>0.802266</td>\n",
       "      <td>0.757981</td>\n",
       "      <td>0.757534</td>\n",
       "      <td>0.667937</td>\n",
       "      <td>0.343291</td>\n",
       "      <td>0.453502</td>\n",
       "      <td>0.694978</td>\n",
       "      <td>0.512855</td>\n",
       "      <td>0.678014</td>\n",
       "      <td>0.702219</td>\n",
       "      <td>0.530027</td>\n",
       "      <td>0.604092</td>\n",
       "      <td>0.701508</td>\n",
       "      <td>0.671614</td>\n",
       "      <td>0.866268</td>\n",
       "      <td>0.641493</td>\n",
       "      <td>0.375652</td>\n",
       "      <td>0.473833</td>\n",
       "      <td>0.768326</td>\n",
       "      <td>0.449910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74783.0</td>\n",
       "      <td>32051.0</td>\n",
       "      <td>45713.0</td>\n",
       "      <td>0.736316</td>\n",
       "      <td>0.779788</td>\n",
       "      <td>0.839793</td>\n",
       "      <td>0.808679</td>\n",
       "      <td>0.793986</td>\n",
       "      <td>0.878222</td>\n",
       "      <td>0.729117</td>\n",
       "      <td>0.761949</td>\n",
       "      <td>0.908655</td>\n",
       "      <td>0.828861</td>\n",
       "      <td>0.754729</td>\n",
       "      <td>0.886837</td>\n",
       "      <td>0.730453</td>\n",
       "      <td>0.748242</td>\n",
       "      <td>0.614796</td>\n",
       "      <td>0.674987</td>\n",
       "      <td>0.778835</td>\n",
       "      <td>0.743494</td>\n",
       "      <td>0.713253</td>\n",
       "      <td>0.753678</td>\n",
       "      <td>0.806801</td>\n",
       "      <td>0.779335</td>\n",
       "      <td>0.767529</td>\n",
       "      <td>0.838672</td>\n",
       "      <td>0.729871</td>\n",
       "      <td>0.793132</td>\n",
       "      <td>0.751878</td>\n",
       "      <td>0.771954</td>\n",
       "      <td>0.792918</td>\n",
       "      <td>0.852970</td>\n",
       "      <td>0.752537</td>\n",
       "      <td>0.759684</td>\n",
       "      <td>0.594628</td>\n",
       "      <td>0.667098</td>\n",
       "      <td>0.799938</td>\n",
       "      <td>0.743516</td>\n",
       "      <td>0.761964</td>\n",
       "      <td>0.680719</td>\n",
       "      <td>0.260858</td>\n",
       "      <td>0.377178</td>\n",
       "      <td>0.684034</td>\n",
       "      <td>0.497936</td>\n",
       "      <td>0.680007</td>\n",
       "      <td>0.714359</td>\n",
       "      <td>0.503399</td>\n",
       "      <td>0.590606</td>\n",
       "      <td>0.705549</td>\n",
       "      <td>0.668804</td>\n",
       "      <td>0.869723</td>\n",
       "      <td>0.716931</td>\n",
       "      <td>0.279094</td>\n",
       "      <td>0.401779</td>\n",
       "      <td>0.772691</td>\n",
       "      <td>0.486454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74405.0</td>\n",
       "      <td>31888.0</td>\n",
       "      <td>46254.0</td>\n",
       "      <td>0.730724</td>\n",
       "      <td>0.777509</td>\n",
       "      <td>0.833783</td>\n",
       "      <td>0.804663</td>\n",
       "      <td>0.789688</td>\n",
       "      <td>0.879033</td>\n",
       "      <td>0.734134</td>\n",
       "      <td>0.758179</td>\n",
       "      <td>0.930660</td>\n",
       "      <td>0.835612</td>\n",
       "      <td>0.757053</td>\n",
       "      <td>0.889833</td>\n",
       "      <td>0.731968</td>\n",
       "      <td>0.762143</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>0.678077</td>\n",
       "      <td>0.780341</td>\n",
       "      <td>0.756185</td>\n",
       "      <td>0.716564</td>\n",
       "      <td>0.763850</td>\n",
       "      <td>0.798952</td>\n",
       "      <td>0.781007</td>\n",
       "      <td>0.770743</td>\n",
       "      <td>0.842904</td>\n",
       "      <td>0.727028</td>\n",
       "      <td>0.784729</td>\n",
       "      <td>0.764444</td>\n",
       "      <td>0.774454</td>\n",
       "      <td>0.790862</td>\n",
       "      <td>0.855731</td>\n",
       "      <td>0.753478</td>\n",
       "      <td>0.759963</td>\n",
       "      <td>0.619776</td>\n",
       "      <td>0.682747</td>\n",
       "      <td>0.807151</td>\n",
       "      <td>0.762912</td>\n",
       "      <td>0.755352</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.305549</td>\n",
       "      <td>0.422732</td>\n",
       "      <td>0.696623</td>\n",
       "      <td>0.523517</td>\n",
       "      <td>0.680694</td>\n",
       "      <td>0.715769</td>\n",
       "      <td>0.523094</td>\n",
       "      <td>0.604449</td>\n",
       "      <td>0.708726</td>\n",
       "      <td>0.680491</td>\n",
       "      <td>0.859246</td>\n",
       "      <td>0.665750</td>\n",
       "      <td>0.290408</td>\n",
       "      <td>0.404408</td>\n",
       "      <td>0.768229</td>\n",
       "      <td>0.461252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74812.0</td>\n",
       "      <td>32063.0</td>\n",
       "      <td>45672.0</td>\n",
       "      <td>0.734475</td>\n",
       "      <td>0.790363</td>\n",
       "      <td>0.818075</td>\n",
       "      <td>0.803980</td>\n",
       "      <td>0.794105</td>\n",
       "      <td>0.881808</td>\n",
       "      <td>0.736081</td>\n",
       "      <td>0.763798</td>\n",
       "      <td>0.917492</td>\n",
       "      <td>0.833620</td>\n",
       "      <td>0.760797</td>\n",
       "      <td>0.880527</td>\n",
       "      <td>0.737281</td>\n",
       "      <td>0.771355</td>\n",
       "      <td>0.617980</td>\n",
       "      <td>0.686202</td>\n",
       "      <td>0.786316</td>\n",
       "      <td>0.754975</td>\n",
       "      <td>0.711377</td>\n",
       "      <td>0.782607</td>\n",
       "      <td>0.751321</td>\n",
       "      <td>0.766645</td>\n",
       "      <td>0.771600</td>\n",
       "      <td>0.844732</td>\n",
       "      <td>0.730842</td>\n",
       "      <td>0.800727</td>\n",
       "      <td>0.743499</td>\n",
       "      <td>0.771053</td>\n",
       "      <td>0.794125</td>\n",
       "      <td>0.853367</td>\n",
       "      <td>0.751550</td>\n",
       "      <td>0.755165</td>\n",
       "      <td>0.607716</td>\n",
       "      <td>0.673465</td>\n",
       "      <td>0.802715</td>\n",
       "      <td>0.748137</td>\n",
       "      <td>0.750166</td>\n",
       "      <td>0.663352</td>\n",
       "      <td>0.242346</td>\n",
       "      <td>0.354998</td>\n",
       "      <td>0.682911</td>\n",
       "      <td>0.494781</td>\n",
       "      <td>0.682485</td>\n",
       "      <td>0.715461</td>\n",
       "      <td>0.525923</td>\n",
       "      <td>0.606222</td>\n",
       "      <td>0.707620</td>\n",
       "      <td>0.675374</td>\n",
       "      <td>0.863789</td>\n",
       "      <td>0.658698</td>\n",
       "      <td>0.324480</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.765953</td>\n",
       "      <td>0.466862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>74771.0</td>\n",
       "      <td>32046.0</td>\n",
       "      <td>45730.0</td>\n",
       "      <td>0.728177</td>\n",
       "      <td>0.784866</td>\n",
       "      <td>0.811771</td>\n",
       "      <td>0.798092</td>\n",
       "      <td>0.791264</td>\n",
       "      <td>0.879917</td>\n",
       "      <td>0.733608</td>\n",
       "      <td>0.752681</td>\n",
       "      <td>0.935846</td>\n",
       "      <td>0.834329</td>\n",
       "      <td>0.759987</td>\n",
       "      <td>0.884667</td>\n",
       "      <td>0.736918</td>\n",
       "      <td>0.763825</td>\n",
       "      <td>0.627125</td>\n",
       "      <td>0.688758</td>\n",
       "      <td>0.786646</td>\n",
       "      <td>0.757760</td>\n",
       "      <td>0.686135</td>\n",
       "      <td>0.726675</td>\n",
       "      <td>0.799058</td>\n",
       "      <td>0.761150</td>\n",
       "      <td>0.754433</td>\n",
       "      <td>0.831951</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>0.806740</td>\n",
       "      <td>0.731746</td>\n",
       "      <td>0.767415</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.854797</td>\n",
       "      <td>0.753113</td>\n",
       "      <td>0.765637</td>\n",
       "      <td>0.609966</td>\n",
       "      <td>0.678994</td>\n",
       "      <td>0.804189</td>\n",
       "      <td>0.758777</td>\n",
       "      <td>0.750782</td>\n",
       "      <td>0.683450</td>\n",
       "      <td>0.329251</td>\n",
       "      <td>0.444408</td>\n",
       "      <td>0.679258</td>\n",
       "      <td>0.520388</td>\n",
       "      <td>0.681899</td>\n",
       "      <td>0.723718</td>\n",
       "      <td>0.514065</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.714216</td>\n",
       "      <td>0.684796</td>\n",
       "      <td>0.867196</td>\n",
       "      <td>0.647429</td>\n",
       "      <td>0.297453</td>\n",
       "      <td>0.407627</td>\n",
       "      <td>0.770839</td>\n",
       "      <td>0.446102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74686.0</td>\n",
       "      <td>32009.0</td>\n",
       "      <td>45852.0</td>\n",
       "      <td>0.741732</td>\n",
       "      <td>0.816270</td>\n",
       "      <td>0.792151</td>\n",
       "      <td>0.804030</td>\n",
       "      <td>0.799379</td>\n",
       "      <td>0.887484</td>\n",
       "      <td>0.738726</td>\n",
       "      <td>0.756384</td>\n",
       "      <td>0.945197</td>\n",
       "      <td>0.840315</td>\n",
       "      <td>0.759081</td>\n",
       "      <td>0.892065</td>\n",
       "      <td>0.732650</td>\n",
       "      <td>0.743245</td>\n",
       "      <td>0.666046</td>\n",
       "      <td>0.702531</td>\n",
       "      <td>0.790763</td>\n",
       "      <td>0.767154</td>\n",
       "      <td>0.719996</td>\n",
       "      <td>0.767995</td>\n",
       "      <td>0.801843</td>\n",
       "      <td>0.784554</td>\n",
       "      <td>0.775044</td>\n",
       "      <td>0.846737</td>\n",
       "      <td>0.728367</td>\n",
       "      <td>0.801166</td>\n",
       "      <td>0.745827</td>\n",
       "      <td>0.772507</td>\n",
       "      <td>0.793012</td>\n",
       "      <td>0.855776</td>\n",
       "      <td>0.746436</td>\n",
       "      <td>0.755539</td>\n",
       "      <td>0.621616</td>\n",
       "      <td>0.682066</td>\n",
       "      <td>0.801405</td>\n",
       "      <td>0.758948</td>\n",
       "      <td>0.743172</td>\n",
       "      <td>0.663403</td>\n",
       "      <td>0.325034</td>\n",
       "      <td>0.436302</td>\n",
       "      <td>0.688114</td>\n",
       "      <td>0.513202</td>\n",
       "      <td>0.678623</td>\n",
       "      <td>0.694962</td>\n",
       "      <td>0.553876</td>\n",
       "      <td>0.616450</td>\n",
       "      <td>0.713455</td>\n",
       "      <td>0.678997</td>\n",
       "      <td>0.861917</td>\n",
       "      <td>0.673725</td>\n",
       "      <td>0.335249</td>\n",
       "      <td>0.447713</td>\n",
       "      <td>0.771857</td>\n",
       "      <td>0.475611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>74628.0</td>\n",
       "      <td>31984.0</td>\n",
       "      <td>45935.0</td>\n",
       "      <td>0.727004</td>\n",
       "      <td>0.797992</td>\n",
       "      <td>0.788957</td>\n",
       "      <td>0.793449</td>\n",
       "      <td>0.786798</td>\n",
       "      <td>0.875618</td>\n",
       "      <td>0.737646</td>\n",
       "      <td>0.763538</td>\n",
       "      <td>0.924457</td>\n",
       "      <td>0.836327</td>\n",
       "      <td>0.765133</td>\n",
       "      <td>0.890853</td>\n",
       "      <td>0.734747</td>\n",
       "      <td>0.758407</td>\n",
       "      <td>0.626439</td>\n",
       "      <td>0.686135</td>\n",
       "      <td>0.789491</td>\n",
       "      <td>0.765745</td>\n",
       "      <td>0.715890</td>\n",
       "      <td>0.745570</td>\n",
       "      <td>0.835668</td>\n",
       "      <td>0.788052</td>\n",
       "      <td>0.775940</td>\n",
       "      <td>0.848104</td>\n",
       "      <td>0.726422</td>\n",
       "      <td>0.827173</td>\n",
       "      <td>0.693993</td>\n",
       "      <td>0.754753</td>\n",
       "      <td>0.793759</td>\n",
       "      <td>0.854304</td>\n",
       "      <td>0.754104</td>\n",
       "      <td>0.759251</td>\n",
       "      <td>0.622615</td>\n",
       "      <td>0.684178</td>\n",
       "      <td>0.802823</td>\n",
       "      <td>0.758510</td>\n",
       "      <td>0.752219</td>\n",
       "      <td>0.671598</td>\n",
       "      <td>0.332114</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.689850</td>\n",
       "      <td>0.516263</td>\n",
       "      <td>0.681406</td>\n",
       "      <td>0.705600</td>\n",
       "      <td>0.536459</td>\n",
       "      <td>0.609513</td>\n",
       "      <td>0.712243</td>\n",
       "      <td>0.677450</td>\n",
       "      <td>0.869786</td>\n",
       "      <td>0.656045</td>\n",
       "      <td>0.376409</td>\n",
       "      <td>0.478358</td>\n",
       "      <td>0.765534</td>\n",
       "      <td>0.468417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74612.0</td>\n",
       "      <td>31977.0</td>\n",
       "      <td>45958.0</td>\n",
       "      <td>0.728736</td>\n",
       "      <td>0.816531</td>\n",
       "      <td>0.761822</td>\n",
       "      <td>0.788228</td>\n",
       "      <td>0.790608</td>\n",
       "      <td>0.878475</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.760066</td>\n",
       "      <td>0.937056</td>\n",
       "      <td>0.839332</td>\n",
       "      <td>0.765188</td>\n",
       "      <td>0.889376</td>\n",
       "      <td>0.732351</td>\n",
       "      <td>0.771784</td>\n",
       "      <td>0.592620</td>\n",
       "      <td>0.670439</td>\n",
       "      <td>0.780573</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.717211</td>\n",
       "      <td>0.788441</td>\n",
       "      <td>0.756360</td>\n",
       "      <td>0.772067</td>\n",
       "      <td>0.773351</td>\n",
       "      <td>0.845948</td>\n",
       "      <td>0.721720</td>\n",
       "      <td>0.755271</td>\n",
       "      <td>0.803971</td>\n",
       "      <td>0.778860</td>\n",
       "      <td>0.788532</td>\n",
       "      <td>0.853834</td>\n",
       "      <td>0.748555</td>\n",
       "      <td>0.750812</td>\n",
       "      <td>0.613890</td>\n",
       "      <td>0.675482</td>\n",
       "      <td>0.798993</td>\n",
       "      <td>0.752178</td>\n",
       "      <td>0.755294</td>\n",
       "      <td>0.651549</td>\n",
       "      <td>0.301202</td>\n",
       "      <td>0.411960</td>\n",
       "      <td>0.690604</td>\n",
       "      <td>0.496026</td>\n",
       "      <td>0.679007</td>\n",
       "      <td>0.706258</td>\n",
       "      <td>0.527313</td>\n",
       "      <td>0.603806</td>\n",
       "      <td>0.708683</td>\n",
       "      <td>0.674905</td>\n",
       "      <td>0.868149</td>\n",
       "      <td>0.661654</td>\n",
       "      <td>0.371492</td>\n",
       "      <td>0.475827</td>\n",
       "      <td>0.769348</td>\n",
       "      <td>0.476570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75218.0</td>\n",
       "      <td>32237.0</td>\n",
       "      <td>45092.0</td>\n",
       "      <td>0.732903</td>\n",
       "      <td>0.787021</td>\n",
       "      <td>0.822524</td>\n",
       "      <td>0.804381</td>\n",
       "      <td>0.789054</td>\n",
       "      <td>0.878937</td>\n",
       "      <td>0.731467</td>\n",
       "      <td>0.740986</td>\n",
       "      <td>0.963985</td>\n",
       "      <td>0.837902</td>\n",
       "      <td>0.759005</td>\n",
       "      <td>0.887357</td>\n",
       "      <td>0.737048</td>\n",
       "      <td>0.774384</td>\n",
       "      <td>0.608109</td>\n",
       "      <td>0.681248</td>\n",
       "      <td>0.788594</td>\n",
       "      <td>0.764155</td>\n",
       "      <td>0.716340</td>\n",
       "      <td>0.762591</td>\n",
       "      <td>0.797159</td>\n",
       "      <td>0.779492</td>\n",
       "      <td>0.770203</td>\n",
       "      <td>0.843298</td>\n",
       "      <td>0.723898</td>\n",
       "      <td>0.788858</td>\n",
       "      <td>0.743195</td>\n",
       "      <td>0.765346</td>\n",
       "      <td>0.785860</td>\n",
       "      <td>0.846798</td>\n",
       "      <td>0.749508</td>\n",
       "      <td>0.744472</td>\n",
       "      <td>0.616899</td>\n",
       "      <td>0.674708</td>\n",
       "      <td>0.801343</td>\n",
       "      <td>0.754635</td>\n",
       "      <td>0.755692</td>\n",
       "      <td>0.666832</td>\n",
       "      <td>0.335411</td>\n",
       "      <td>0.446325</td>\n",
       "      <td>0.685715</td>\n",
       "      <td>0.514105</td>\n",
       "      <td>0.679663</td>\n",
       "      <td>0.720581</td>\n",
       "      <td>0.499145</td>\n",
       "      <td>0.589762</td>\n",
       "      <td>0.707880</td>\n",
       "      <td>0.670312</td>\n",
       "      <td>0.867398</td>\n",
       "      <td>0.672561</td>\n",
       "      <td>0.305757</td>\n",
       "      <td>0.420396</td>\n",
       "      <td>0.772696</td>\n",
       "      <td>0.469958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>75644.0</td>\n",
       "      <td>32420.0</td>\n",
       "      <td>44483.0</td>\n",
       "      <td>0.728596</td>\n",
       "      <td>0.802341</td>\n",
       "      <td>0.783575</td>\n",
       "      <td>0.792847</td>\n",
       "      <td>0.787058</td>\n",
       "      <td>0.874431</td>\n",
       "      <td>0.717457</td>\n",
       "      <td>0.771935</td>\n",
       "      <td>0.860231</td>\n",
       "      <td>0.813695</td>\n",
       "      <td>0.748180</td>\n",
       "      <td>0.884975</td>\n",
       "      <td>0.732728</td>\n",
       "      <td>0.751050</td>\n",
       "      <td>0.636054</td>\n",
       "      <td>0.688785</td>\n",
       "      <td>0.782632</td>\n",
       "      <td>0.754535</td>\n",
       "      <td>0.710985</td>\n",
       "      <td>0.763414</td>\n",
       "      <td>0.777432</td>\n",
       "      <td>0.770359</td>\n",
       "      <td>0.764784</td>\n",
       "      <td>0.836830</td>\n",
       "      <td>0.724027</td>\n",
       "      <td>0.777814</td>\n",
       "      <td>0.762803</td>\n",
       "      <td>0.770236</td>\n",
       "      <td>0.787711</td>\n",
       "      <td>0.850405</td>\n",
       "      <td>0.750987</td>\n",
       "      <td>0.746733</td>\n",
       "      <td>0.619079</td>\n",
       "      <td>0.676940</td>\n",
       "      <td>0.799807</td>\n",
       "      <td>0.745437</td>\n",
       "      <td>0.756633</td>\n",
       "      <td>0.658525</td>\n",
       "      <td>0.352564</td>\n",
       "      <td>0.459252</td>\n",
       "      <td>0.694662</td>\n",
       "      <td>0.516777</td>\n",
       "      <td>0.677775</td>\n",
       "      <td>0.705365</td>\n",
       "      <td>0.519222</td>\n",
       "      <td>0.598146</td>\n",
       "      <td>0.708830</td>\n",
       "      <td>0.674389</td>\n",
       "      <td>0.873489</td>\n",
       "      <td>0.646910</td>\n",
       "      <td>0.353250</td>\n",
       "      <td>0.456969</td>\n",
       "      <td>0.768078</td>\n",
       "      <td>0.464389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74930.0</td>\n",
       "      <td>32113.0</td>\n",
       "      <td>45504.0</td>\n",
       "      <td>0.737133</td>\n",
       "      <td>0.797863</td>\n",
       "      <td>0.814369</td>\n",
       "      <td>0.806032</td>\n",
       "      <td>0.794764</td>\n",
       "      <td>0.883517</td>\n",
       "      <td>0.745830</td>\n",
       "      <td>0.773734</td>\n",
       "      <td>0.921320</td>\n",
       "      <td>0.841102</td>\n",
       "      <td>0.763578</td>\n",
       "      <td>0.892177</td>\n",
       "      <td>0.734484</td>\n",
       "      <td>0.775002</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>0.689118</td>\n",
       "      <td>0.788125</td>\n",
       "      <td>0.764983</td>\n",
       "      <td>0.715180</td>\n",
       "      <td>0.782048</td>\n",
       "      <td>0.762357</td>\n",
       "      <td>0.772077</td>\n",
       "      <td>0.767297</td>\n",
       "      <td>0.842053</td>\n",
       "      <td>0.726163</td>\n",
       "      <td>0.774941</td>\n",
       "      <td>0.782129</td>\n",
       "      <td>0.778519</td>\n",
       "      <td>0.790739</td>\n",
       "      <td>0.854278</td>\n",
       "      <td>0.754397</td>\n",
       "      <td>0.768658</td>\n",
       "      <td>0.619850</td>\n",
       "      <td>0.686280</td>\n",
       "      <td>0.806063</td>\n",
       "      <td>0.761659</td>\n",
       "      <td>0.754879</td>\n",
       "      <td>0.641686</td>\n",
       "      <td>0.341731</td>\n",
       "      <td>0.445964</td>\n",
       "      <td>0.681837</td>\n",
       "      <td>0.493857</td>\n",
       "      <td>0.672856</td>\n",
       "      <td>0.703631</td>\n",
       "      <td>0.511074</td>\n",
       "      <td>0.592090</td>\n",
       "      <td>0.706760</td>\n",
       "      <td>0.667254</td>\n",
       "      <td>0.862740</td>\n",
       "      <td>0.676247</td>\n",
       "      <td>0.309122</td>\n",
       "      <td>0.424294</td>\n",
       "      <td>0.780644</td>\n",
       "      <td>0.480358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>74930.0</td>\n",
       "      <td>32114.0</td>\n",
       "      <td>45503.0</td>\n",
       "      <td>0.721566</td>\n",
       "      <td>0.755784</td>\n",
       "      <td>0.848432</td>\n",
       "      <td>0.799433</td>\n",
       "      <td>0.785138</td>\n",
       "      <td>0.867922</td>\n",
       "      <td>0.734282</td>\n",
       "      <td>0.763465</td>\n",
       "      <td>0.912700</td>\n",
       "      <td>0.831439</td>\n",
       "      <td>0.759725</td>\n",
       "      <td>0.884455</td>\n",
       "      <td>0.734495</td>\n",
       "      <td>0.766898</td>\n",
       "      <td>0.602314</td>\n",
       "      <td>0.674714</td>\n",
       "      <td>0.785662</td>\n",
       "      <td>0.753361</td>\n",
       "      <td>0.712845</td>\n",
       "      <td>0.778902</td>\n",
       "      <td>0.753481</td>\n",
       "      <td>0.765981</td>\n",
       "      <td>0.771134</td>\n",
       "      <td>0.841359</td>\n",
       "      <td>0.724613</td>\n",
       "      <td>0.778498</td>\n",
       "      <td>0.757858</td>\n",
       "      <td>0.768039</td>\n",
       "      <td>0.788248</td>\n",
       "      <td>0.844765</td>\n",
       "      <td>0.751249</td>\n",
       "      <td>0.753711</td>\n",
       "      <td>0.604807</td>\n",
       "      <td>0.671098</td>\n",
       "      <td>0.802229</td>\n",
       "      <td>0.747038</td>\n",
       "      <td>0.745347</td>\n",
       "      <td>0.628917</td>\n",
       "      <td>0.289035</td>\n",
       "      <td>0.396053</td>\n",
       "      <td>0.686535</td>\n",
       "      <td>0.480217</td>\n",
       "      <td>0.674298</td>\n",
       "      <td>0.685075</td>\n",
       "      <td>0.523506</td>\n",
       "      <td>0.593491</td>\n",
       "      <td>0.704093</td>\n",
       "      <td>0.664478</td>\n",
       "      <td>0.860518</td>\n",
       "      <td>0.666440</td>\n",
       "      <td>0.247665</td>\n",
       "      <td>0.361126</td>\n",
       "      <td>0.766323</td>\n",
       "      <td>0.455717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>74422.0</td>\n",
       "      <td>31896.0</td>\n",
       "      <td>46229.0</td>\n",
       "      <td>0.737130</td>\n",
       "      <td>0.799960</td>\n",
       "      <td>0.808727</td>\n",
       "      <td>0.804320</td>\n",
       "      <td>0.794766</td>\n",
       "      <td>0.884322</td>\n",
       "      <td>0.737959</td>\n",
       "      <td>0.756838</td>\n",
       "      <td>0.943063</td>\n",
       "      <td>0.839750</td>\n",
       "      <td>0.758284</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.734273</td>\n",
       "      <td>0.772817</td>\n",
       "      <td>0.616997</td>\n",
       "      <td>0.686172</td>\n",
       "      <td>0.789982</td>\n",
       "      <td>0.762773</td>\n",
       "      <td>0.714980</td>\n",
       "      <td>0.775120</td>\n",
       "      <td>0.776100</td>\n",
       "      <td>0.775610</td>\n",
       "      <td>0.769893</td>\n",
       "      <td>0.845650</td>\n",
       "      <td>0.728438</td>\n",
       "      <td>0.795632</td>\n",
       "      <td>0.750089</td>\n",
       "      <td>0.772190</td>\n",
       "      <td>0.792730</td>\n",
       "      <td>0.858375</td>\n",
       "      <td>0.755235</td>\n",
       "      <td>0.756515</td>\n",
       "      <td>0.636954</td>\n",
       "      <td>0.691605</td>\n",
       "      <td>0.807604</td>\n",
       "      <td>0.763558</td>\n",
       "      <td>0.759701</td>\n",
       "      <td>0.668555</td>\n",
       "      <td>0.343689</td>\n",
       "      <td>0.453992</td>\n",
       "      <td>0.683440</td>\n",
       "      <td>0.510202</td>\n",
       "      <td>0.676327</td>\n",
       "      <td>0.706876</td>\n",
       "      <td>0.523091</td>\n",
       "      <td>0.601252</td>\n",
       "      <td>0.707007</td>\n",
       "      <td>0.672156</td>\n",
       "      <td>0.860032</td>\n",
       "      <td>0.656818</td>\n",
       "      <td>0.344130</td>\n",
       "      <td>0.451633</td>\n",
       "      <td>0.772360</td>\n",
       "      <td>0.472442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74554.0</td>\n",
       "      <td>31952.0</td>\n",
       "      <td>46041.0</td>\n",
       "      <td>0.732264</td>\n",
       "      <td>0.809455</td>\n",
       "      <td>0.776661</td>\n",
       "      <td>0.792719</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>0.879088</td>\n",
       "      <td>0.730561</td>\n",
       "      <td>0.754551</td>\n",
       "      <td>0.927860</td>\n",
       "      <td>0.832279</td>\n",
       "      <td>0.755301</td>\n",
       "      <td>0.884825</td>\n",
       "      <td>0.734424</td>\n",
       "      <td>0.752448</td>\n",
       "      <td>0.640819</td>\n",
       "      <td>0.692162</td>\n",
       "      <td>0.786533</td>\n",
       "      <td>0.760621</td>\n",
       "      <td>0.715843</td>\n",
       "      <td>0.765214</td>\n",
       "      <td>0.792179</td>\n",
       "      <td>0.778463</td>\n",
       "      <td>0.770635</td>\n",
       "      <td>0.842841</td>\n",
       "      <td>0.722614</td>\n",
       "      <td>0.783668</td>\n",
       "      <td>0.749974</td>\n",
       "      <td>0.766451</td>\n",
       "      <td>0.785169</td>\n",
       "      <td>0.846773</td>\n",
       "      <td>0.746125</td>\n",
       "      <td>0.737607</td>\n",
       "      <td>0.625648</td>\n",
       "      <td>0.677030</td>\n",
       "      <td>0.794489</td>\n",
       "      <td>0.737171</td>\n",
       "      <td>0.760470</td>\n",
       "      <td>0.668163</td>\n",
       "      <td>0.363370</td>\n",
       "      <td>0.470737</td>\n",
       "      <td>0.692136</td>\n",
       "      <td>0.513580</td>\n",
       "      <td>0.678048</td>\n",
       "      <td>0.695621</td>\n",
       "      <td>0.542703</td>\n",
       "      <td>0.609720</td>\n",
       "      <td>0.710702</td>\n",
       "      <td>0.675677</td>\n",
       "      <td>0.867364</td>\n",
       "      <td>0.642298</td>\n",
       "      <td>0.368631</td>\n",
       "      <td>0.468423</td>\n",
       "      <td>0.775991</td>\n",
       "      <td>0.464644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>74921.0</td>\n",
       "      <td>32110.0</td>\n",
       "      <td>45516.0</td>\n",
       "      <td>0.727219</td>\n",
       "      <td>0.785845</td>\n",
       "      <td>0.807939</td>\n",
       "      <td>0.796739</td>\n",
       "      <td>0.786641</td>\n",
       "      <td>0.874877</td>\n",
       "      <td>0.734409</td>\n",
       "      <td>0.757215</td>\n",
       "      <td>0.928809</td>\n",
       "      <td>0.834280</td>\n",
       "      <td>0.759626</td>\n",
       "      <td>0.888731</td>\n",
       "      <td>0.735942</td>\n",
       "      <td>0.762835</td>\n",
       "      <td>0.614232</td>\n",
       "      <td>0.680516</td>\n",
       "      <td>0.785960</td>\n",
       "      <td>0.756703</td>\n",
       "      <td>0.714808</td>\n",
       "      <td>0.770084</td>\n",
       "      <td>0.778277</td>\n",
       "      <td>0.774159</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.843515</td>\n",
       "      <td>0.725393</td>\n",
       "      <td>0.779956</td>\n",
       "      <td>0.759385</td>\n",
       "      <td>0.769533</td>\n",
       "      <td>0.790039</td>\n",
       "      <td>0.852158</td>\n",
       "      <td>0.755069</td>\n",
       "      <td>0.749891</td>\n",
       "      <td>0.620972</td>\n",
       "      <td>0.679369</td>\n",
       "      <td>0.799844</td>\n",
       "      <td>0.750496</td>\n",
       "      <td>0.760353</td>\n",
       "      <td>0.674817</td>\n",
       "      <td>0.347345</td>\n",
       "      <td>0.458624</td>\n",
       "      <td>0.693337</td>\n",
       "      <td>0.510968</td>\n",
       "      <td>0.683620</td>\n",
       "      <td>0.711091</td>\n",
       "      <td>0.527963</td>\n",
       "      <td>0.605994</td>\n",
       "      <td>0.707307</td>\n",
       "      <td>0.677400</td>\n",
       "      <td>0.867968</td>\n",
       "      <td>0.671967</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.409327</td>\n",
       "      <td>0.774827</td>\n",
       "      <td>0.465755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>74595.0</td>\n",
       "      <td>31970.0</td>\n",
       "      <td>45982.0</td>\n",
       "      <td>0.730648</td>\n",
       "      <td>0.797784</td>\n",
       "      <td>0.797057</td>\n",
       "      <td>0.797420</td>\n",
       "      <td>0.787263</td>\n",
       "      <td>0.875697</td>\n",
       "      <td>0.733910</td>\n",
       "      <td>0.757472</td>\n",
       "      <td>0.927286</td>\n",
       "      <td>0.833821</td>\n",
       "      <td>0.761232</td>\n",
       "      <td>0.888291</td>\n",
       "      <td>0.732201</td>\n",
       "      <td>0.738800</td>\n",
       "      <td>0.642056</td>\n",
       "      <td>0.687039</td>\n",
       "      <td>0.783288</td>\n",
       "      <td>0.751934</td>\n",
       "      <td>0.710758</td>\n",
       "      <td>0.764779</td>\n",
       "      <td>0.785235</td>\n",
       "      <td>0.774872</td>\n",
       "      <td>0.764419</td>\n",
       "      <td>0.838123</td>\n",
       "      <td>0.727543</td>\n",
       "      <td>0.792740</td>\n",
       "      <td>0.750460</td>\n",
       "      <td>0.771021</td>\n",
       "      <td>0.788032</td>\n",
       "      <td>0.849035</td>\n",
       "      <td>0.753487</td>\n",
       "      <td>0.747104</td>\n",
       "      <td>0.635222</td>\n",
       "      <td>0.686635</td>\n",
       "      <td>0.803718</td>\n",
       "      <td>0.757043</td>\n",
       "      <td>0.757452</td>\n",
       "      <td>0.685811</td>\n",
       "      <td>0.301709</td>\n",
       "      <td>0.419061</td>\n",
       "      <td>0.693021</td>\n",
       "      <td>0.518514</td>\n",
       "      <td>0.677522</td>\n",
       "      <td>0.713723</td>\n",
       "      <td>0.505530</td>\n",
       "      <td>0.591851</td>\n",
       "      <td>0.706861</td>\n",
       "      <td>0.671550</td>\n",
       "      <td>0.869139</td>\n",
       "      <td>0.664642</td>\n",
       "      <td>0.381189</td>\n",
       "      <td>0.484503</td>\n",
       "      <td>0.780263</td>\n",
       "      <td>0.483135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>74894.0</td>\n",
       "      <td>32098.0</td>\n",
       "      <td>45555.0</td>\n",
       "      <td>0.730136</td>\n",
       "      <td>0.782509</td>\n",
       "      <td>0.817097</td>\n",
       "      <td>0.799429</td>\n",
       "      <td>0.790604</td>\n",
       "      <td>0.878243</td>\n",
       "      <td>0.739775</td>\n",
       "      <td>0.754993</td>\n",
       "      <td>0.949876</td>\n",
       "      <td>0.841296</td>\n",
       "      <td>0.756856</td>\n",
       "      <td>0.886645</td>\n",
       "      <td>0.736225</td>\n",
       "      <td>0.759604</td>\n",
       "      <td>0.623714</td>\n",
       "      <td>0.684984</td>\n",
       "      <td>0.785350</td>\n",
       "      <td>0.758581</td>\n",
       "      <td>0.714373</td>\n",
       "      <td>0.766730</td>\n",
       "      <td>0.781914</td>\n",
       "      <td>0.774248</td>\n",
       "      <td>0.769552</td>\n",
       "      <td>0.841741</td>\n",
       "      <td>0.722959</td>\n",
       "      <td>0.780231</td>\n",
       "      <td>0.752046</td>\n",
       "      <td>0.765880</td>\n",
       "      <td>0.786812</td>\n",
       "      <td>0.849679</td>\n",
       "      <td>0.751993</td>\n",
       "      <td>0.743656</td>\n",
       "      <td>0.631399</td>\n",
       "      <td>0.682946</td>\n",
       "      <td>0.800189</td>\n",
       "      <td>0.756382</td>\n",
       "      <td>0.766089</td>\n",
       "      <td>0.677327</td>\n",
       "      <td>0.355105</td>\n",
       "      <td>0.465933</td>\n",
       "      <td>0.688374</td>\n",
       "      <td>0.510706</td>\n",
       "      <td>0.675870</td>\n",
       "      <td>0.696020</td>\n",
       "      <td>0.541584</td>\n",
       "      <td>0.609167</td>\n",
       "      <td>0.705917</td>\n",
       "      <td>0.674768</td>\n",
       "      <td>0.859961</td>\n",
       "      <td>0.656233</td>\n",
       "      <td>0.290235</td>\n",
       "      <td>0.402468</td>\n",
       "      <td>0.762168</td>\n",
       "      <td>0.459444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75020.0</td>\n",
       "      <td>32152.0</td>\n",
       "      <td>45375.0</td>\n",
       "      <td>0.730187</td>\n",
       "      <td>0.796642</td>\n",
       "      <td>0.796395</td>\n",
       "      <td>0.796518</td>\n",
       "      <td>0.788921</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.733814</td>\n",
       "      <td>0.747961</td>\n",
       "      <td>0.949829</td>\n",
       "      <td>0.836894</td>\n",
       "      <td>0.745687</td>\n",
       "      <td>0.882509</td>\n",
       "      <td>0.725863</td>\n",
       "      <td>0.749725</td>\n",
       "      <td>0.607538</td>\n",
       "      <td>0.671184</td>\n",
       "      <td>0.778041</td>\n",
       "      <td>0.750366</td>\n",
       "      <td>0.707612</td>\n",
       "      <td>0.768706</td>\n",
       "      <td>0.764655</td>\n",
       "      <td>0.766675</td>\n",
       "      <td>0.765113</td>\n",
       "      <td>0.839838</td>\n",
       "      <td>0.725211</td>\n",
       "      <td>0.787672</td>\n",
       "      <td>0.746613</td>\n",
       "      <td>0.766593</td>\n",
       "      <td>0.789667</td>\n",
       "      <td>0.849113</td>\n",
       "      <td>0.752691</td>\n",
       "      <td>0.749036</td>\n",
       "      <td>0.615667</td>\n",
       "      <td>0.675835</td>\n",
       "      <td>0.800947</td>\n",
       "      <td>0.749472</td>\n",
       "      <td>0.752850</td>\n",
       "      <td>0.656280</td>\n",
       "      <td>0.349334</td>\n",
       "      <td>0.455962</td>\n",
       "      <td>0.679783</td>\n",
       "      <td>0.498366</td>\n",
       "      <td>0.675874</td>\n",
       "      <td>0.703961</td>\n",
       "      <td>0.516511</td>\n",
       "      <td>0.595841</td>\n",
       "      <td>0.704866</td>\n",
       "      <td>0.671265</td>\n",
       "      <td>0.866601</td>\n",
       "      <td>0.654567</td>\n",
       "      <td>0.296081</td>\n",
       "      <td>0.407732</td>\n",
       "      <td>0.763730</td>\n",
       "      <td>0.445584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>74561.0</td>\n",
       "      <td>31956.0</td>\n",
       "      <td>46030.0</td>\n",
       "      <td>0.730024</td>\n",
       "      <td>0.806607</td>\n",
       "      <td>0.784070</td>\n",
       "      <td>0.795179</td>\n",
       "      <td>0.788240</td>\n",
       "      <td>0.880008</td>\n",
       "      <td>0.737723</td>\n",
       "      <td>0.780600</td>\n",
       "      <td>0.887143</td>\n",
       "      <td>0.830468</td>\n",
       "      <td>0.763511</td>\n",
       "      <td>0.889929</td>\n",
       "      <td>0.740729</td>\n",
       "      <td>0.765510</td>\n",
       "      <td>0.628523</td>\n",
       "      <td>0.690286</td>\n",
       "      <td>0.792270</td>\n",
       "      <td>0.761403</td>\n",
       "      <td>0.714359</td>\n",
       "      <td>0.767468</td>\n",
       "      <td>0.784376</td>\n",
       "      <td>0.775830</td>\n",
       "      <td>0.769765</td>\n",
       "      <td>0.842684</td>\n",
       "      <td>0.728197</td>\n",
       "      <td>0.787895</td>\n",
       "      <td>0.761944</td>\n",
       "      <td>0.774702</td>\n",
       "      <td>0.794383</td>\n",
       "      <td>0.856791</td>\n",
       "      <td>0.757735</td>\n",
       "      <td>0.777198</td>\n",
       "      <td>0.602469</td>\n",
       "      <td>0.678769</td>\n",
       "      <td>0.809152</td>\n",
       "      <td>0.763213</td>\n",
       "      <td>0.759240</td>\n",
       "      <td>0.691411</td>\n",
       "      <td>0.290389</td>\n",
       "      <td>0.409000</td>\n",
       "      <td>0.703472</td>\n",
       "      <td>0.520959</td>\n",
       "      <td>0.674432</td>\n",
       "      <td>0.682485</td>\n",
       "      <td>0.553418</td>\n",
       "      <td>0.611212</td>\n",
       "      <td>0.708835</td>\n",
       "      <td>0.675194</td>\n",
       "      <td>0.865088</td>\n",
       "      <td>0.641453</td>\n",
       "      <td>0.373662</td>\n",
       "      <td>0.472235</td>\n",
       "      <td>0.776414</td>\n",
       "      <td>0.477240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>75352.0</td>\n",
       "      <td>32295.0</td>\n",
       "      <td>44900.0</td>\n",
       "      <td>0.729424</td>\n",
       "      <td>0.794971</td>\n",
       "      <td>0.794298</td>\n",
       "      <td>0.794634</td>\n",
       "      <td>0.789501</td>\n",
       "      <td>0.876203</td>\n",
       "      <td>0.738645</td>\n",
       "      <td>0.753476</td>\n",
       "      <td>0.949388</td>\n",
       "      <td>0.840162</td>\n",
       "      <td>0.761229</td>\n",
       "      <td>0.888852</td>\n",
       "      <td>0.732710</td>\n",
       "      <td>0.741063</td>\n",
       "      <td>0.636864</td>\n",
       "      <td>0.685024</td>\n",
       "      <td>0.785336</td>\n",
       "      <td>0.753547</td>\n",
       "      <td>0.715200</td>\n",
       "      <td>0.783354</td>\n",
       "      <td>0.757138</td>\n",
       "      <td>0.770023</td>\n",
       "      <td>0.774051</td>\n",
       "      <td>0.847261</td>\n",
       "      <td>0.718922</td>\n",
       "      <td>0.806408</td>\n",
       "      <td>0.701812</td>\n",
       "      <td>0.750483</td>\n",
       "      <td>0.785736</td>\n",
       "      <td>0.845924</td>\n",
       "      <td>0.756782</td>\n",
       "      <td>0.756824</td>\n",
       "      <td>0.619225</td>\n",
       "      <td>0.681145</td>\n",
       "      <td>0.806103</td>\n",
       "      <td>0.755511</td>\n",
       "      <td>0.751975</td>\n",
       "      <td>0.665829</td>\n",
       "      <td>0.332247</td>\n",
       "      <td>0.443292</td>\n",
       "      <td>0.683461</td>\n",
       "      <td>0.508516</td>\n",
       "      <td>0.678081</td>\n",
       "      <td>0.706298</td>\n",
       "      <td>0.519958</td>\n",
       "      <td>0.598970</td>\n",
       "      <td>0.708890</td>\n",
       "      <td>0.671901</td>\n",
       "      <td>0.863440</td>\n",
       "      <td>0.624786</td>\n",
       "      <td>0.372730</td>\n",
       "      <td>0.466912</td>\n",
       "      <td>0.761321</td>\n",
       "      <td>0.448823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>74791.0</td>\n",
       "      <td>32054.0</td>\n",
       "      <td>45702.0</td>\n",
       "      <td>0.726092</td>\n",
       "      <td>0.765136</td>\n",
       "      <td>0.847133</td>\n",
       "      <td>0.804049</td>\n",
       "      <td>0.791196</td>\n",
       "      <td>0.880492</td>\n",
       "      <td>0.733084</td>\n",
       "      <td>0.744954</td>\n",
       "      <td>0.958992</td>\n",
       "      <td>0.838530</td>\n",
       "      <td>0.765673</td>\n",
       "      <td>0.891684</td>\n",
       "      <td>0.735534</td>\n",
       "      <td>0.779214</td>\n",
       "      <td>0.612272</td>\n",
       "      <td>0.685728</td>\n",
       "      <td>0.788030</td>\n",
       "      <td>0.768638</td>\n",
       "      <td>0.716297</td>\n",
       "      <td>0.761848</td>\n",
       "      <td>0.800407</td>\n",
       "      <td>0.780652</td>\n",
       "      <td>0.771465</td>\n",
       "      <td>0.844584</td>\n",
       "      <td>0.727238</td>\n",
       "      <td>0.774392</td>\n",
       "      <td>0.779426</td>\n",
       "      <td>0.776901</td>\n",
       "      <td>0.791160</td>\n",
       "      <td>0.853713</td>\n",
       "      <td>0.757890</td>\n",
       "      <td>0.767175</td>\n",
       "      <td>0.626951</td>\n",
       "      <td>0.690011</td>\n",
       "      <td>0.809554</td>\n",
       "      <td>0.763373</td>\n",
       "      <td>0.752931</td>\n",
       "      <td>0.662298</td>\n",
       "      <td>0.323805</td>\n",
       "      <td>0.434955</td>\n",
       "      <td>0.684452</td>\n",
       "      <td>0.510978</td>\n",
       "      <td>0.672373</td>\n",
       "      <td>0.708476</td>\n",
       "      <td>0.504522</td>\n",
       "      <td>0.589352</td>\n",
       "      <td>0.707427</td>\n",
       "      <td>0.676848</td>\n",
       "      <td>0.870485</td>\n",
       "      <td>0.657724</td>\n",
       "      <td>0.365083</td>\n",
       "      <td>0.469539</td>\n",
       "      <td>0.773036</td>\n",
       "      <td>0.467351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>74766.0</td>\n",
       "      <td>32043.0</td>\n",
       "      <td>45738.0</td>\n",
       "      <td>0.739528</td>\n",
       "      <td>0.827624</td>\n",
       "      <td>0.771951</td>\n",
       "      <td>0.798819</td>\n",
       "      <td>0.799406</td>\n",
       "      <td>0.888325</td>\n",
       "      <td>0.733242</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.973526</td>\n",
       "      <td>0.840581</td>\n",
       "      <td>0.763458</td>\n",
       "      <td>0.889637</td>\n",
       "      <td>0.741456</td>\n",
       "      <td>0.765276</td>\n",
       "      <td>0.648273</td>\n",
       "      <td>0.701933</td>\n",
       "      <td>0.791218</td>\n",
       "      <td>0.768117</td>\n",
       "      <td>0.716414</td>\n",
       "      <td>0.770703</td>\n",
       "      <td>0.785239</td>\n",
       "      <td>0.777903</td>\n",
       "      <td>0.771179</td>\n",
       "      <td>0.843130</td>\n",
       "      <td>0.734331</td>\n",
       "      <td>0.790370</td>\n",
       "      <td>0.772168</td>\n",
       "      <td>0.781163</td>\n",
       "      <td>0.794361</td>\n",
       "      <td>0.853396</td>\n",
       "      <td>0.755716</td>\n",
       "      <td>0.756036</td>\n",
       "      <td>0.643340</td>\n",
       "      <td>0.695150</td>\n",
       "      <td>0.806644</td>\n",
       "      <td>0.761338</td>\n",
       "      <td>0.763445</td>\n",
       "      <td>0.658876</td>\n",
       "      <td>0.336465</td>\n",
       "      <td>0.445453</td>\n",
       "      <td>0.693864</td>\n",
       "      <td>0.505028</td>\n",
       "      <td>0.682369</td>\n",
       "      <td>0.706076</td>\n",
       "      <td>0.537249</td>\n",
       "      <td>0.610200</td>\n",
       "      <td>0.709901</td>\n",
       "      <td>0.678174</td>\n",
       "      <td>0.862646</td>\n",
       "      <td>0.668027</td>\n",
       "      <td>0.320921</td>\n",
       "      <td>0.433559</td>\n",
       "      <td>0.763963</td>\n",
       "      <td>0.472847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>74617.0</td>\n",
       "      <td>31980.0</td>\n",
       "      <td>45950.0</td>\n",
       "      <td>0.737431</td>\n",
       "      <td>0.810535</td>\n",
       "      <td>0.790137</td>\n",
       "      <td>0.800206</td>\n",
       "      <td>0.795210</td>\n",
       "      <td>0.880505</td>\n",
       "      <td>0.735479</td>\n",
       "      <td>0.770572</td>\n",
       "      <td>0.903279</td>\n",
       "      <td>0.831665</td>\n",
       "      <td>0.762560</td>\n",
       "      <td>0.889922</td>\n",
       "      <td>0.734053</td>\n",
       "      <td>0.757586</td>\n",
       "      <td>0.636285</td>\n",
       "      <td>0.691658</td>\n",
       "      <td>0.787872</td>\n",
       "      <td>0.764149</td>\n",
       "      <td>0.714718</td>\n",
       "      <td>0.751042</td>\n",
       "      <td>0.819164</td>\n",
       "      <td>0.783625</td>\n",
       "      <td>0.772354</td>\n",
       "      <td>0.846416</td>\n",
       "      <td>0.727664</td>\n",
       "      <td>0.792633</td>\n",
       "      <td>0.748943</td>\n",
       "      <td>0.770169</td>\n",
       "      <td>0.792710</td>\n",
       "      <td>0.851986</td>\n",
       "      <td>0.756781</td>\n",
       "      <td>0.746332</td>\n",
       "      <td>0.650292</td>\n",
       "      <td>0.695010</td>\n",
       "      <td>0.807731</td>\n",
       "      <td>0.759995</td>\n",
       "      <td>0.758053</td>\n",
       "      <td>0.671926</td>\n",
       "      <td>0.307827</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.691276</td>\n",
       "      <td>0.512985</td>\n",
       "      <td>0.682826</td>\n",
       "      <td>0.712780</td>\n",
       "      <td>0.537066</td>\n",
       "      <td>0.612571</td>\n",
       "      <td>0.714001</td>\n",
       "      <td>0.688501</td>\n",
       "      <td>0.865306</td>\n",
       "      <td>0.664968</td>\n",
       "      <td>0.353710</td>\n",
       "      <td>0.461786</td>\n",
       "      <td>0.775298</td>\n",
       "      <td>0.476396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>74348.0</td>\n",
       "      <td>31864.0</td>\n",
       "      <td>46335.0</td>\n",
       "      <td>0.737132</td>\n",
       "      <td>0.816068</td>\n",
       "      <td>0.781024</td>\n",
       "      <td>0.798162</td>\n",
       "      <td>0.793544</td>\n",
       "      <td>0.881476</td>\n",
       "      <td>0.742848</td>\n",
       "      <td>0.753944</td>\n",
       "      <td>0.961783</td>\n",
       "      <td>0.845275</td>\n",
       "      <td>0.767387</td>\n",
       "      <td>0.893791</td>\n",
       "      <td>0.734973</td>\n",
       "      <td>0.764351</td>\n",
       "      <td>0.620164</td>\n",
       "      <td>0.684749</td>\n",
       "      <td>0.788063</td>\n",
       "      <td>0.755629</td>\n",
       "      <td>0.715095</td>\n",
       "      <td>0.780475</td>\n",
       "      <td>0.762351</td>\n",
       "      <td>0.771307</td>\n",
       "      <td>0.771012</td>\n",
       "      <td>0.841777</td>\n",
       "      <td>0.731461</td>\n",
       "      <td>0.803635</td>\n",
       "      <td>0.744253</td>\n",
       "      <td>0.772805</td>\n",
       "      <td>0.794074</td>\n",
       "      <td>0.853770</td>\n",
       "      <td>0.751055</td>\n",
       "      <td>0.766845</td>\n",
       "      <td>0.603916</td>\n",
       "      <td>0.675698</td>\n",
       "      <td>0.802460</td>\n",
       "      <td>0.753985</td>\n",
       "      <td>0.752347</td>\n",
       "      <td>0.683202</td>\n",
       "      <td>0.295178</td>\n",
       "      <td>0.412245</td>\n",
       "      <td>0.696313</td>\n",
       "      <td>0.515276</td>\n",
       "      <td>0.676968</td>\n",
       "      <td>0.717295</td>\n",
       "      <td>0.502711</td>\n",
       "      <td>0.591132</td>\n",
       "      <td>0.707208</td>\n",
       "      <td>0.676938</td>\n",
       "      <td>0.866245</td>\n",
       "      <td>0.633258</td>\n",
       "      <td>0.354287</td>\n",
       "      <td>0.454370</td>\n",
       "      <td>0.773616</td>\n",
       "      <td>0.456566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>74657.0</td>\n",
       "      <td>31997.0</td>\n",
       "      <td>45893.0</td>\n",
       "      <td>0.737187</td>\n",
       "      <td>0.794691</td>\n",
       "      <td>0.817929</td>\n",
       "      <td>0.806143</td>\n",
       "      <td>0.794798</td>\n",
       "      <td>0.882761</td>\n",
       "      <td>0.730976</td>\n",
       "      <td>0.757097</td>\n",
       "      <td>0.919955</td>\n",
       "      <td>0.830618</td>\n",
       "      <td>0.761943</td>\n",
       "      <td>0.889007</td>\n",
       "      <td>0.733485</td>\n",
       "      <td>0.766115</td>\n",
       "      <td>0.617427</td>\n",
       "      <td>0.683781</td>\n",
       "      <td>0.786721</td>\n",
       "      <td>0.758035</td>\n",
       "      <td>0.719943</td>\n",
       "      <td>0.763719</td>\n",
       "      <td>0.806575</td>\n",
       "      <td>0.784562</td>\n",
       "      <td>0.776514</td>\n",
       "      <td>0.849074</td>\n",
       "      <td>0.724977</td>\n",
       "      <td>0.805164</td>\n",
       "      <td>0.727477</td>\n",
       "      <td>0.764352</td>\n",
       "      <td>0.789200</td>\n",
       "      <td>0.853828</td>\n",
       "      <td>0.754153</td>\n",
       "      <td>0.750598</td>\n",
       "      <td>0.634140</td>\n",
       "      <td>0.687472</td>\n",
       "      <td>0.803973</td>\n",
       "      <td>0.748624</td>\n",
       "      <td>0.758166</td>\n",
       "      <td>0.698860</td>\n",
       "      <td>0.293821</td>\n",
       "      <td>0.413707</td>\n",
       "      <td>0.692416</td>\n",
       "      <td>0.523651</td>\n",
       "      <td>0.680692</td>\n",
       "      <td>0.693070</td>\n",
       "      <td>0.559799</td>\n",
       "      <td>0.619347</td>\n",
       "      <td>0.713650</td>\n",
       "      <td>0.678552</td>\n",
       "      <td>0.865838</td>\n",
       "      <td>0.679417</td>\n",
       "      <td>0.285678</td>\n",
       "      <td>0.402229</td>\n",
       "      <td>0.759455</td>\n",
       "      <td>0.465908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>74777.0</td>\n",
       "      <td>32048.0</td>\n",
       "      <td>45722.0</td>\n",
       "      <td>0.731057</td>\n",
       "      <td>0.786970</td>\n",
       "      <td>0.811423</td>\n",
       "      <td>0.799009</td>\n",
       "      <td>0.792742</td>\n",
       "      <td>0.879288</td>\n",
       "      <td>0.734552</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.912625</td>\n",
       "      <td>0.832498</td>\n",
       "      <td>0.757796</td>\n",
       "      <td>0.886734</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.735432</td>\n",
       "      <td>0.652843</td>\n",
       "      <td>0.691681</td>\n",
       "      <td>0.778003</td>\n",
       "      <td>0.748462</td>\n",
       "      <td>0.714105</td>\n",
       "      <td>0.759461</td>\n",
       "      <td>0.802705</td>\n",
       "      <td>0.780484</td>\n",
       "      <td>0.770200</td>\n",
       "      <td>0.843287</td>\n",
       "      <td>0.720159</td>\n",
       "      <td>0.758482</td>\n",
       "      <td>0.789354</td>\n",
       "      <td>0.773610</td>\n",
       "      <td>0.787675</td>\n",
       "      <td>0.848784</td>\n",
       "      <td>0.750874</td>\n",
       "      <td>0.747043</td>\n",
       "      <td>0.623845</td>\n",
       "      <td>0.679909</td>\n",
       "      <td>0.801668</td>\n",
       "      <td>0.752328</td>\n",
       "      <td>0.764378</td>\n",
       "      <td>0.655483</td>\n",
       "      <td>0.334355</td>\n",
       "      <td>0.442828</td>\n",
       "      <td>0.666895</td>\n",
       "      <td>0.489952</td>\n",
       "      <td>0.677863</td>\n",
       "      <td>0.697996</td>\n",
       "      <td>0.529806</td>\n",
       "      <td>0.602382</td>\n",
       "      <td>0.707716</td>\n",
       "      <td>0.673490</td>\n",
       "      <td>0.867065</td>\n",
       "      <td>0.667967</td>\n",
       "      <td>0.340204</td>\n",
       "      <td>0.450806</td>\n",
       "      <td>0.772393</td>\n",
       "      <td>0.478627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>74986.0</td>\n",
       "      <td>32138.0</td>\n",
       "      <td>45423.0</td>\n",
       "      <td>0.725982</td>\n",
       "      <td>0.778267</td>\n",
       "      <td>0.814596</td>\n",
       "      <td>0.796017</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.873664</td>\n",
       "      <td>0.733828</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.927592</td>\n",
       "      <td>0.833830</td>\n",
       "      <td>0.756293</td>\n",
       "      <td>0.881178</td>\n",
       "      <td>0.734953</td>\n",
       "      <td>0.756610</td>\n",
       "      <td>0.625578</td>\n",
       "      <td>0.684883</td>\n",
       "      <td>0.788249</td>\n",
       "      <td>0.761695</td>\n",
       "      <td>0.707124</td>\n",
       "      <td>0.766843</td>\n",
       "      <td>0.763062</td>\n",
       "      <td>0.764947</td>\n",
       "      <td>0.766478</td>\n",
       "      <td>0.836439</td>\n",
       "      <td>0.723568</td>\n",
       "      <td>0.786429</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.763668</td>\n",
       "      <td>0.789380</td>\n",
       "      <td>0.847395</td>\n",
       "      <td>0.755547</td>\n",
       "      <td>0.744797</td>\n",
       "      <td>0.631518</td>\n",
       "      <td>0.683496</td>\n",
       "      <td>0.803866</td>\n",
       "      <td>0.752405</td>\n",
       "      <td>0.755621</td>\n",
       "      <td>0.673130</td>\n",
       "      <td>0.359645</td>\n",
       "      <td>0.468810</td>\n",
       "      <td>0.686998</td>\n",
       "      <td>0.518930</td>\n",
       "      <td>0.681567</td>\n",
       "      <td>0.708751</td>\n",
       "      <td>0.522170</td>\n",
       "      <td>0.601320</td>\n",
       "      <td>0.710613</td>\n",
       "      <td>0.678946</td>\n",
       "      <td>0.869590</td>\n",
       "      <td>0.671727</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.396491</td>\n",
       "      <td>0.779357</td>\n",
       "      <td>0.471373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>74314.0</td>\n",
       "      <td>31849.0</td>\n",
       "      <td>46384.0</td>\n",
       "      <td>0.732988</td>\n",
       "      <td>0.792166</td>\n",
       "      <td>0.817373</td>\n",
       "      <td>0.804572</td>\n",
       "      <td>0.788640</td>\n",
       "      <td>0.882478</td>\n",
       "      <td>0.735976</td>\n",
       "      <td>0.749380</td>\n",
       "      <td>0.949892</td>\n",
       "      <td>0.837806</td>\n",
       "      <td>0.764339</td>\n",
       "      <td>0.887006</td>\n",
       "      <td>0.733626</td>\n",
       "      <td>0.766747</td>\n",
       "      <td>0.627466</td>\n",
       "      <td>0.690150</td>\n",
       "      <td>0.786628</td>\n",
       "      <td>0.766150</td>\n",
       "      <td>0.717440</td>\n",
       "      <td>0.751263</td>\n",
       "      <td>0.827865</td>\n",
       "      <td>0.787706</td>\n",
       "      <td>0.774810</td>\n",
       "      <td>0.848129</td>\n",
       "      <td>0.726744</td>\n",
       "      <td>0.794091</td>\n",
       "      <td>0.750390</td>\n",
       "      <td>0.771622</td>\n",
       "      <td>0.792020</td>\n",
       "      <td>0.857792</td>\n",
       "      <td>0.755003</td>\n",
       "      <td>0.755550</td>\n",
       "      <td>0.633001</td>\n",
       "      <td>0.688867</td>\n",
       "      <td>0.809919</td>\n",
       "      <td>0.762785</td>\n",
       "      <td>0.755257</td>\n",
       "      <td>0.682845</td>\n",
       "      <td>0.340686</td>\n",
       "      <td>0.454575</td>\n",
       "      <td>0.692429</td>\n",
       "      <td>0.521701</td>\n",
       "      <td>0.679268</td>\n",
       "      <td>0.696799</td>\n",
       "      <td>0.541195</td>\n",
       "      <td>0.609218</td>\n",
       "      <td>0.713254</td>\n",
       "      <td>0.678961</td>\n",
       "      <td>0.869684</td>\n",
       "      <td>0.681501</td>\n",
       "      <td>0.323574</td>\n",
       "      <td>0.438805</td>\n",
       "      <td>0.770605</td>\n",
       "      <td>0.469190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_length  valid_length  test_length  tgc_accuracy  tgc_precision  \\\n",
       "0        74769.0       32044.0      45734.0      0.725230       0.765263   \n",
       "1        74602.0       31973.0      45972.0      0.727444       0.780433   \n",
       "2        74182.0       31793.0      46572.0      0.735526       0.792204   \n",
       "3        74783.0       32051.0      45713.0      0.736316       0.779788   \n",
       "4        74405.0       31888.0      46254.0      0.730724       0.777509   \n",
       "5        74812.0       32063.0      45672.0      0.734475       0.790363   \n",
       "6        74771.0       32046.0      45730.0      0.728177       0.784866   \n",
       "7        74686.0       32009.0      45852.0      0.741732       0.816270   \n",
       "8        74628.0       31984.0      45935.0      0.727004       0.797992   \n",
       "9        74612.0       31977.0      45958.0      0.728736       0.816531   \n",
       "10       75218.0       32237.0      45092.0      0.732903       0.787021   \n",
       "11       75644.0       32420.0      44483.0      0.728596       0.802341   \n",
       "12       74930.0       32113.0      45504.0      0.737133       0.797863   \n",
       "13       74930.0       32114.0      45503.0      0.721566       0.755784   \n",
       "14       74422.0       31896.0      46229.0      0.737130       0.799960   \n",
       "15       74554.0       31952.0      46041.0      0.732264       0.809455   \n",
       "16       74921.0       32110.0      45516.0      0.727219       0.785845   \n",
       "17       74595.0       31970.0      45982.0      0.730648       0.797784   \n",
       "18       74894.0       32098.0      45555.0      0.730136       0.782509   \n",
       "19       75020.0       32152.0      45375.0      0.730187       0.796642   \n",
       "20       74561.0       31956.0      46030.0      0.730024       0.806607   \n",
       "21       75352.0       32295.0      44900.0      0.729424       0.794971   \n",
       "22       74791.0       32054.0      45702.0      0.726092       0.765136   \n",
       "23       74766.0       32043.0      45738.0      0.739528       0.827624   \n",
       "24       74617.0       31980.0      45950.0      0.737431       0.810535   \n",
       "25       74348.0       31864.0      46335.0      0.737132       0.816068   \n",
       "26       74657.0       31997.0      45893.0      0.737187       0.794691   \n",
       "27       74777.0       32048.0      45722.0      0.731057       0.786970   \n",
       "28       74986.0       32138.0      45423.0      0.725982       0.778267   \n",
       "29       74314.0       31849.0      46384.0      0.732988       0.792166   \n",
       "\n",
       "    tgc_recall    tgc_f1   tgc_auc   tgc_prc  m_accuracy  m_precision  \\\n",
       "0     0.837800  0.799890  0.787206  0.871580    0.735114     0.741921   \n",
       "1     0.815493  0.797578  0.790523  0.877775    0.733549     0.752680   \n",
       "2     0.821153  0.806419  0.793667  0.884395    0.736284     0.745905   \n",
       "3     0.839793  0.808679  0.793986  0.878222    0.729117     0.761949   \n",
       "4     0.833783  0.804663  0.789688  0.879033    0.734134     0.758179   \n",
       "5     0.818075  0.803980  0.794105  0.881808    0.736081     0.763798   \n",
       "6     0.811771  0.798092  0.791264  0.879917    0.733608     0.752681   \n",
       "7     0.792151  0.804030  0.799379  0.887484    0.738726     0.756384   \n",
       "8     0.788957  0.793449  0.786798  0.875618    0.737646     0.763538   \n",
       "9     0.761822  0.788228  0.790608  0.878475    0.740260     0.760066   \n",
       "10    0.822524  0.804381  0.789054  0.878937    0.731467     0.740986   \n",
       "11    0.783575  0.792847  0.787058  0.874431    0.717457     0.771935   \n",
       "12    0.814369  0.806032  0.794764  0.883517    0.745830     0.773734   \n",
       "13    0.848432  0.799433  0.785138  0.867922    0.734282     0.763465   \n",
       "14    0.808727  0.804320  0.794766  0.884322    0.737959     0.756838   \n",
       "15    0.776661  0.792719  0.791856  0.879088    0.730561     0.754551   \n",
       "16    0.807939  0.796739  0.786641  0.874877    0.734409     0.757215   \n",
       "17    0.797057  0.797420  0.787263  0.875697    0.733910     0.757472   \n",
       "18    0.817097  0.799429  0.790604  0.878243    0.739775     0.754993   \n",
       "19    0.796395  0.796518  0.788921  0.876712    0.733814     0.747961   \n",
       "20    0.784070  0.795179  0.788240  0.880008    0.737723     0.780600   \n",
       "21    0.794298  0.794634  0.789501  0.876203    0.738645     0.753476   \n",
       "22    0.847133  0.804049  0.791196  0.880492    0.733084     0.744954   \n",
       "23    0.771951  0.798819  0.799406  0.888325    0.733242     0.739583   \n",
       "24    0.790137  0.800206  0.795210  0.880505    0.735479     0.770572   \n",
       "25    0.781024  0.798162  0.793544  0.881476    0.742848     0.753944   \n",
       "26    0.817929  0.806143  0.794798  0.882761    0.730976     0.757097   \n",
       "27    0.811423  0.799009  0.792742  0.879288    0.734552     0.765306   \n",
       "28    0.814596  0.796017  0.786241  0.873664    0.733828     0.757282   \n",
       "29    0.817373  0.804572  0.788640  0.882478    0.735976     0.749380   \n",
       "\n",
       "    m_recall      m_f1     m_auc     m_prc  fgc_accuracy  fgc_precision  \\\n",
       "0   0.969663  0.840640  0.759956  0.884111      0.735437       0.738109   \n",
       "1   0.941815  0.836692  0.763202  0.893957      0.736775       0.745318   \n",
       "2   0.963600  0.840891  0.762210  0.889334      0.733491       0.749466   \n",
       "3   0.908655  0.828861  0.754729  0.886837      0.730453       0.748242   \n",
       "4   0.930660  0.835612  0.757053  0.889833      0.731968       0.762143   \n",
       "5   0.917492  0.833620  0.760797  0.880527      0.737281       0.771355   \n",
       "6   0.935846  0.834329  0.759987  0.884667      0.736918       0.763825   \n",
       "7   0.945197  0.840315  0.759081  0.892065      0.732650       0.743245   \n",
       "8   0.924457  0.836327  0.765133  0.890853      0.734747       0.758407   \n",
       "9   0.937056  0.839332  0.765188  0.889376      0.732351       0.771784   \n",
       "10  0.963985  0.837902  0.759005  0.887357      0.737048       0.774384   \n",
       "11  0.860231  0.813695  0.748180  0.884975      0.732728       0.751050   \n",
       "12  0.921320  0.841102  0.763578  0.892177      0.734484       0.775002   \n",
       "13  0.912700  0.831439  0.759725  0.884455      0.734495       0.766898   \n",
       "14  0.943063  0.839750  0.758284  0.889051      0.734273       0.772817   \n",
       "15  0.927860  0.832279  0.755301  0.884825      0.734424       0.752448   \n",
       "16  0.928809  0.834280  0.759626  0.888731      0.735942       0.762835   \n",
       "17  0.927286  0.833821  0.761232  0.888291      0.732201       0.738800   \n",
       "18  0.949876  0.841296  0.756856  0.886645      0.736225       0.759604   \n",
       "19  0.949829  0.836894  0.745687  0.882509      0.725863       0.749725   \n",
       "20  0.887143  0.830468  0.763511  0.889929      0.740729       0.765510   \n",
       "21  0.949388  0.840162  0.761229  0.888852      0.732710       0.741063   \n",
       "22  0.958992  0.838530  0.765673  0.891684      0.735534       0.779214   \n",
       "23  0.973526  0.840581  0.763458  0.889637      0.741456       0.765276   \n",
       "24  0.903279  0.831665  0.762560  0.889922      0.734053       0.757586   \n",
       "25  0.961783  0.845275  0.767387  0.893791      0.734973       0.764351   \n",
       "26  0.919955  0.830618  0.761943  0.889007      0.733485       0.766115   \n",
       "27  0.912625  0.832498  0.757796  0.886734      0.730337       0.735432   \n",
       "28  0.927592  0.833830  0.756293  0.881178      0.734953       0.756610   \n",
       "29  0.949892  0.837806  0.764339  0.887006      0.733626       0.766747   \n",
       "\n",
       "    fgc_recall    fgc_f1   fgc_auc   fgc_prc  f_accuracy  f_precision  \\\n",
       "0     0.651374  0.692035  0.785744  0.754571    0.704631     0.732449   \n",
       "1     0.645437  0.691791  0.784149  0.758504    0.715456     0.761656   \n",
       "2     0.648023  0.695063  0.786833  0.763719    0.718724     0.758949   \n",
       "3     0.614796  0.674987  0.778835  0.743494    0.713253     0.753678   \n",
       "4     0.610714  0.678077  0.780341  0.756185    0.716564     0.763850   \n",
       "5     0.617980  0.686202  0.786316  0.754975    0.711377     0.782607   \n",
       "6     0.627125  0.688758  0.786646  0.757760    0.686135     0.726675   \n",
       "7     0.666046  0.702531  0.790763  0.767154    0.719996     0.767995   \n",
       "8     0.626439  0.686135  0.789491  0.765745    0.715890     0.745570   \n",
       "9     0.592620  0.670439  0.780573  0.755102    0.717211     0.788441   \n",
       "10    0.608109  0.681248  0.788594  0.764155    0.716340     0.762591   \n",
       "11    0.636054  0.688785  0.782632  0.754535    0.710985     0.763414   \n",
       "12    0.620370  0.689118  0.788125  0.764983    0.715180     0.782048   \n",
       "13    0.602314  0.674714  0.785662  0.753361    0.712845     0.778902   \n",
       "14    0.616997  0.686172  0.789982  0.762773    0.714980     0.775120   \n",
       "15    0.640819  0.692162  0.786533  0.760621    0.715843     0.765214   \n",
       "16    0.614232  0.680516  0.785960  0.756703    0.714808     0.770084   \n",
       "17    0.642056  0.687039  0.783288  0.751934    0.710758     0.764779   \n",
       "18    0.623714  0.684984  0.785350  0.758581    0.714373     0.766730   \n",
       "19    0.607538  0.671184  0.778041  0.750366    0.707612     0.768706   \n",
       "20    0.628523  0.690286  0.792270  0.761403    0.714359     0.767468   \n",
       "21    0.636864  0.685024  0.785336  0.753547    0.715200     0.783354   \n",
       "22    0.612272  0.685728  0.788030  0.768638    0.716297     0.761848   \n",
       "23    0.648273  0.701933  0.791218  0.768117    0.716414     0.770703   \n",
       "24    0.636285  0.691658  0.787872  0.764149    0.714718     0.751042   \n",
       "25    0.620164  0.684749  0.788063  0.755629    0.715095     0.780475   \n",
       "26    0.617427  0.683781  0.786721  0.758035    0.719943     0.763719   \n",
       "27    0.652843  0.691681  0.778003  0.748462    0.714105     0.759461   \n",
       "28    0.625578  0.684883  0.788249  0.761695    0.707124     0.766843   \n",
       "29    0.627466  0.690150  0.786628  0.766150    0.717440     0.751263   \n",
       "\n",
       "    f_recall      f_f1     f_auc     f_prc  cp_accuracy  cp_precision  \\\n",
       "0   0.830941  0.778593  0.762033  0.828507     0.729167      0.791395   \n",
       "1   0.795455  0.778189  0.773543  0.846373     0.727012      0.784068   \n",
       "2   0.815652  0.786280  0.772986  0.849616     0.733344      0.790064   \n",
       "3   0.806801  0.779335  0.767529  0.838672     0.729871      0.793132   \n",
       "4   0.798952  0.781007  0.770743  0.842904     0.727028      0.784729   \n",
       "5   0.751321  0.766645  0.771600  0.844732     0.730842      0.800727   \n",
       "6   0.799058  0.761150  0.754433  0.831951     0.729964      0.806740   \n",
       "7   0.801843  0.784554  0.775044  0.846737     0.728367      0.801166   \n",
       "8   0.835668  0.788052  0.775940  0.848104     0.726422      0.827173   \n",
       "9   0.756360  0.772067  0.773351  0.845948     0.721720      0.755271   \n",
       "10  0.797159  0.779492  0.770203  0.843298     0.723898      0.788858   \n",
       "11  0.777432  0.770359  0.764784  0.836830     0.724027      0.777814   \n",
       "12  0.762357  0.772077  0.767297  0.842053     0.726163      0.774941   \n",
       "13  0.753481  0.765981  0.771134  0.841359     0.724613      0.778498   \n",
       "14  0.776100  0.775610  0.769893  0.845650     0.728438      0.795632   \n",
       "15  0.792179  0.778463  0.770635  0.842841     0.722614      0.783668   \n",
       "16  0.778277  0.774159  0.772021  0.843515     0.725393      0.779956   \n",
       "17  0.785235  0.774872  0.764419  0.838123     0.727543      0.792740   \n",
       "18  0.781914  0.774248  0.769552  0.841741     0.722959      0.780231   \n",
       "19  0.764655  0.766675  0.765113  0.839838     0.725211      0.787672   \n",
       "20  0.784376  0.775830  0.769765  0.842684     0.728197      0.787895   \n",
       "21  0.757138  0.770023  0.774051  0.847261     0.718922      0.806408   \n",
       "22  0.800407  0.780652  0.771465  0.844584     0.727238      0.774392   \n",
       "23  0.785239  0.777903  0.771179  0.843130     0.734331      0.790370   \n",
       "24  0.819164  0.783625  0.772354  0.846416     0.727664      0.792633   \n",
       "25  0.762351  0.771307  0.771012  0.841777     0.731461      0.803635   \n",
       "26  0.806575  0.784562  0.776514  0.849074     0.724977      0.805164   \n",
       "27  0.802705  0.780484  0.770200  0.843287     0.720159      0.758482   \n",
       "28  0.763062  0.764947  0.766478  0.836439     0.723568      0.786429   \n",
       "29  0.827865  0.787706  0.774810  0.848129     0.726744      0.794091   \n",
       "\n",
       "    cp_recall     cp_f1    cp_auc    cp_prc  c_accuracy  c_precision  \\\n",
       "0    0.749039  0.769635  0.791235  0.851700    0.753475     0.736937   \n",
       "1    0.756943  0.770267  0.788682  0.848994    0.754852     0.760970   \n",
       "2    0.774229  0.782066  0.795943  0.856260    0.750080     0.761897   \n",
       "3    0.751878  0.771954  0.792918  0.852970    0.752537     0.759684   \n",
       "4    0.764444  0.774454  0.790862  0.855731    0.753478     0.759963   \n",
       "5    0.743499  0.771053  0.794125  0.853367    0.751550     0.755165   \n",
       "6    0.731746  0.767415  0.793578  0.854797    0.753113     0.765637   \n",
       "7    0.745827  0.772507  0.793012  0.855776    0.746436     0.755539   \n",
       "8    0.693993  0.754753  0.793759  0.854304    0.754104     0.759251   \n",
       "9    0.803971  0.778860  0.788532  0.853834    0.748555     0.750812   \n",
       "10   0.743195  0.765346  0.785860  0.846798    0.749508     0.744472   \n",
       "11   0.762803  0.770236  0.787711  0.850405    0.750987     0.746733   \n",
       "12   0.782129  0.778519  0.790739  0.854278    0.754397     0.768658   \n",
       "13   0.757858  0.768039  0.788248  0.844765    0.751249     0.753711   \n",
       "14   0.750089  0.772190  0.792730  0.858375    0.755235     0.756515   \n",
       "15   0.749974  0.766451  0.785169  0.846773    0.746125     0.737607   \n",
       "16   0.759385  0.769533  0.790039  0.852158    0.755069     0.749891   \n",
       "17   0.750460  0.771021  0.788032  0.849035    0.753487     0.747104   \n",
       "18   0.752046  0.765880  0.786812  0.849679    0.751993     0.743656   \n",
       "19   0.746613  0.766593  0.789667  0.849113    0.752691     0.749036   \n",
       "20   0.761944  0.774702  0.794383  0.856791    0.757735     0.777198   \n",
       "21   0.701812  0.750483  0.785736  0.845924    0.756782     0.756824   \n",
       "22   0.779426  0.776901  0.791160  0.853713    0.757890     0.767175   \n",
       "23   0.772168  0.781163  0.794361  0.853396    0.755716     0.756036   \n",
       "24   0.748943  0.770169  0.792710  0.851986    0.756781     0.746332   \n",
       "25   0.744253  0.772805  0.794074  0.853770    0.751055     0.766845   \n",
       "26   0.727477  0.764352  0.789200  0.853828    0.754153     0.750598   \n",
       "27   0.789354  0.773610  0.787675  0.848784    0.750874     0.747043   \n",
       "28   0.742188  0.763668  0.789380  0.847395    0.755547     0.744797   \n",
       "29   0.750390  0.771622  0.792020  0.857792    0.755003     0.755550   \n",
       "\n",
       "    c_recall      c_f1     c_auc     c_prc  a_accuracy  a_precision  a_recall  \\\n",
       "0   0.641677  0.686016  0.803421  0.744071    0.757683     0.694795  0.338087   \n",
       "1   0.612958  0.678991  0.803138  0.752631    0.754202     0.680672  0.318741   \n",
       "2   0.618267  0.682609  0.802266  0.757981    0.757534     0.667937  0.343291   \n",
       "3   0.594628  0.667098  0.799938  0.743516    0.761964     0.680719  0.260858   \n",
       "4   0.619776  0.682747  0.807151  0.762912    0.755352     0.685714  0.305549   \n",
       "5   0.607716  0.673465  0.802715  0.748137    0.750166     0.663352  0.242346   \n",
       "6   0.609966  0.678994  0.804189  0.758777    0.750782     0.683450  0.329251   \n",
       "7   0.621616  0.682066  0.801405  0.758948    0.743172     0.663403  0.325034   \n",
       "8   0.622615  0.684178  0.802823  0.758510    0.752219     0.671598  0.332114   \n",
       "9   0.613890  0.675482  0.798993  0.752178    0.755294     0.651549  0.301202   \n",
       "10  0.616899  0.674708  0.801343  0.754635    0.755692     0.666832  0.335411   \n",
       "11  0.619079  0.676940  0.799807  0.745437    0.756633     0.658525  0.352564   \n",
       "12  0.619850  0.686280  0.806063  0.761659    0.754879     0.641686  0.341731   \n",
       "13  0.604807  0.671098  0.802229  0.747038    0.745347     0.628917  0.289035   \n",
       "14  0.636954  0.691605  0.807604  0.763558    0.759701     0.668555  0.343689   \n",
       "15  0.625648  0.677030  0.794489  0.737171    0.760470     0.668163  0.363370   \n",
       "16  0.620972  0.679369  0.799844  0.750496    0.760353     0.674817  0.347345   \n",
       "17  0.635222  0.686635  0.803718  0.757043    0.757452     0.685811  0.301709   \n",
       "18  0.631399  0.682946  0.800189  0.756382    0.766089     0.677327  0.355105   \n",
       "19  0.615667  0.675835  0.800947  0.749472    0.752850     0.656280  0.349334   \n",
       "20  0.602469  0.678769  0.809152  0.763213    0.759240     0.691411  0.290389   \n",
       "21  0.619225  0.681145  0.806103  0.755511    0.751975     0.665829  0.332247   \n",
       "22  0.626951  0.690011  0.809554  0.763373    0.752931     0.662298  0.323805   \n",
       "23  0.643340  0.695150  0.806644  0.761338    0.763445     0.658876  0.336465   \n",
       "24  0.650292  0.695010  0.807731  0.759995    0.758053     0.671926  0.307827   \n",
       "25  0.603916  0.675698  0.802460  0.753985    0.752347     0.683202  0.295178   \n",
       "26  0.634140  0.687472  0.803973  0.748624    0.758166     0.698860  0.293821   \n",
       "27  0.623845  0.679909  0.801668  0.752328    0.764378     0.655483  0.334355   \n",
       "28  0.631518  0.683496  0.803866  0.752405    0.755621     0.673130  0.359645   \n",
       "29  0.633001  0.688867  0.809919  0.762785    0.755257     0.682845  0.340686   \n",
       "\n",
       "        a_f1     a_auc     a_prc  ag_accuracy  ag_precision  ag_recall  \\\n",
       "0   0.454846  0.688312  0.526606     0.679072      0.728596   0.484586   \n",
       "1   0.434171  0.683314  0.511012     0.678509      0.698350   0.538551   \n",
       "2   0.453502  0.694978  0.512855     0.678014      0.702219   0.530027   \n",
       "3   0.377178  0.684034  0.497936     0.680007      0.714359   0.503399   \n",
       "4   0.422732  0.696623  0.523517     0.680694      0.715769   0.523094   \n",
       "5   0.354998  0.682911  0.494781     0.682485      0.715461   0.525923   \n",
       "6   0.444408  0.679258  0.520388     0.681899      0.723718   0.514065   \n",
       "7   0.436302  0.688114  0.513202     0.678623      0.694962   0.553876   \n",
       "8   0.444444  0.689850  0.516263     0.681406      0.705600   0.536459   \n",
       "9   0.411960  0.690604  0.496026     0.679007      0.706258   0.527313   \n",
       "10  0.446325  0.685715  0.514105     0.679663      0.720581   0.499145   \n",
       "11  0.459252  0.694662  0.516777     0.677775      0.705365   0.519222   \n",
       "12  0.445964  0.681837  0.493857     0.672856      0.703631   0.511074   \n",
       "13  0.396053  0.686535  0.480217     0.674298      0.685075   0.523506   \n",
       "14  0.453992  0.683440  0.510202     0.676327      0.706876   0.523091   \n",
       "15  0.470737  0.692136  0.513580     0.678048      0.695621   0.542703   \n",
       "16  0.458624  0.693337  0.510968     0.683620      0.711091   0.527963   \n",
       "17  0.419061  0.693021  0.518514     0.677522      0.713723   0.505530   \n",
       "18  0.465933  0.688374  0.510706     0.675870      0.696020   0.541584   \n",
       "19  0.455962  0.679783  0.498366     0.675874      0.703961   0.516511   \n",
       "20  0.409000  0.703472  0.520959     0.674432      0.682485   0.553418   \n",
       "21  0.443292  0.683461  0.508516     0.678081      0.706298   0.519958   \n",
       "22  0.434955  0.684452  0.510978     0.672373      0.708476   0.504522   \n",
       "23  0.445453  0.693864  0.505028     0.682369      0.706076   0.537249   \n",
       "24  0.422222  0.691276  0.512985     0.682826      0.712780   0.537066   \n",
       "25  0.412245  0.696313  0.515276     0.676968      0.717295   0.502711   \n",
       "26  0.413707  0.692416  0.523651     0.680692      0.693070   0.559799   \n",
       "27  0.442828  0.666895  0.489952     0.677863      0.697996   0.529806   \n",
       "28  0.468810  0.686998  0.518930     0.681567      0.708751   0.522170   \n",
       "29  0.454575  0.692429  0.521701     0.679268      0.696799   0.541195   \n",
       "\n",
       "       ag_f1    ag_auc    ag_prc  g_accuracy  g_precision  g_recall      g_f1  \\\n",
       "0   0.582052  0.706944  0.676271    0.864314     0.630664  0.348420  0.448860   \n",
       "1   0.608128  0.707125  0.670287    0.861431     0.686105  0.242001  0.357800   \n",
       "2   0.604092  0.701508  0.671614    0.866268     0.641493  0.375652  0.473833   \n",
       "3   0.590606  0.705549  0.668804    0.869723     0.716931  0.279094  0.401779   \n",
       "4   0.604449  0.708726  0.680491    0.859246     0.665750  0.290408  0.404408   \n",
       "5   0.606222  0.707620  0.675374    0.863789     0.658698  0.324480  0.434783   \n",
       "6   0.601136  0.714216  0.684796    0.867196     0.647429  0.297453  0.407627   \n",
       "7   0.616450  0.713455  0.678997    0.861917     0.673725  0.335249  0.447713   \n",
       "8   0.609513  0.712243  0.677450    0.869786     0.656045  0.376409  0.478358   \n",
       "9   0.603806  0.708683  0.674905    0.868149     0.661654  0.371492  0.475827   \n",
       "10  0.589762  0.707880  0.670312    0.867398     0.672561  0.305757  0.420396   \n",
       "11  0.598146  0.708830  0.674389    0.873489     0.646910  0.353250  0.456969   \n",
       "12  0.592090  0.706760  0.667254    0.862740     0.676247  0.309122  0.424294   \n",
       "13  0.593491  0.704093  0.664478    0.860518     0.666440  0.247665  0.361126   \n",
       "14  0.601252  0.707007  0.672156    0.860032     0.656818  0.344130  0.451633   \n",
       "15  0.609720  0.710702  0.675677    0.867364     0.642298  0.368631  0.468423   \n",
       "16  0.605994  0.707307  0.677400    0.867968     0.671967  0.294300  0.409327   \n",
       "17  0.591851  0.706861  0.671550    0.869139     0.664642  0.381189  0.484503   \n",
       "18  0.609167  0.705917  0.674768    0.859961     0.656233  0.290235  0.402468   \n",
       "19  0.595841  0.704866  0.671265    0.866601     0.654567  0.296081  0.407732   \n",
       "20  0.611212  0.708835  0.675194    0.865088     0.641453  0.373662  0.472235   \n",
       "21  0.598970  0.708890  0.671901    0.863440     0.624786  0.372730  0.466912   \n",
       "22  0.589352  0.707427  0.676848    0.870485     0.657724  0.365083  0.469539   \n",
       "23  0.610200  0.709901  0.678174    0.862646     0.668027  0.320921  0.433559   \n",
       "24  0.612571  0.714001  0.688501    0.865306     0.664968  0.353710  0.461786   \n",
       "25  0.591132  0.707208  0.676938    0.866245     0.633258  0.354287  0.454370   \n",
       "26  0.619347  0.713650  0.678552    0.865838     0.679417  0.285678  0.402229   \n",
       "27  0.602382  0.707716  0.673490    0.867065     0.667967  0.340204  0.450806   \n",
       "28  0.601320  0.710613  0.678946    0.869590     0.671727  0.281250  0.396491   \n",
       "29  0.609218  0.713254  0.678961    0.869684     0.681501  0.323574  0.438805   \n",
       "\n",
       "       g_auc     g_prc  \n",
       "0   0.764959  0.449019  \n",
       "1   0.773070  0.464832  \n",
       "2   0.768326  0.449910  \n",
       "3   0.772691  0.486454  \n",
       "4   0.768229  0.461252  \n",
       "5   0.765953  0.466862  \n",
       "6   0.770839  0.446102  \n",
       "7   0.771857  0.475611  \n",
       "8   0.765534  0.468417  \n",
       "9   0.769348  0.476570  \n",
       "10  0.772696  0.469958  \n",
       "11  0.768078  0.464389  \n",
       "12  0.780644  0.480358  \n",
       "13  0.766323  0.455717  \n",
       "14  0.772360  0.472442  \n",
       "15  0.775991  0.464644  \n",
       "16  0.774827  0.465755  \n",
       "17  0.780263  0.483135  \n",
       "18  0.762168  0.459444  \n",
       "19  0.763730  0.445584  \n",
       "20  0.776414  0.477240  \n",
       "21  0.761321  0.448823  \n",
       "22  0.773036  0.467351  \n",
       "23  0.763963  0.472847  \n",
       "24  0.775298  0.476396  \n",
       "25  0.773616  0.456566  \n",
       "26  0.759455  0.465908  \n",
       "27  0.772393  0.478627  \n",
       "28  0.779357  0.471373  \n",
       "29  0.770605  0.469190  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ba17b1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_length</th>\n",
       "      <th>valid_length</th>\n",
       "      <th>test_length</th>\n",
       "      <th>tgc_accuracy</th>\n",
       "      <th>tgc_precision</th>\n",
       "      <th>tgc_recall</th>\n",
       "      <th>tgc_f1</th>\n",
       "      <th>tgc_auc</th>\n",
       "      <th>tgc_prc</th>\n",
       "      <th>m_accuracy</th>\n",
       "      <th>m_precision</th>\n",
       "      <th>m_recall</th>\n",
       "      <th>m_f1</th>\n",
       "      <th>m_auc</th>\n",
       "      <th>m_prc</th>\n",
       "      <th>fgc_accuracy</th>\n",
       "      <th>fgc_precision</th>\n",
       "      <th>fgc_recall</th>\n",
       "      <th>fgc_f1</th>\n",
       "      <th>fgc_auc</th>\n",
       "      <th>fgc_prc</th>\n",
       "      <th>f_accuracy</th>\n",
       "      <th>f_precision</th>\n",
       "      <th>f_recall</th>\n",
       "      <th>f_f1</th>\n",
       "      <th>f_auc</th>\n",
       "      <th>f_prc</th>\n",
       "      <th>cp_accuracy</th>\n",
       "      <th>cp_precision</th>\n",
       "      <th>cp_recall</th>\n",
       "      <th>cp_f1</th>\n",
       "      <th>cp_auc</th>\n",
       "      <th>cp_prc</th>\n",
       "      <th>c_accuracy</th>\n",
       "      <th>c_precision</th>\n",
       "      <th>c_recall</th>\n",
       "      <th>c_f1</th>\n",
       "      <th>c_auc</th>\n",
       "      <th>c_prc</th>\n",
       "      <th>a_accuracy</th>\n",
       "      <th>a_precision</th>\n",
       "      <th>a_recall</th>\n",
       "      <th>a_f1</th>\n",
       "      <th>a_auc</th>\n",
       "      <th>a_prc</th>\n",
       "      <th>ag_accuracy</th>\n",
       "      <th>ag_precision</th>\n",
       "      <th>ag_recall</th>\n",
       "      <th>ag_f1</th>\n",
       "      <th>ag_auc</th>\n",
       "      <th>ag_prc</th>\n",
       "      <th>g_accuracy</th>\n",
       "      <th>g_precision</th>\n",
       "      <th>g_recall</th>\n",
       "      <th>g_f1</th>\n",
       "      <th>g_auc</th>\n",
       "      <th>g_prc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.719821</td>\n",
       "      <td>0.746960</td>\n",
       "      <td>0.871706</td>\n",
       "      <td>0.804526</td>\n",
       "      <td>0.785253</td>\n",
       "      <td>0.874994</td>\n",
       "      <td>0.750323</td>\n",
       "      <td>0.754468</td>\n",
       "      <td>0.977146</td>\n",
       "      <td>0.851489</td>\n",
       "      <td>0.786185</td>\n",
       "      <td>0.908954</td>\n",
       "      <td>0.719914</td>\n",
       "      <td>0.737819</td>\n",
       "      <td>0.598875</td>\n",
       "      <td>0.661126</td>\n",
       "      <td>0.760872</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.695417</td>\n",
       "      <td>0.714103</td>\n",
       "      <td>0.801758</td>\n",
       "      <td>0.755396</td>\n",
       "      <td>0.768299</td>\n",
       "      <td>0.821994</td>\n",
       "      <td>0.725855</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.735198</td>\n",
       "      <td>0.766989</td>\n",
       "      <td>0.789669</td>\n",
       "      <td>0.853608</td>\n",
       "      <td>0.757221</td>\n",
       "      <td>0.733034</td>\n",
       "      <td>0.636919</td>\n",
       "      <td>0.681605</td>\n",
       "      <td>0.800321</td>\n",
       "      <td>0.738993</td>\n",
       "      <td>0.838238</td>\n",
       "      <td>0.668394</td>\n",
       "      <td>0.192633</td>\n",
       "      <td>0.299073</td>\n",
       "      <td>0.634375</td>\n",
       "      <td>0.375421</td>\n",
       "      <td>0.727695</td>\n",
       "      <td>0.719218</td>\n",
       "      <td>0.487455</td>\n",
       "      <td>0.581079</td>\n",
       "      <td>0.723755</td>\n",
       "      <td>0.641046</td>\n",
       "      <td>0.893874</td>\n",
       "      <td>0.715818</td>\n",
       "      <td>0.408361</td>\n",
       "      <td>0.520045</td>\n",
       "      <td>0.789589</td>\n",
       "      <td>0.498379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724080</td>\n",
       "      <td>0.788511</td>\n",
       "      <td>0.796471</td>\n",
       "      <td>0.792471</td>\n",
       "      <td>0.784656</td>\n",
       "      <td>0.874147</td>\n",
       "      <td>0.749389</td>\n",
       "      <td>0.775306</td>\n",
       "      <td>0.926336</td>\n",
       "      <td>0.844119</td>\n",
       "      <td>0.779028</td>\n",
       "      <td>0.906598</td>\n",
       "      <td>0.723114</td>\n",
       "      <td>0.751704</td>\n",
       "      <td>0.586962</td>\n",
       "      <td>0.659196</td>\n",
       "      <td>0.761648</td>\n",
       "      <td>0.734090</td>\n",
       "      <td>0.703483</td>\n",
       "      <td>0.738206</td>\n",
       "      <td>0.766262</td>\n",
       "      <td>0.751972</td>\n",
       "      <td>0.771118</td>\n",
       "      <td>0.826157</td>\n",
       "      <td>0.722802</td>\n",
       "      <td>0.779945</td>\n",
       "      <td>0.763826</td>\n",
       "      <td>0.771801</td>\n",
       "      <td>0.789207</td>\n",
       "      <td>0.854373</td>\n",
       "      <td>0.758953</td>\n",
       "      <td>0.765709</td>\n",
       "      <td>0.589610</td>\n",
       "      <td>0.666219</td>\n",
       "      <td>0.799139</td>\n",
       "      <td>0.742328</td>\n",
       "      <td>0.842964</td>\n",
       "      <td>0.680758</td>\n",
       "      <td>0.232454</td>\n",
       "      <td>0.346568</td>\n",
       "      <td>0.666707</td>\n",
       "      <td>0.387560</td>\n",
       "      <td>0.723089</td>\n",
       "      <td>0.688836</td>\n",
       "      <td>0.520290</td>\n",
       "      <td>0.592816</td>\n",
       "      <td>0.725792</td>\n",
       "      <td>0.633825</td>\n",
       "      <td>0.885655</td>\n",
       "      <td>0.725382</td>\n",
       "      <td>0.302320</td>\n",
       "      <td>0.426772</td>\n",
       "      <td>0.800713</td>\n",
       "      <td>0.514411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.721293</td>\n",
       "      <td>0.777304</td>\n",
       "      <td>0.810977</td>\n",
       "      <td>0.793784</td>\n",
       "      <td>0.782018</td>\n",
       "      <td>0.873437</td>\n",
       "      <td>0.745438</td>\n",
       "      <td>0.757690</td>\n",
       "      <td>0.959245</td>\n",
       "      <td>0.846637</td>\n",
       "      <td>0.780428</td>\n",
       "      <td>0.908242</td>\n",
       "      <td>0.719859</td>\n",
       "      <td>0.753778</td>\n",
       "      <td>0.573174</td>\n",
       "      <td>0.651185</td>\n",
       "      <td>0.761616</td>\n",
       "      <td>0.733414</td>\n",
       "      <td>0.698615</td>\n",
       "      <td>0.725422</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.752807</td>\n",
       "      <td>0.768515</td>\n",
       "      <td>0.823853</td>\n",
       "      <td>0.725409</td>\n",
       "      <td>0.780917</td>\n",
       "      <td>0.768036</td>\n",
       "      <td>0.774423</td>\n",
       "      <td>0.791711</td>\n",
       "      <td>0.855099</td>\n",
       "      <td>0.754196</td>\n",
       "      <td>0.766240</td>\n",
       "      <td>0.572067</td>\n",
       "      <td>0.655067</td>\n",
       "      <td>0.792440</td>\n",
       "      <td>0.738661</td>\n",
       "      <td>0.837346</td>\n",
       "      <td>0.633478</td>\n",
       "      <td>0.218517</td>\n",
       "      <td>0.324944</td>\n",
       "      <td>0.652311</td>\n",
       "      <td>0.356423</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.703709</td>\n",
       "      <td>0.510145</td>\n",
       "      <td>0.591494</td>\n",
       "      <td>0.716615</td>\n",
       "      <td>0.636417</td>\n",
       "      <td>0.896099</td>\n",
       "      <td>0.707258</td>\n",
       "      <td>0.447107</td>\n",
       "      <td>0.547868</td>\n",
       "      <td>0.790840</td>\n",
       "      <td>0.504006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722818</td>\n",
       "      <td>0.765542</td>\n",
       "      <td>0.837407</td>\n",
       "      <td>0.799863</td>\n",
       "      <td>0.784979</td>\n",
       "      <td>0.874011</td>\n",
       "      <td>0.750503</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>0.914762</td>\n",
       "      <td>0.843047</td>\n",
       "      <td>0.785348</td>\n",
       "      <td>0.909763</td>\n",
       "      <td>0.722562</td>\n",
       "      <td>0.754797</td>\n",
       "      <td>0.580431</td>\n",
       "      <td>0.656229</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.728030</td>\n",
       "      <td>0.700789</td>\n",
       "      <td>0.728053</td>\n",
       "      <td>0.782035</td>\n",
       "      <td>0.754079</td>\n",
       "      <td>0.770336</td>\n",
       "      <td>0.826211</td>\n",
       "      <td>0.724610</td>\n",
       "      <td>0.781218</td>\n",
       "      <td>0.765701</td>\n",
       "      <td>0.773382</td>\n",
       "      <td>0.791062</td>\n",
       "      <td>0.856318</td>\n",
       "      <td>0.756644</td>\n",
       "      <td>0.765666</td>\n",
       "      <td>0.581518</td>\n",
       "      <td>0.661006</td>\n",
       "      <td>0.795701</td>\n",
       "      <td>0.737423</td>\n",
       "      <td>0.832085</td>\n",
       "      <td>0.649289</td>\n",
       "      <td>0.136386</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.683122</td>\n",
       "      <td>0.394668</td>\n",
       "      <td>0.728055</td>\n",
       "      <td>0.714532</td>\n",
       "      <td>0.496400</td>\n",
       "      <td>0.585820</td>\n",
       "      <td>0.729389</td>\n",
       "      <td>0.640742</td>\n",
       "      <td>0.888131</td>\n",
       "      <td>0.735673</td>\n",
       "      <td>0.320673</td>\n",
       "      <td>0.446654</td>\n",
       "      <td>0.801806</td>\n",
       "      <td>0.520040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.715694</td>\n",
       "      <td>0.743930</td>\n",
       "      <td>0.869441</td>\n",
       "      <td>0.801803</td>\n",
       "      <td>0.784762</td>\n",
       "      <td>0.874632</td>\n",
       "      <td>0.749389</td>\n",
       "      <td>0.782186</td>\n",
       "      <td>0.911770</td>\n",
       "      <td>0.842022</td>\n",
       "      <td>0.780463</td>\n",
       "      <td>0.904265</td>\n",
       "      <td>0.721073</td>\n",
       "      <td>0.760120</td>\n",
       "      <td>0.567791</td>\n",
       "      <td>0.650028</td>\n",
       "      <td>0.758775</td>\n",
       "      <td>0.734090</td>\n",
       "      <td>0.701795</td>\n",
       "      <td>0.731518</td>\n",
       "      <td>0.776706</td>\n",
       "      <td>0.753435</td>\n",
       "      <td>0.769457</td>\n",
       "      <td>0.822951</td>\n",
       "      <td>0.724516</td>\n",
       "      <td>0.802140</td>\n",
       "      <td>0.731563</td>\n",
       "      <td>0.765227</td>\n",
       "      <td>0.791149</td>\n",
       "      <td>0.857940</td>\n",
       "      <td>0.758883</td>\n",
       "      <td>0.761581</td>\n",
       "      <td>0.595439</td>\n",
       "      <td>0.668339</td>\n",
       "      <td>0.795673</td>\n",
       "      <td>0.741317</td>\n",
       "      <td>0.830212</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.131906</td>\n",
       "      <td>0.217749</td>\n",
       "      <td>0.668035</td>\n",
       "      <td>0.368827</td>\n",
       "      <td>0.727801</td>\n",
       "      <td>0.710362</td>\n",
       "      <td>0.502182</td>\n",
       "      <td>0.588401</td>\n",
       "      <td>0.728742</td>\n",
       "      <td>0.641627</td>\n",
       "      <td>0.885619</td>\n",
       "      <td>0.718268</td>\n",
       "      <td>0.308692</td>\n",
       "      <td>0.431806</td>\n",
       "      <td>0.784160</td>\n",
       "      <td>0.489967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.719637</td>\n",
       "      <td>0.759172</td>\n",
       "      <td>0.843806</td>\n",
       "      <td>0.799255</td>\n",
       "      <td>0.782554</td>\n",
       "      <td>0.871854</td>\n",
       "      <td>0.747988</td>\n",
       "      <td>0.796629</td>\n",
       "      <td>0.880824</td>\n",
       "      <td>0.836613</td>\n",
       "      <td>0.786007</td>\n",
       "      <td>0.907007</td>\n",
       "      <td>0.721845</td>\n",
       "      <td>0.773660</td>\n",
       "      <td>0.551705</td>\n",
       "      <td>0.644098</td>\n",
       "      <td>0.758697</td>\n",
       "      <td>0.726788</td>\n",
       "      <td>0.705783</td>\n",
       "      <td>0.761093</td>\n",
       "      <td>0.726479</td>\n",
       "      <td>0.743384</td>\n",
       "      <td>0.770469</td>\n",
       "      <td>0.824277</td>\n",
       "      <td>0.723271</td>\n",
       "      <td>0.798064</td>\n",
       "      <td>0.735084</td>\n",
       "      <td>0.765280</td>\n",
       "      <td>0.788811</td>\n",
       "      <td>0.853276</td>\n",
       "      <td>0.759553</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.598608</td>\n",
       "      <td>0.670130</td>\n",
       "      <td>0.797157</td>\n",
       "      <td>0.736921</td>\n",
       "      <td>0.832174</td>\n",
       "      <td>0.648712</td>\n",
       "      <td>0.137880</td>\n",
       "      <td>0.227422</td>\n",
       "      <td>0.690662</td>\n",
       "      <td>0.384192</td>\n",
       "      <td>0.728160</td>\n",
       "      <td>0.714040</td>\n",
       "      <td>0.497655</td>\n",
       "      <td>0.586526</td>\n",
       "      <td>0.729046</td>\n",
       "      <td>0.642184</td>\n",
       "      <td>0.893156</td>\n",
       "      <td>0.737688</td>\n",
       "      <td>0.374203</td>\n",
       "      <td>0.496533</td>\n",
       "      <td>0.798591</td>\n",
       "      <td>0.513350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722766</td>\n",
       "      <td>0.774131</td>\n",
       "      <td>0.820158</td>\n",
       "      <td>0.796480</td>\n",
       "      <td>0.783967</td>\n",
       "      <td>0.874857</td>\n",
       "      <td>0.749749</td>\n",
       "      <td>0.774722</td>\n",
       "      <td>0.928298</td>\n",
       "      <td>0.844585</td>\n",
       "      <td>0.784140</td>\n",
       "      <td>0.909781</td>\n",
       "      <td>0.723445</td>\n",
       "      <td>0.768603</td>\n",
       "      <td>0.563437</td>\n",
       "      <td>0.650220</td>\n",
       "      <td>0.760087</td>\n",
       "      <td>0.730832</td>\n",
       "      <td>0.670517</td>\n",
       "      <td>0.695220</td>\n",
       "      <td>0.780473</td>\n",
       "      <td>0.735384</td>\n",
       "      <td>0.753503</td>\n",
       "      <td>0.814659</td>\n",
       "      <td>0.724399</td>\n",
       "      <td>0.811945</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.761514</td>\n",
       "      <td>0.787588</td>\n",
       "      <td>0.854616</td>\n",
       "      <td>0.757937</td>\n",
       "      <td>0.762779</td>\n",
       "      <td>0.590289</td>\n",
       "      <td>0.665539</td>\n",
       "      <td>0.796941</td>\n",
       "      <td>0.742300</td>\n",
       "      <td>0.839576</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.205575</td>\n",
       "      <td>0.314667</td>\n",
       "      <td>0.670594</td>\n",
       "      <td>0.384964</td>\n",
       "      <td>0.726047</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>0.500927</td>\n",
       "      <td>0.586238</td>\n",
       "      <td>0.724761</td>\n",
       "      <td>0.635758</td>\n",
       "      <td>0.884722</td>\n",
       "      <td>0.701416</td>\n",
       "      <td>0.315575</td>\n",
       "      <td>0.435302</td>\n",
       "      <td>0.794709</td>\n",
       "      <td>0.489400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725683</td>\n",
       "      <td>0.800359</td>\n",
       "      <td>0.779778</td>\n",
       "      <td>0.789935</td>\n",
       "      <td>0.785866</td>\n",
       "      <td>0.874871</td>\n",
       "      <td>0.753233</td>\n",
       "      <td>0.770582</td>\n",
       "      <td>0.944237</td>\n",
       "      <td>0.848617</td>\n",
       "      <td>0.781369</td>\n",
       "      <td>0.907976</td>\n",
       "      <td>0.723225</td>\n",
       "      <td>0.748055</td>\n",
       "      <td>0.593070</td>\n",
       "      <td>0.661607</td>\n",
       "      <td>0.764403</td>\n",
       "      <td>0.734031</td>\n",
       "      <td>0.703501</td>\n",
       "      <td>0.741433</td>\n",
       "      <td>0.759372</td>\n",
       "      <td>0.750295</td>\n",
       "      <td>0.770899</td>\n",
       "      <td>0.825237</td>\n",
       "      <td>0.722966</td>\n",
       "      <td>0.792173</td>\n",
       "      <td>0.743695</td>\n",
       "      <td>0.767169</td>\n",
       "      <td>0.788512</td>\n",
       "      <td>0.851722</td>\n",
       "      <td>0.755605</td>\n",
       "      <td>0.758802</td>\n",
       "      <td>0.587856</td>\n",
       "      <td>0.662479</td>\n",
       "      <td>0.797550</td>\n",
       "      <td>0.740648</td>\n",
       "      <td>0.833155</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.158288</td>\n",
       "      <td>0.253690</td>\n",
       "      <td>0.672520</td>\n",
       "      <td>0.379256</td>\n",
       "      <td>0.725075</td>\n",
       "      <td>0.689305</td>\n",
       "      <td>0.528690</td>\n",
       "      <td>0.598407</td>\n",
       "      <td>0.732579</td>\n",
       "      <td>0.646612</td>\n",
       "      <td>0.888993</td>\n",
       "      <td>0.709384</td>\n",
       "      <td>0.358399</td>\n",
       "      <td>0.476207</td>\n",
       "      <td>0.796082</td>\n",
       "      <td>0.490775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.787919</td>\n",
       "      <td>0.803545</td>\n",
       "      <td>0.795655</td>\n",
       "      <td>0.785121</td>\n",
       "      <td>0.873695</td>\n",
       "      <td>0.752012</td>\n",
       "      <td>0.777293</td>\n",
       "      <td>0.927072</td>\n",
       "      <td>0.845602</td>\n",
       "      <td>0.785883</td>\n",
       "      <td>0.909319</td>\n",
       "      <td>0.725708</td>\n",
       "      <td>0.770423</td>\n",
       "      <td>0.568033</td>\n",
       "      <td>0.653926</td>\n",
       "      <td>0.764077</td>\n",
       "      <td>0.738023</td>\n",
       "      <td>0.690602</td>\n",
       "      <td>0.703401</td>\n",
       "      <td>0.817102</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.765808</td>\n",
       "      <td>0.821531</td>\n",
       "      <td>0.723929</td>\n",
       "      <td>0.826690</td>\n",
       "      <td>0.696085</td>\n",
       "      <td>0.755786</td>\n",
       "      <td>0.789825</td>\n",
       "      <td>0.854623</td>\n",
       "      <td>0.757383</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>0.582197</td>\n",
       "      <td>0.661948</td>\n",
       "      <td>0.796065</td>\n",
       "      <td>0.734826</td>\n",
       "      <td>0.842162</td>\n",
       "      <td>0.690590</td>\n",
       "      <td>0.215530</td>\n",
       "      <td>0.328528</td>\n",
       "      <td>0.661581</td>\n",
       "      <td>0.388873</td>\n",
       "      <td>0.722434</td>\n",
       "      <td>0.686197</td>\n",
       "      <td>0.522526</td>\n",
       "      <td>0.593281</td>\n",
       "      <td>0.726169</td>\n",
       "      <td>0.637051</td>\n",
       "      <td>0.894376</td>\n",
       "      <td>0.701646</td>\n",
       "      <td>0.434616</td>\n",
       "      <td>0.536754</td>\n",
       "      <td>0.790194</td>\n",
       "      <td>0.500981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725894</td>\n",
       "      <td>0.812214</td>\n",
       "      <td>0.761695</td>\n",
       "      <td>0.786144</td>\n",
       "      <td>0.785959</td>\n",
       "      <td>0.875957</td>\n",
       "      <td>0.752263</td>\n",
       "      <td>0.779194</td>\n",
       "      <td>0.923492</td>\n",
       "      <td>0.845228</td>\n",
       "      <td>0.786572</td>\n",
       "      <td>0.912221</td>\n",
       "      <td>0.727225</td>\n",
       "      <td>0.780762</td>\n",
       "      <td>0.559083</td>\n",
       "      <td>0.651584</td>\n",
       "      <td>0.761892</td>\n",
       "      <td>0.734803</td>\n",
       "      <td>0.703609</td>\n",
       "      <td>0.748324</td>\n",
       "      <td>0.745437</td>\n",
       "      <td>0.746878</td>\n",
       "      <td>0.770412</td>\n",
       "      <td>0.823441</td>\n",
       "      <td>0.721134</td>\n",
       "      <td>0.765376</td>\n",
       "      <td>0.786789</td>\n",
       "      <td>0.775935</td>\n",
       "      <td>0.786776</td>\n",
       "      <td>0.852319</td>\n",
       "      <td>0.756690</td>\n",
       "      <td>0.750932</td>\n",
       "      <td>0.603984</td>\n",
       "      <td>0.669489</td>\n",
       "      <td>0.798389</td>\n",
       "      <td>0.737658</td>\n",
       "      <td>0.829945</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.169238</td>\n",
       "      <td>0.262853</td>\n",
       "      <td>0.677786</td>\n",
       "      <td>0.368462</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.703729</td>\n",
       "      <td>0.508509</td>\n",
       "      <td>0.590400</td>\n",
       "      <td>0.726452</td>\n",
       "      <td>0.638917</td>\n",
       "      <td>0.894340</td>\n",
       "      <td>0.717459</td>\n",
       "      <td>0.411675</td>\n",
       "      <td>0.523162</td>\n",
       "      <td>0.795693</td>\n",
       "      <td>0.511690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720189</td>\n",
       "      <td>0.750786</td>\n",
       "      <td>0.863638</td>\n",
       "      <td>0.803268</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>0.872037</td>\n",
       "      <td>0.751293</td>\n",
       "      <td>0.762157</td>\n",
       "      <td>0.960078</td>\n",
       "      <td>0.849745</td>\n",
       "      <td>0.790853</td>\n",
       "      <td>0.912906</td>\n",
       "      <td>0.723776</td>\n",
       "      <td>0.780868</td>\n",
       "      <td>0.548440</td>\n",
       "      <td>0.644334</td>\n",
       "      <td>0.757847</td>\n",
       "      <td>0.733119</td>\n",
       "      <td>0.702495</td>\n",
       "      <td>0.732651</td>\n",
       "      <td>0.776001</td>\n",
       "      <td>0.753703</td>\n",
       "      <td>0.764784</td>\n",
       "      <td>0.819549</td>\n",
       "      <td>0.721839</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.728310</td>\n",
       "      <td>0.762680</td>\n",
       "      <td>0.787241</td>\n",
       "      <td>0.851336</td>\n",
       "      <td>0.757267</td>\n",
       "      <td>0.747169</td>\n",
       "      <td>0.612246</td>\n",
       "      <td>0.673012</td>\n",
       "      <td>0.798502</td>\n",
       "      <td>0.742321</td>\n",
       "      <td>0.840913</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.253858</td>\n",
       "      <td>0.363766</td>\n",
       "      <td>0.661131</td>\n",
       "      <td>0.382044</td>\n",
       "      <td>0.727907</td>\n",
       "      <td>0.712208</td>\n",
       "      <td>0.499564</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>0.728175</td>\n",
       "      <td>0.645727</td>\n",
       "      <td>0.884937</td>\n",
       "      <td>0.709527</td>\n",
       "      <td>0.309457</td>\n",
       "      <td>0.430955</td>\n",
       "      <td>0.796375</td>\n",
       "      <td>0.491784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.723291</td>\n",
       "      <td>0.787310</td>\n",
       "      <td>0.796948</td>\n",
       "      <td>0.792100</td>\n",
       "      <td>0.784187</td>\n",
       "      <td>0.874525</td>\n",
       "      <td>0.735846</td>\n",
       "      <td>0.799715</td>\n",
       "      <td>0.853016</td>\n",
       "      <td>0.825506</td>\n",
       "      <td>0.776320</td>\n",
       "      <td>0.907011</td>\n",
       "      <td>0.724908</td>\n",
       "      <td>0.751359</td>\n",
       "      <td>0.593372</td>\n",
       "      <td>0.663085</td>\n",
       "      <td>0.759460</td>\n",
       "      <td>0.726610</td>\n",
       "      <td>0.703501</td>\n",
       "      <td>0.739485</td>\n",
       "      <td>0.763537</td>\n",
       "      <td>0.751318</td>\n",
       "      <td>0.765756</td>\n",
       "      <td>0.820250</td>\n",
       "      <td>0.723741</td>\n",
       "      <td>0.765750</td>\n",
       "      <td>0.792185</td>\n",
       "      <td>0.778743</td>\n",
       "      <td>0.791355</td>\n",
       "      <td>0.854927</td>\n",
       "      <td>0.758676</td>\n",
       "      <td>0.759583</td>\n",
       "      <td>0.597702</td>\n",
       "      <td>0.668989</td>\n",
       "      <td>0.801302</td>\n",
       "      <td>0.744136</td>\n",
       "      <td>0.845372</td>\n",
       "      <td>0.660070</td>\n",
       "      <td>0.282230</td>\n",
       "      <td>0.395397</td>\n",
       "      <td>0.657136</td>\n",
       "      <td>0.384524</td>\n",
       "      <td>0.724843</td>\n",
       "      <td>0.699632</td>\n",
       "      <td>0.507800</td>\n",
       "      <td>0.588477</td>\n",
       "      <td>0.728114</td>\n",
       "      <td>0.641855</td>\n",
       "      <td>0.895883</td>\n",
       "      <td>0.717262</td>\n",
       "      <td>0.430028</td>\n",
       "      <td>0.537689</td>\n",
       "      <td>0.795656</td>\n",
       "      <td>0.508160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.723423</td>\n",
       "      <td>0.784095</td>\n",
       "      <td>0.802949</td>\n",
       "      <td>0.793410</td>\n",
       "      <td>0.784448</td>\n",
       "      <td>0.872760</td>\n",
       "      <td>0.761280</td>\n",
       "      <td>0.805675</td>\n",
       "      <td>0.888377</td>\n",
       "      <td>0.845007</td>\n",
       "      <td>0.795597</td>\n",
       "      <td>0.913061</td>\n",
       "      <td>0.725735</td>\n",
       "      <td>0.775595</td>\n",
       "      <td>0.561200</td>\n",
       "      <td>0.651205</td>\n",
       "      <td>0.763815</td>\n",
       "      <td>0.735315</td>\n",
       "      <td>0.708262</td>\n",
       "      <td>0.753107</td>\n",
       "      <td>0.747826</td>\n",
       "      <td>0.750457</td>\n",
       "      <td>0.768605</td>\n",
       "      <td>0.824946</td>\n",
       "      <td>0.724728</td>\n",
       "      <td>0.779168</td>\n",
       "      <td>0.769566</td>\n",
       "      <td>0.774338</td>\n",
       "      <td>0.788904</td>\n",
       "      <td>0.850415</td>\n",
       "      <td>0.760084</td>\n",
       "      <td>0.765190</td>\n",
       "      <td>0.594364</td>\n",
       "      <td>0.669045</td>\n",
       "      <td>0.798076</td>\n",
       "      <td>0.739817</td>\n",
       "      <td>0.837525</td>\n",
       "      <td>0.633001</td>\n",
       "      <td>0.221503</td>\n",
       "      <td>0.328171</td>\n",
       "      <td>0.701829</td>\n",
       "      <td>0.395069</td>\n",
       "      <td>0.724420</td>\n",
       "      <td>0.702626</td>\n",
       "      <td>0.500545</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.728032</td>\n",
       "      <td>0.639963</td>\n",
       "      <td>0.888777</td>\n",
       "      <td>0.728381</td>\n",
       "      <td>0.334948</td>\n",
       "      <td>0.458879</td>\n",
       "      <td>0.802961</td>\n",
       "      <td>0.509639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724159</td>\n",
       "      <td>0.761723</td>\n",
       "      <td>0.848337</td>\n",
       "      <td>0.802700</td>\n",
       "      <td>0.785371</td>\n",
       "      <td>0.872395</td>\n",
       "      <td>0.749210</td>\n",
       "      <td>0.798203</td>\n",
       "      <td>0.880137</td>\n",
       "      <td>0.837170</td>\n",
       "      <td>0.785067</td>\n",
       "      <td>0.908471</td>\n",
       "      <td>0.725349</td>\n",
       "      <td>0.774140</td>\n",
       "      <td>0.561925</td>\n",
       "      <td>0.651179</td>\n",
       "      <td>0.764088</td>\n",
       "      <td>0.734823</td>\n",
       "      <td>0.706358</td>\n",
       "      <td>0.760620</td>\n",
       "      <td>0.728776</td>\n",
       "      <td>0.744358</td>\n",
       "      <td>0.770106</td>\n",
       "      <td>0.824653</td>\n",
       "      <td>0.725385</td>\n",
       "      <td>0.801059</td>\n",
       "      <td>0.735084</td>\n",
       "      <td>0.766655</td>\n",
       "      <td>0.789088</td>\n",
       "      <td>0.852960</td>\n",
       "      <td>0.758583</td>\n",
       "      <td>0.757734</td>\n",
       "      <td>0.600192</td>\n",
       "      <td>0.669824</td>\n",
       "      <td>0.799880</td>\n",
       "      <td>0.742206</td>\n",
       "      <td>0.834671</td>\n",
       "      <td>0.619414</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.302483</td>\n",
       "      <td>0.669173</td>\n",
       "      <td>0.368005</td>\n",
       "      <td>0.721567</td>\n",
       "      <td>0.687318</td>\n",
       "      <td>0.516145</td>\n",
       "      <td>0.589558</td>\n",
       "      <td>0.725221</td>\n",
       "      <td>0.643619</td>\n",
       "      <td>0.885260</td>\n",
       "      <td>0.733591</td>\n",
       "      <td>0.290594</td>\n",
       "      <td>0.416286</td>\n",
       "      <td>0.797918</td>\n",
       "      <td>0.507762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.723028</td>\n",
       "      <td>0.787520</td>\n",
       "      <td>0.796034</td>\n",
       "      <td>0.791754</td>\n",
       "      <td>0.784036</td>\n",
       "      <td>0.874747</td>\n",
       "      <td>0.754634</td>\n",
       "      <td>0.783611</td>\n",
       "      <td>0.918735</td>\n",
       "      <td>0.845810</td>\n",
       "      <td>0.788763</td>\n",
       "      <td>0.911254</td>\n",
       "      <td>0.719776</td>\n",
       "      <td>0.768816</td>\n",
       "      <td>0.551645</td>\n",
       "      <td>0.642372</td>\n",
       "      <td>0.762158</td>\n",
       "      <td>0.736735</td>\n",
       "      <td>0.700807</td>\n",
       "      <td>0.735903</td>\n",
       "      <td>0.764210</td>\n",
       "      <td>0.749790</td>\n",
       "      <td>0.768216</td>\n",
       "      <td>0.821762</td>\n",
       "      <td>0.723083</td>\n",
       "      <td>0.794956</td>\n",
       "      <td>0.739523</td>\n",
       "      <td>0.766238</td>\n",
       "      <td>0.788252</td>\n",
       "      <td>0.856713</td>\n",
       "      <td>0.759207</td>\n",
       "      <td>0.760241</td>\n",
       "      <td>0.598608</td>\n",
       "      <td>0.669812</td>\n",
       "      <td>0.800161</td>\n",
       "      <td>0.744004</td>\n",
       "      <td>0.839754</td>\n",
       "      <td>0.644809</td>\n",
       "      <td>0.234943</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.658802</td>\n",
       "      <td>0.376387</td>\n",
       "      <td>0.724547</td>\n",
       "      <td>0.697209</td>\n",
       "      <td>0.510909</td>\n",
       "      <td>0.589694</td>\n",
       "      <td>0.723831</td>\n",
       "      <td>0.634116</td>\n",
       "      <td>0.889100</td>\n",
       "      <td>0.708563</td>\n",
       "      <td>0.360693</td>\n",
       "      <td>0.478041</td>\n",
       "      <td>0.797425</td>\n",
       "      <td>0.493072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.723423</td>\n",
       "      <td>0.779283</td>\n",
       "      <td>0.811772</td>\n",
       "      <td>0.795196</td>\n",
       "      <td>0.782791</td>\n",
       "      <td>0.871810</td>\n",
       "      <td>0.749138</td>\n",
       "      <td>0.774138</td>\n",
       "      <td>0.928396</td>\n",
       "      <td>0.844279</td>\n",
       "      <td>0.780181</td>\n",
       "      <td>0.905239</td>\n",
       "      <td>0.723169</td>\n",
       "      <td>0.754103</td>\n",
       "      <td>0.583454</td>\n",
       "      <td>0.657893</td>\n",
       "      <td>0.763951</td>\n",
       "      <td>0.736522</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.746201</td>\n",
       "      <td>0.756554</td>\n",
       "      <td>0.751342</td>\n",
       "      <td>0.772002</td>\n",
       "      <td>0.825509</td>\n",
       "      <td>0.725338</td>\n",
       "      <td>0.788273</td>\n",
       "      <td>0.755329</td>\n",
       "      <td>0.771450</td>\n",
       "      <td>0.790069</td>\n",
       "      <td>0.853963</td>\n",
       "      <td>0.758768</td>\n",
       "      <td>0.751830</td>\n",
       "      <td>0.610152</td>\n",
       "      <td>0.673622</td>\n",
       "      <td>0.799266</td>\n",
       "      <td>0.736607</td>\n",
       "      <td>0.834047</td>\n",
       "      <td>0.603352</td>\n",
       "      <td>0.215032</td>\n",
       "      <td>0.317064</td>\n",
       "      <td>0.657886</td>\n",
       "      <td>0.348134</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.694150</td>\n",
       "      <td>0.515218</td>\n",
       "      <td>0.591447</td>\n",
       "      <td>0.726343</td>\n",
       "      <td>0.641917</td>\n",
       "      <td>0.896171</td>\n",
       "      <td>0.711586</td>\n",
       "      <td>0.441499</td>\n",
       "      <td>0.544911</td>\n",
       "      <td>0.804700</td>\n",
       "      <td>0.516927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722056</td>\n",
       "      <td>0.777909</td>\n",
       "      <td>0.811454</td>\n",
       "      <td>0.794328</td>\n",
       "      <td>0.782455</td>\n",
       "      <td>0.872842</td>\n",
       "      <td>0.757293</td>\n",
       "      <td>0.783545</td>\n",
       "      <td>0.923884</td>\n",
       "      <td>0.847947</td>\n",
       "      <td>0.788414</td>\n",
       "      <td>0.909202</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.764880</td>\n",
       "      <td>0.562651</td>\n",
       "      <td>0.648362</td>\n",
       "      <td>0.762280</td>\n",
       "      <td>0.731728</td>\n",
       "      <td>0.702747</td>\n",
       "      <td>0.737959</td>\n",
       "      <td>0.764854</td>\n",
       "      <td>0.751166</td>\n",
       "      <td>0.768228</td>\n",
       "      <td>0.822625</td>\n",
       "      <td>0.723553</td>\n",
       "      <td>0.784596</td>\n",
       "      <td>0.757511</td>\n",
       "      <td>0.770815</td>\n",
       "      <td>0.786035</td>\n",
       "      <td>0.851843</td>\n",
       "      <td>0.756020</td>\n",
       "      <td>0.741962</td>\n",
       "      <td>0.616377</td>\n",
       "      <td>0.673364</td>\n",
       "      <td>0.793855</td>\n",
       "      <td>0.735556</td>\n",
       "      <td>0.837435</td>\n",
       "      <td>0.641768</td>\n",
       "      <td>0.209557</td>\n",
       "      <td>0.315947</td>\n",
       "      <td>0.674424</td>\n",
       "      <td>0.375045</td>\n",
       "      <td>0.723194</td>\n",
       "      <td>0.694972</td>\n",
       "      <td>0.508891</td>\n",
       "      <td>0.587550</td>\n",
       "      <td>0.714588</td>\n",
       "      <td>0.634266</td>\n",
       "      <td>0.886229</td>\n",
       "      <td>0.710924</td>\n",
       "      <td>0.323477</td>\n",
       "      <td>0.444639</td>\n",
       "      <td>0.790178</td>\n",
       "      <td>0.496813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.723528</td>\n",
       "      <td>0.798297</td>\n",
       "      <td>0.778785</td>\n",
       "      <td>0.788420</td>\n",
       "      <td>0.783759</td>\n",
       "      <td>0.872654</td>\n",
       "      <td>0.748958</td>\n",
       "      <td>0.767655</td>\n",
       "      <td>0.942570</td>\n",
       "      <td>0.846167</td>\n",
       "      <td>0.786159</td>\n",
       "      <td>0.909565</td>\n",
       "      <td>0.724466</td>\n",
       "      <td>0.764392</td>\n",
       "      <td>0.572508</td>\n",
       "      <td>0.654680</td>\n",
       "      <td>0.762094</td>\n",
       "      <td>0.735640</td>\n",
       "      <td>0.702513</td>\n",
       "      <td>0.743575</td>\n",
       "      <td>0.752297</td>\n",
       "      <td>0.747911</td>\n",
       "      <td>0.769559</td>\n",
       "      <td>0.823599</td>\n",
       "      <td>0.724070</td>\n",
       "      <td>0.793143</td>\n",
       "      <td>0.744575</td>\n",
       "      <td>0.768092</td>\n",
       "      <td>0.788025</td>\n",
       "      <td>0.851070</td>\n",
       "      <td>0.756852</td>\n",
       "      <td>0.743886</td>\n",
       "      <td>0.616207</td>\n",
       "      <td>0.674054</td>\n",
       "      <td>0.797826</td>\n",
       "      <td>0.740073</td>\n",
       "      <td>0.826734</td>\n",
       "      <td>0.585492</td>\n",
       "      <td>0.112494</td>\n",
       "      <td>0.188727</td>\n",
       "      <td>0.674392</td>\n",
       "      <td>0.361391</td>\n",
       "      <td>0.725963</td>\n",
       "      <td>0.715156</td>\n",
       "      <td>0.486419</td>\n",
       "      <td>0.579016</td>\n",
       "      <td>0.727222</td>\n",
       "      <td>0.639543</td>\n",
       "      <td>0.890464</td>\n",
       "      <td>0.707678</td>\n",
       "      <td>0.378282</td>\n",
       "      <td>0.493023</td>\n",
       "      <td>0.804738</td>\n",
       "      <td>0.498061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722844</td>\n",
       "      <td>0.766208</td>\n",
       "      <td>0.836096</td>\n",
       "      <td>0.799627</td>\n",
       "      <td>0.785305</td>\n",
       "      <td>0.874788</td>\n",
       "      <td>0.747270</td>\n",
       "      <td>0.776650</td>\n",
       "      <td>0.919372</td>\n",
       "      <td>0.842006</td>\n",
       "      <td>0.782549</td>\n",
       "      <td>0.905957</td>\n",
       "      <td>0.725708</td>\n",
       "      <td>0.772524</td>\n",
       "      <td>0.565191</td>\n",
       "      <td>0.652790</td>\n",
       "      <td>0.763957</td>\n",
       "      <td>0.735150</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>0.740996</td>\n",
       "      <td>0.746690</td>\n",
       "      <td>0.769934</td>\n",
       "      <td>0.824770</td>\n",
       "      <td>0.723553</td>\n",
       "      <td>0.797399</td>\n",
       "      <td>0.736729</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.789891</td>\n",
       "      <td>0.855940</td>\n",
       "      <td>0.756759</td>\n",
       "      <td>0.746920</td>\n",
       "      <td>0.610775</td>\n",
       "      <td>0.672021</td>\n",
       "      <td>0.795835</td>\n",
       "      <td>0.734546</td>\n",
       "      <td>0.838060</td>\n",
       "      <td>0.643815</td>\n",
       "      <td>0.215032</td>\n",
       "      <td>0.322388</td>\n",
       "      <td>0.649293</td>\n",
       "      <td>0.365778</td>\n",
       "      <td>0.725624</td>\n",
       "      <td>0.694659</td>\n",
       "      <td>0.520672</td>\n",
       "      <td>0.595211</td>\n",
       "      <td>0.726719</td>\n",
       "      <td>0.639131</td>\n",
       "      <td>0.895130</td>\n",
       "      <td>0.723937</td>\n",
       "      <td>0.412439</td>\n",
       "      <td>0.525495</td>\n",
       "      <td>0.786691</td>\n",
       "      <td>0.500161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.721635</td>\n",
       "      <td>0.774467</td>\n",
       "      <td>0.817098</td>\n",
       "      <td>0.795211</td>\n",
       "      <td>0.784568</td>\n",
       "      <td>0.873930</td>\n",
       "      <td>0.745042</td>\n",
       "      <td>0.757546</td>\n",
       "      <td>0.958803</td>\n",
       "      <td>0.846375</td>\n",
       "      <td>0.770842</td>\n",
       "      <td>0.905596</td>\n",
       "      <td>0.725542</td>\n",
       "      <td>0.781010</td>\n",
       "      <td>0.553641</td>\n",
       "      <td>0.647958</td>\n",
       "      <td>0.763257</td>\n",
       "      <td>0.734924</td>\n",
       "      <td>0.699711</td>\n",
       "      <td>0.726397</td>\n",
       "      <td>0.783015</td>\n",
       "      <td>0.753644</td>\n",
       "      <td>0.768162</td>\n",
       "      <td>0.822637</td>\n",
       "      <td>0.725620</td>\n",
       "      <td>0.784021</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.790427</td>\n",
       "      <td>0.854827</td>\n",
       "      <td>0.758237</td>\n",
       "      <td>0.753628</td>\n",
       "      <td>0.605342</td>\n",
       "      <td>0.671395</td>\n",
       "      <td>0.796474</td>\n",
       "      <td>0.738633</td>\n",
       "      <td>0.834047</td>\n",
       "      <td>0.604520</td>\n",
       "      <td>0.213041</td>\n",
       "      <td>0.315053</td>\n",
       "      <td>0.652121</td>\n",
       "      <td>0.361519</td>\n",
       "      <td>0.726829</td>\n",
       "      <td>0.701528</td>\n",
       "      <td>0.513309</td>\n",
       "      <td>0.592838</td>\n",
       "      <td>0.725385</td>\n",
       "      <td>0.641270</td>\n",
       "      <td>0.891684</td>\n",
       "      <td>0.725911</td>\n",
       "      <td>0.370635</td>\n",
       "      <td>0.490719</td>\n",
       "      <td>0.800041</td>\n",
       "      <td>0.503606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717744</td>\n",
       "      <td>0.771557</td>\n",
       "      <td>0.814395</td>\n",
       "      <td>0.792397</td>\n",
       "      <td>0.778385</td>\n",
       "      <td>0.869404</td>\n",
       "      <td>0.753090</td>\n",
       "      <td>0.803031</td>\n",
       "      <td>0.878372</td>\n",
       "      <td>0.839013</td>\n",
       "      <td>0.784686</td>\n",
       "      <td>0.907057</td>\n",
       "      <td>0.726122</td>\n",
       "      <td>0.778508</td>\n",
       "      <td>0.558599</td>\n",
       "      <td>0.650470</td>\n",
       "      <td>0.761594</td>\n",
       "      <td>0.734239</td>\n",
       "      <td>0.708172</td>\n",
       "      <td>0.746870</td>\n",
       "      <td>0.760137</td>\n",
       "      <td>0.753445</td>\n",
       "      <td>0.772625</td>\n",
       "      <td>0.826058</td>\n",
       "      <td>0.722614</td>\n",
       "      <td>0.780358</td>\n",
       "      <td>0.762677</td>\n",
       "      <td>0.771416</td>\n",
       "      <td>0.786919</td>\n",
       "      <td>0.853139</td>\n",
       "      <td>0.758121</td>\n",
       "      <td>0.774723</td>\n",
       "      <td>0.574104</td>\n",
       "      <td>0.659494</td>\n",
       "      <td>0.799513</td>\n",
       "      <td>0.743339</td>\n",
       "      <td>0.834136</td>\n",
       "      <td>0.625632</td>\n",
       "      <td>0.184669</td>\n",
       "      <td>0.285165</td>\n",
       "      <td>0.683568</td>\n",
       "      <td>0.384783</td>\n",
       "      <td>0.718778</td>\n",
       "      <td>0.668116</td>\n",
       "      <td>0.544726</td>\n",
       "      <td>0.600144</td>\n",
       "      <td>0.729366</td>\n",
       "      <td>0.640931</td>\n",
       "      <td>0.893048</td>\n",
       "      <td>0.714416</td>\n",
       "      <td>0.400459</td>\n",
       "      <td>0.513231</td>\n",
       "      <td>0.796573</td>\n",
       "      <td>0.492916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.719716</td>\n",
       "      <td>0.768749</td>\n",
       "      <td>0.824172</td>\n",
       "      <td>0.795496</td>\n",
       "      <td>0.781036</td>\n",
       "      <td>0.872599</td>\n",
       "      <td>0.753090</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>0.935115</td>\n",
       "      <td>0.847290</td>\n",
       "      <td>0.785724</td>\n",
       "      <td>0.910601</td>\n",
       "      <td>0.721238</td>\n",
       "      <td>0.746588</td>\n",
       "      <td>0.588836</td>\n",
       "      <td>0.658395</td>\n",
       "      <td>0.760702</td>\n",
       "      <td>0.729704</td>\n",
       "      <td>0.708927</td>\n",
       "      <td>0.768773</td>\n",
       "      <td>0.720507</td>\n",
       "      <td>0.743858</td>\n",
       "      <td>0.771726</td>\n",
       "      <td>0.825578</td>\n",
       "      <td>0.722355</td>\n",
       "      <td>0.819033</td>\n",
       "      <td>0.702897</td>\n",
       "      <td>0.756534</td>\n",
       "      <td>0.789448</td>\n",
       "      <td>0.851399</td>\n",
       "      <td>0.760292</td>\n",
       "      <td>0.754700</td>\n",
       "      <td>0.611114</td>\n",
       "      <td>0.675360</td>\n",
       "      <td>0.800420</td>\n",
       "      <td>0.740190</td>\n",
       "      <td>0.837257</td>\n",
       "      <td>0.636095</td>\n",
       "      <td>0.214037</td>\n",
       "      <td>0.320298</td>\n",
       "      <td>0.671547</td>\n",
       "      <td>0.376606</td>\n",
       "      <td>0.725582</td>\n",
       "      <td>0.700450</td>\n",
       "      <td>0.509654</td>\n",
       "      <td>0.590011</td>\n",
       "      <td>0.725394</td>\n",
       "      <td>0.638063</td>\n",
       "      <td>0.894232</td>\n",
       "      <td>0.711255</td>\n",
       "      <td>0.418812</td>\n",
       "      <td>0.527194</td>\n",
       "      <td>0.801888</td>\n",
       "      <td>0.502271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.719506</td>\n",
       "      <td>0.744590</td>\n",
       "      <td>0.876634</td>\n",
       "      <td>0.805235</td>\n",
       "      <td>0.783965</td>\n",
       "      <td>0.873404</td>\n",
       "      <td>0.749174</td>\n",
       "      <td>0.761344</td>\n",
       "      <td>0.957822</td>\n",
       "      <td>0.848356</td>\n",
       "      <td>0.786095</td>\n",
       "      <td>0.909769</td>\n",
       "      <td>0.727115</td>\n",
       "      <td>0.775110</td>\n",
       "      <td>0.566098</td>\n",
       "      <td>0.654318</td>\n",
       "      <td>0.764163</td>\n",
       "      <td>0.736818</td>\n",
       "      <td>0.702172</td>\n",
       "      <td>0.737066</td>\n",
       "      <td>0.765282</td>\n",
       "      <td>0.750909</td>\n",
       "      <td>0.769265</td>\n",
       "      <td>0.823759</td>\n",
       "      <td>0.723412</td>\n",
       "      <td>0.776583</td>\n",
       "      <td>0.771174</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.789221</td>\n",
       "      <td>0.855649</td>\n",
       "      <td>0.757106</td>\n",
       "      <td>0.747697</td>\n",
       "      <td>0.610775</td>\n",
       "      <td>0.672335</td>\n",
       "      <td>0.798636</td>\n",
       "      <td>0.739903</td>\n",
       "      <td>0.833244</td>\n",
       "      <td>0.613377</td>\n",
       "      <td>0.187158</td>\n",
       "      <td>0.286804</td>\n",
       "      <td>0.678857</td>\n",
       "      <td>0.371743</td>\n",
       "      <td>0.723849</td>\n",
       "      <td>0.707519</td>\n",
       "      <td>0.489637</td>\n",
       "      <td>0.578751</td>\n",
       "      <td>0.721789</td>\n",
       "      <td>0.628332</td>\n",
       "      <td>0.894412</td>\n",
       "      <td>0.709168</td>\n",
       "      <td>0.423910</td>\n",
       "      <td>0.530632</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.514646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724921</td>\n",
       "      <td>0.815292</td>\n",
       "      <td>0.755216</td>\n",
       "      <td>0.784105</td>\n",
       "      <td>0.787301</td>\n",
       "      <td>0.875730</td>\n",
       "      <td>0.748779</td>\n",
       "      <td>0.758380</td>\n",
       "      <td>0.964247</td>\n",
       "      <td>0.849012</td>\n",
       "      <td>0.788468</td>\n",
       "      <td>0.909366</td>\n",
       "      <td>0.724687</td>\n",
       "      <td>0.771377</td>\n",
       "      <td>0.563558</td>\n",
       "      <td>0.651291</td>\n",
       "      <td>0.763478</td>\n",
       "      <td>0.736814</td>\n",
       "      <td>0.701885</td>\n",
       "      <td>0.745056</td>\n",
       "      <td>0.747611</td>\n",
       "      <td>0.746331</td>\n",
       "      <td>0.769451</td>\n",
       "      <td>0.824468</td>\n",
       "      <td>0.723154</td>\n",
       "      <td>0.777044</td>\n",
       "      <td>0.769758</td>\n",
       "      <td>0.773384</td>\n",
       "      <td>0.784057</td>\n",
       "      <td>0.845541</td>\n",
       "      <td>0.756344</td>\n",
       "      <td>0.734980</td>\n",
       "      <td>0.629959</td>\n",
       "      <td>0.678429</td>\n",
       "      <td>0.796500</td>\n",
       "      <td>0.734808</td>\n",
       "      <td>0.832263</td>\n",
       "      <td>0.611888</td>\n",
       "      <td>0.174216</td>\n",
       "      <td>0.271213</td>\n",
       "      <td>0.666691</td>\n",
       "      <td>0.361607</td>\n",
       "      <td>0.720447</td>\n",
       "      <td>0.680580</td>\n",
       "      <td>0.524708</td>\n",
       "      <td>0.592565</td>\n",
       "      <td>0.723221</td>\n",
       "      <td>0.636695</td>\n",
       "      <td>0.888167</td>\n",
       "      <td>0.710485</td>\n",
       "      <td>0.347183</td>\n",
       "      <td>0.466438</td>\n",
       "      <td>0.774073</td>\n",
       "      <td>0.487006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724474</td>\n",
       "      <td>0.789981</td>\n",
       "      <td>0.794722</td>\n",
       "      <td>0.792344</td>\n",
       "      <td>0.784114</td>\n",
       "      <td>0.873740</td>\n",
       "      <td>0.751473</td>\n",
       "      <td>0.792133</td>\n",
       "      <td>0.895782</td>\n",
       "      <td>0.840775</td>\n",
       "      <td>0.787893</td>\n",
       "      <td>0.910194</td>\n",
       "      <td>0.723142</td>\n",
       "      <td>0.762370</td>\n",
       "      <td>0.571178</td>\n",
       "      <td>0.653068</td>\n",
       "      <td>0.761648</td>\n",
       "      <td>0.732011</td>\n",
       "      <td>0.698633</td>\n",
       "      <td>0.726136</td>\n",
       "      <td>0.780687</td>\n",
       "      <td>0.752424</td>\n",
       "      <td>0.769412</td>\n",
       "      <td>0.824441</td>\n",
       "      <td>0.723412</td>\n",
       "      <td>0.782573</td>\n",
       "      <td>0.760649</td>\n",
       "      <td>0.771455</td>\n",
       "      <td>0.787784</td>\n",
       "      <td>0.851023</td>\n",
       "      <td>0.753850</td>\n",
       "      <td>0.728726</td>\n",
       "      <td>0.631939</td>\n",
       "      <td>0.676890</td>\n",
       "      <td>0.796518</td>\n",
       "      <td>0.740624</td>\n",
       "      <td>0.831639</td>\n",
       "      <td>0.637813</td>\n",
       "      <td>0.139373</td>\n",
       "      <td>0.228758</td>\n",
       "      <td>0.665852</td>\n",
       "      <td>0.375989</td>\n",
       "      <td>0.723786</td>\n",
       "      <td>0.694854</td>\n",
       "      <td>0.511836</td>\n",
       "      <td>0.589466</td>\n",
       "      <td>0.727110</td>\n",
       "      <td>0.640548</td>\n",
       "      <td>0.894376</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.401478</td>\n",
       "      <td>0.516987</td>\n",
       "      <td>0.799259</td>\n",
       "      <td>0.510058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.723423</td>\n",
       "      <td>0.792730</td>\n",
       "      <td>0.787846</td>\n",
       "      <td>0.790280</td>\n",
       "      <td>0.783458</td>\n",
       "      <td>0.872128</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>0.766057</td>\n",
       "      <td>0.951692</td>\n",
       "      <td>0.848844</td>\n",
       "      <td>0.787555</td>\n",
       "      <td>0.907650</td>\n",
       "      <td>0.723445</td>\n",
       "      <td>0.768691</td>\n",
       "      <td>0.563316</td>\n",
       "      <td>0.650171</td>\n",
       "      <td>0.760910</td>\n",
       "      <td>0.732678</td>\n",
       "      <td>0.705837</td>\n",
       "      <td>0.758677</td>\n",
       "      <td>0.731073</td>\n",
       "      <td>0.744619</td>\n",
       "      <td>0.769905</td>\n",
       "      <td>0.822253</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>0.794366</td>\n",
       "      <td>0.751196</td>\n",
       "      <td>0.772178</td>\n",
       "      <td>0.789187</td>\n",
       "      <td>0.851497</td>\n",
       "      <td>0.759784</td>\n",
       "      <td>0.771217</td>\n",
       "      <td>0.584687</td>\n",
       "      <td>0.665122</td>\n",
       "      <td>0.801158</td>\n",
       "      <td>0.743272</td>\n",
       "      <td>0.836454</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.272222</td>\n",
       "      <td>0.647433</td>\n",
       "      <td>0.370908</td>\n",
       "      <td>0.726322</td>\n",
       "      <td>0.711513</td>\n",
       "      <td>0.493837</td>\n",
       "      <td>0.583019</td>\n",
       "      <td>0.725150</td>\n",
       "      <td>0.640177</td>\n",
       "      <td>0.891110</td>\n",
       "      <td>0.680178</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>0.525196</td>\n",
       "      <td>0.801187</td>\n",
       "      <td>0.491945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724711</td>\n",
       "      <td>0.777874</td>\n",
       "      <td>0.817138</td>\n",
       "      <td>0.797023</td>\n",
       "      <td>0.784648</td>\n",
       "      <td>0.873826</td>\n",
       "      <td>0.755496</td>\n",
       "      <td>0.777338</td>\n",
       "      <td>0.933644</td>\n",
       "      <td>0.848351</td>\n",
       "      <td>0.788476</td>\n",
       "      <td>0.909978</td>\n",
       "      <td>0.722866</td>\n",
       "      <td>0.773121</td>\n",
       "      <td>0.555576</td>\n",
       "      <td>0.646539</td>\n",
       "      <td>0.764323</td>\n",
       "      <td>0.732480</td>\n",
       "      <td>0.701867</td>\n",
       "      <td>0.733992</td>\n",
       "      <td>0.771285</td>\n",
       "      <td>0.752177</td>\n",
       "      <td>0.769921</td>\n",
       "      <td>0.824864</td>\n",
       "      <td>0.721064</td>\n",
       "      <td>0.799395</td>\n",
       "      <td>0.728233</td>\n",
       "      <td>0.762157</td>\n",
       "      <td>0.783045</td>\n",
       "      <td>0.848232</td>\n",
       "      <td>0.756367</td>\n",
       "      <td>0.745195</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.672176</td>\n",
       "      <td>0.795352</td>\n",
       "      <td>0.731178</td>\n",
       "      <td>0.836811</td>\n",
       "      <td>0.669187</td>\n",
       "      <td>0.176207</td>\n",
       "      <td>0.278960</td>\n",
       "      <td>0.663316</td>\n",
       "      <td>0.393596</td>\n",
       "      <td>0.717129</td>\n",
       "      <td>0.664999</td>\n",
       "      <td>0.543853</td>\n",
       "      <td>0.598356</td>\n",
       "      <td>0.727150</td>\n",
       "      <td>0.637165</td>\n",
       "      <td>0.890679</td>\n",
       "      <td>0.721577</td>\n",
       "      <td>0.364007</td>\n",
       "      <td>0.483904</td>\n",
       "      <td>0.785937</td>\n",
       "      <td>0.494083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722397</td>\n",
       "      <td>0.785076</td>\n",
       "      <td>0.799054</td>\n",
       "      <td>0.792003</td>\n",
       "      <td>0.782832</td>\n",
       "      <td>0.872380</td>\n",
       "      <td>0.746803</td>\n",
       "      <td>0.783535</td>\n",
       "      <td>0.904120</td>\n",
       "      <td>0.839519</td>\n",
       "      <td>0.782677</td>\n",
       "      <td>0.908913</td>\n",
       "      <td>0.719252</td>\n",
       "      <td>0.733412</td>\n",
       "      <td>0.604257</td>\n",
       "      <td>0.662599</td>\n",
       "      <td>0.761503</td>\n",
       "      <td>0.728309</td>\n",
       "      <td>0.697806</td>\n",
       "      <td>0.722740</td>\n",
       "      <td>0.786598</td>\n",
       "      <td>0.753318</td>\n",
       "      <td>0.767148</td>\n",
       "      <td>0.820919</td>\n",
       "      <td>0.716249</td>\n",
       "      <td>0.744313</td>\n",
       "      <td>0.818975</td>\n",
       "      <td>0.779861</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.849417</td>\n",
       "      <td>0.757798</td>\n",
       "      <td>0.747024</td>\n",
       "      <td>0.614453</td>\n",
       "      <td>0.674284</td>\n",
       "      <td>0.796516</td>\n",
       "      <td>0.742561</td>\n",
       "      <td>0.841627</td>\n",
       "      <td>0.662031</td>\n",
       "      <td>0.236934</td>\n",
       "      <td>0.348974</td>\n",
       "      <td>0.621786</td>\n",
       "      <td>0.350799</td>\n",
       "      <td>0.724695</td>\n",
       "      <td>0.693367</td>\n",
       "      <td>0.518872</td>\n",
       "      <td>0.593561</td>\n",
       "      <td>0.728905</td>\n",
       "      <td>0.642344</td>\n",
       "      <td>0.894412</td>\n",
       "      <td>0.729313</td>\n",
       "      <td>0.397655</td>\n",
       "      <td>0.514682</td>\n",
       "      <td>0.794877</td>\n",
       "      <td>0.506897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720005</td>\n",
       "      <td>0.763607</td>\n",
       "      <td>0.835261</td>\n",
       "      <td>0.797829</td>\n",
       "      <td>0.782395</td>\n",
       "      <td>0.873489</td>\n",
       "      <td>0.749928</td>\n",
       "      <td>0.780203</td>\n",
       "      <td>0.916920</td>\n",
       "      <td>0.843055</td>\n",
       "      <td>0.786967</td>\n",
       "      <td>0.910583</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.768003</td>\n",
       "      <td>0.564344</td>\n",
       "      <td>0.650608</td>\n",
       "      <td>0.762198</td>\n",
       "      <td>0.737233</td>\n",
       "      <td>0.701292</td>\n",
       "      <td>0.751989</td>\n",
       "      <td>0.732298</td>\n",
       "      <td>0.742013</td>\n",
       "      <td>0.766046</td>\n",
       "      <td>0.817916</td>\n",
       "      <td>0.721886</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.746221</td>\n",
       "      <td>0.767079</td>\n",
       "      <td>0.789481</td>\n",
       "      <td>0.854688</td>\n",
       "      <td>0.758976</td>\n",
       "      <td>0.744754</td>\n",
       "      <td>0.622659</td>\n",
       "      <td>0.678256</td>\n",
       "      <td>0.798056</td>\n",
       "      <td>0.743540</td>\n",
       "      <td>0.842875</td>\n",
       "      <td>0.649697</td>\n",
       "      <td>0.266799</td>\n",
       "      <td>0.378264</td>\n",
       "      <td>0.685676</td>\n",
       "      <td>0.397624</td>\n",
       "      <td>0.726702</td>\n",
       "      <td>0.709552</td>\n",
       "      <td>0.498746</td>\n",
       "      <td>0.585760</td>\n",
       "      <td>0.723791</td>\n",
       "      <td>0.637387</td>\n",
       "      <td>0.880415</td>\n",
       "      <td>0.735834</td>\n",
       "      <td>0.235024</td>\n",
       "      <td>0.356260</td>\n",
       "      <td>0.798764</td>\n",
       "      <td>0.506971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722529</td>\n",
       "      <td>0.777638</td>\n",
       "      <td>0.812965</td>\n",
       "      <td>0.794909</td>\n",
       "      <td>0.781894</td>\n",
       "      <td>0.871894</td>\n",
       "      <td>0.756071</td>\n",
       "      <td>0.764098</td>\n",
       "      <td>0.964885</td>\n",
       "      <td>0.852833</td>\n",
       "      <td>0.792323</td>\n",
       "      <td>0.912737</td>\n",
       "      <td>0.724218</td>\n",
       "      <td>0.767332</td>\n",
       "      <td>0.567610</td>\n",
       "      <td>0.652531</td>\n",
       "      <td>0.760828</td>\n",
       "      <td>0.736136</td>\n",
       "      <td>0.697860</td>\n",
       "      <td>0.720898</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.754453</td>\n",
       "      <td>0.768764</td>\n",
       "      <td>0.824103</td>\n",
       "      <td>0.721886</td>\n",
       "      <td>0.788810</td>\n",
       "      <td>0.746756</td>\n",
       "      <td>0.767207</td>\n",
       "      <td>0.788975</td>\n",
       "      <td>0.856360</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.763353</td>\n",
       "      <td>0.587969</td>\n",
       "      <td>0.664280</td>\n",
       "      <td>0.797168</td>\n",
       "      <td>0.740944</td>\n",
       "      <td>0.836454</td>\n",
       "      <td>0.640902</td>\n",
       "      <td>0.198109</td>\n",
       "      <td>0.302662</td>\n",
       "      <td>0.654635</td>\n",
       "      <td>0.372474</td>\n",
       "      <td>0.725603</td>\n",
       "      <td>0.697162</td>\n",
       "      <td>0.515818</td>\n",
       "      <td>0.592934</td>\n",
       "      <td>0.729719</td>\n",
       "      <td>0.643113</td>\n",
       "      <td>0.894627</td>\n",
       "      <td>0.731581</td>\n",
       "      <td>0.397400</td>\n",
       "      <td>0.515031</td>\n",
       "      <td>0.794317</td>\n",
       "      <td>0.513565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_length  valid_length  test_length  tgc_accuracy  tgc_precision  \\\n",
       "0            NaN           NaN          NaN      0.719821       0.746960   \n",
       "1            NaN           NaN          NaN      0.724080       0.788511   \n",
       "2            NaN           NaN          NaN      0.721293       0.777304   \n",
       "3            NaN           NaN          NaN      0.722818       0.765542   \n",
       "4            NaN           NaN          NaN      0.715694       0.743930   \n",
       "5            NaN           NaN          NaN      0.719637       0.759172   \n",
       "6            NaN           NaN          NaN      0.722766       0.774131   \n",
       "7            NaN           NaN          NaN      0.725683       0.800359   \n",
       "8            NaN           NaN          NaN      0.726998       0.787919   \n",
       "9            NaN           NaN          NaN      0.725894       0.812214   \n",
       "10           NaN           NaN          NaN      0.720189       0.750786   \n",
       "11           NaN           NaN          NaN      0.723291       0.787310   \n",
       "12           NaN           NaN          NaN      0.723423       0.784095   \n",
       "13           NaN           NaN          NaN      0.724159       0.761723   \n",
       "14           NaN           NaN          NaN      0.723028       0.787520   \n",
       "15           NaN           NaN          NaN      0.723423       0.779283   \n",
       "16           NaN           NaN          NaN      0.722056       0.777909   \n",
       "17           NaN           NaN          NaN      0.723528       0.798297   \n",
       "18           NaN           NaN          NaN      0.722844       0.766208   \n",
       "19           NaN           NaN          NaN      0.721635       0.774467   \n",
       "20           NaN           NaN          NaN      0.717744       0.771557   \n",
       "21           NaN           NaN          NaN      0.719716       0.768749   \n",
       "22           NaN           NaN          NaN      0.719506       0.744590   \n",
       "23           NaN           NaN          NaN      0.724921       0.815292   \n",
       "24           NaN           NaN          NaN      0.724474       0.789981   \n",
       "25           NaN           NaN          NaN      0.723423       0.792730   \n",
       "26           NaN           NaN          NaN      0.724711       0.777874   \n",
       "27           NaN           NaN          NaN      0.722397       0.785076   \n",
       "28           NaN           NaN          NaN      0.720005       0.763607   \n",
       "29           NaN           NaN          NaN      0.722529       0.777638   \n",
       "\n",
       "    tgc_recall    tgc_f1   tgc_auc   tgc_prc  m_accuracy  m_precision  \\\n",
       "0     0.871706  0.804526  0.785253  0.874994    0.750323     0.754468   \n",
       "1     0.796471  0.792471  0.784656  0.874147    0.749389     0.775306   \n",
       "2     0.810977  0.793784  0.782018  0.873437    0.745438     0.757690   \n",
       "3     0.837407  0.799863  0.784979  0.874011    0.750503     0.781760   \n",
       "4     0.869441  0.801803  0.784762  0.874632    0.749389     0.782186   \n",
       "5     0.843806  0.799255  0.782554  0.871854    0.747988     0.796629   \n",
       "6     0.820158  0.796480  0.783967  0.874857    0.749749     0.774722   \n",
       "7     0.779778  0.789935  0.785866  0.874871    0.753233     0.770582   \n",
       "8     0.803545  0.795655  0.785121  0.873695    0.752012     0.777293   \n",
       "9     0.761695  0.786144  0.785959  0.875957    0.752263     0.779194   \n",
       "10    0.863638  0.803268  0.782333  0.872037    0.751293     0.762157   \n",
       "11    0.796948  0.792100  0.784187  0.874525    0.735846     0.799715   \n",
       "12    0.802949  0.793410  0.784448  0.872760    0.761280     0.805675   \n",
       "13    0.848337  0.802700  0.785371  0.872395    0.749210     0.798203   \n",
       "14    0.796034  0.791754  0.784036  0.874747    0.754634     0.783611   \n",
       "15    0.811772  0.795196  0.782791  0.871810    0.749138     0.774138   \n",
       "16    0.811454  0.794328  0.782455  0.872842    0.757293     0.783545   \n",
       "17    0.778785  0.788420  0.783759  0.872654    0.748958     0.767655   \n",
       "18    0.836096  0.799627  0.785305  0.874788    0.747270     0.776650   \n",
       "19    0.817098  0.795211  0.784568  0.873930    0.745042     0.757546   \n",
       "20    0.814395  0.792397  0.778385  0.869404    0.753090     0.803031   \n",
       "21    0.824172  0.795496  0.781036  0.872599    0.753090     0.774546   \n",
       "22    0.876634  0.805235  0.783965  0.873404    0.749174     0.761344   \n",
       "23    0.755216  0.784105  0.787301  0.875730    0.748779     0.758380   \n",
       "24    0.794722  0.792344  0.784114  0.873740    0.751473     0.792133   \n",
       "25    0.787846  0.790280  0.783458  0.872128    0.751724     0.766057   \n",
       "26    0.817138  0.797023  0.784648  0.873826    0.755496     0.777338   \n",
       "27    0.799054  0.792003  0.782832  0.872380    0.746803     0.783535   \n",
       "28    0.835261  0.797829  0.782395  0.873489    0.749928     0.780203   \n",
       "29    0.812965  0.794909  0.781894  0.871894    0.756071     0.764098   \n",
       "\n",
       "    m_recall      m_f1     m_auc     m_prc  fgc_accuracy  fgc_precision  \\\n",
       "0   0.977146  0.851489  0.786185  0.908954      0.719914       0.737819   \n",
       "1   0.926336  0.844119  0.779028  0.906598      0.723114       0.751704   \n",
       "2   0.959245  0.846637  0.780428  0.908242      0.719859       0.753778   \n",
       "3   0.914762  0.843047  0.785348  0.909763      0.722562       0.754797   \n",
       "4   0.911770  0.842022  0.780463  0.904265      0.721073       0.760120   \n",
       "5   0.880824  0.836613  0.786007  0.907007      0.721845       0.773660   \n",
       "6   0.928298  0.844585  0.784140  0.909781      0.723445       0.768603   \n",
       "7   0.944237  0.848617  0.781369  0.907976      0.723225       0.748055   \n",
       "8   0.927072  0.845602  0.785883  0.909319      0.725708       0.770423   \n",
       "9   0.923492  0.845228  0.786572  0.912221      0.727225       0.780762   \n",
       "10  0.960078  0.849745  0.790853  0.912906      0.723776       0.780868   \n",
       "11  0.853016  0.825506  0.776320  0.907011      0.724908       0.751359   \n",
       "12  0.888377  0.845007  0.795597  0.913061      0.725735       0.775595   \n",
       "13  0.880137  0.837170  0.785067  0.908471      0.725349       0.774140   \n",
       "14  0.918735  0.845810  0.788763  0.911254      0.719776       0.768816   \n",
       "15  0.928396  0.844279  0.780181  0.905239      0.723169       0.754103   \n",
       "16  0.923884  0.847947  0.788414  0.909202      0.721569       0.764880   \n",
       "17  0.942570  0.846167  0.786159  0.909565      0.724466       0.764392   \n",
       "18  0.919372  0.842006  0.782549  0.905957      0.725708       0.772524   \n",
       "19  0.958803  0.846375  0.770842  0.905596      0.725542       0.781010   \n",
       "20  0.878372  0.839013  0.784686  0.907057      0.726122       0.778508   \n",
       "21  0.935115  0.847290  0.785724  0.910601      0.721238       0.746588   \n",
       "22  0.957822  0.848356  0.786095  0.909769      0.727115       0.775110   \n",
       "23  0.964247  0.849012  0.788468  0.909366      0.724687       0.771377   \n",
       "24  0.895782  0.840775  0.787893  0.910194      0.723142       0.762370   \n",
       "25  0.951692  0.848844  0.787555  0.907650      0.723445       0.768691   \n",
       "26  0.933644  0.848351  0.788476  0.909978      0.722866       0.773121   \n",
       "27  0.904120  0.839519  0.782677  0.908913      0.719252       0.733412   \n",
       "28  0.916920  0.843055  0.786967  0.910583      0.723473       0.768003   \n",
       "29  0.964885  0.852833  0.792323  0.912737      0.724218       0.767332   \n",
       "\n",
       "    fgc_recall    fgc_f1   fgc_auc   fgc_prc  f_accuracy  f_precision  \\\n",
       "0     0.598875  0.661126  0.760872  0.728792    0.695417     0.714103   \n",
       "1     0.586962  0.659196  0.761648  0.734090    0.703483     0.738206   \n",
       "2     0.573174  0.651185  0.761616  0.733414    0.698615     0.725422   \n",
       "3     0.580431  0.656229  0.760331  0.728030    0.700789     0.728053   \n",
       "4     0.567791  0.650028  0.758775  0.734090    0.701795     0.731518   \n",
       "5     0.551705  0.644098  0.758697  0.726788    0.705783     0.761093   \n",
       "6     0.563437  0.650220  0.760087  0.730832    0.670517     0.695220   \n",
       "7     0.593070  0.661607  0.764403  0.734031    0.703501     0.741433   \n",
       "8     0.568033  0.653926  0.764077  0.738023    0.690602     0.703401   \n",
       "9     0.559083  0.651584  0.761892  0.734803    0.703609     0.748324   \n",
       "10    0.548440  0.644334  0.757847  0.733119    0.702495     0.732651   \n",
       "11    0.593372  0.663085  0.759460  0.726610    0.703501     0.739485   \n",
       "12    0.561200  0.651205  0.763815  0.735315    0.708262     0.753107   \n",
       "13    0.561925  0.651179  0.764088  0.734823    0.706358     0.760620   \n",
       "14    0.551645  0.642372  0.762158  0.736735    0.700807     0.735903   \n",
       "15    0.583454  0.657893  0.763951  0.736522    0.706250     0.746201   \n",
       "16    0.562651  0.648362  0.762280  0.731728    0.702747     0.737959   \n",
       "17    0.572508  0.654680  0.762094  0.735640    0.702513     0.743575   \n",
       "18    0.565191  0.652790  0.763957  0.735150    0.705082     0.752472   \n",
       "19    0.553641  0.647958  0.763257  0.734924    0.699711     0.726397   \n",
       "20    0.558599  0.650470  0.761594  0.734239    0.708172     0.746870   \n",
       "21    0.588836  0.658395  0.760702  0.729704    0.708927     0.768773   \n",
       "22    0.566098  0.654318  0.764163  0.736818    0.702172     0.737066   \n",
       "23    0.563558  0.651291  0.763478  0.736814    0.701885     0.745056   \n",
       "24    0.571178  0.653068  0.761648  0.732011    0.698633     0.726136   \n",
       "25    0.563316  0.650171  0.760910  0.732678    0.705837     0.758677   \n",
       "26    0.555576  0.646539  0.764323  0.732480    0.701867     0.733992   \n",
       "27    0.604257  0.662599  0.761503  0.728309    0.697806     0.722740   \n",
       "28    0.564344  0.650608  0.762198  0.737233    0.701292     0.751989   \n",
       "29    0.567610  0.652531  0.760828  0.736136    0.697860     0.720898   \n",
       "\n",
       "    f_recall      f_f1     f_auc     f_prc  cp_accuracy  cp_precision  \\\n",
       "0   0.801758  0.755396  0.768299  0.821994     0.725855      0.801653   \n",
       "1   0.766262  0.751972  0.771118  0.826157     0.722802      0.779945   \n",
       "2   0.782341  0.752807  0.768515  0.823853     0.725409      0.780917   \n",
       "3   0.782035  0.754079  0.770336  0.826211     0.724610      0.781218   \n",
       "4   0.776706  0.753435  0.769457  0.822951     0.724516      0.802140   \n",
       "5   0.726479  0.743384  0.770469  0.824277     0.723271      0.798064   \n",
       "6   0.780473  0.735384  0.753503  0.814659     0.724399      0.811945   \n",
       "7   0.759372  0.750295  0.770899  0.825237     0.722966      0.792173   \n",
       "8   0.817102  0.756000  0.765808  0.821531     0.723929      0.826690   \n",
       "9   0.745437  0.746878  0.770412  0.823441     0.721134      0.765376   \n",
       "10  0.776001  0.753703  0.764784  0.819549     0.721839      0.800454   \n",
       "11  0.763537  0.751318  0.765756  0.820250     0.723741      0.765750   \n",
       "12  0.747826  0.750457  0.768605  0.824946     0.724728      0.779168   \n",
       "13  0.728776  0.744358  0.770106  0.824653     0.725385      0.801059   \n",
       "14  0.764210  0.749790  0.768216  0.821762     0.723083      0.794956   \n",
       "15  0.756554  0.751342  0.772002  0.825509     0.725338      0.788273   \n",
       "16  0.764854  0.751166  0.768228  0.822625     0.723553      0.784596   \n",
       "17  0.752297  0.747911  0.769559  0.823599     0.724070      0.793143   \n",
       "18  0.740996  0.746690  0.769934  0.824770     0.723553      0.797399   \n",
       "19  0.783015  0.753644  0.768162  0.822637     0.725620      0.784021   \n",
       "20  0.760137  0.753445  0.772625  0.826058     0.722614      0.780358   \n",
       "21  0.720507  0.743858  0.771726  0.825578     0.722355      0.819033   \n",
       "22  0.765282  0.750909  0.769265  0.823759     0.723412      0.776583   \n",
       "23  0.747611  0.746331  0.769451  0.824468     0.723154      0.777044   \n",
       "24  0.780687  0.752424  0.769412  0.824441     0.723412      0.782573   \n",
       "25  0.731073  0.744619  0.769905  0.822253     0.727969      0.794366   \n",
       "26  0.771285  0.752177  0.769921  0.824864     0.721064      0.799395   \n",
       "27  0.786598  0.753318  0.767148  0.820919     0.716249      0.744313   \n",
       "28  0.732298  0.742013  0.766046  0.817916     0.721886      0.789137   \n",
       "29  0.791284  0.754453  0.768764  0.824103     0.721886      0.788810   \n",
       "\n",
       "    cp_recall     cp_f1    cp_auc    cp_prc  c_accuracy  c_precision  \\\n",
       "0    0.735198  0.766989  0.789669  0.853608    0.757221     0.733034   \n",
       "1    0.763826  0.771801  0.789207  0.854373    0.758953     0.765709   \n",
       "2    0.768036  0.774423  0.791711  0.855099    0.754196     0.766240   \n",
       "3    0.765701  0.773382  0.791062  0.856318    0.756644     0.765666   \n",
       "4    0.731563  0.765227  0.791149  0.857940    0.758883     0.761581   \n",
       "5    0.735084  0.765280  0.788811  0.853276    0.759553     0.761062   \n",
       "6    0.716981  0.761514  0.787588  0.854616    0.757937     0.762779   \n",
       "7    0.743695  0.767169  0.788512  0.851722    0.755605     0.758802   \n",
       "8    0.696085  0.755786  0.789825  0.854623    0.757383     0.767017   \n",
       "9    0.786789  0.775935  0.786776  0.852319    0.756690     0.750932   \n",
       "10   0.728310  0.762680  0.787241  0.851336    0.757267     0.747169   \n",
       "11   0.792185  0.778743  0.791355  0.854927    0.758676     0.759583   \n",
       "12   0.769566  0.774338  0.788904  0.850415    0.760084     0.765190   \n",
       "13   0.735084  0.766655  0.789088  0.852960    0.758583     0.757734   \n",
       "14   0.739523  0.766238  0.788252  0.856713    0.759207     0.760241   \n",
       "15   0.755329  0.771450  0.790069  0.853963    0.758768     0.751830   \n",
       "16   0.757511  0.770815  0.786035  0.851843    0.756020     0.741962   \n",
       "17   0.744575  0.768092  0.788025  0.851070    0.756852     0.743886   \n",
       "18   0.736729  0.765864  0.789891  0.855940    0.756759     0.746920   \n",
       "19   0.763137  0.773438  0.790427  0.854827    0.758237     0.753628   \n",
       "20   0.762677  0.771416  0.786919  0.853139    0.758121     0.774723   \n",
       "21   0.702897  0.756534  0.789448  0.851399    0.760292     0.754700   \n",
       "22   0.771174  0.773869  0.789221  0.855649    0.757106     0.747697   \n",
       "23   0.769758  0.773384  0.784057  0.845541    0.756344     0.734980   \n",
       "24   0.760649  0.771455  0.787784  0.851023    0.753850     0.728726   \n",
       "25   0.751196  0.772178  0.789187  0.851497    0.759784     0.771217   \n",
       "26   0.728233  0.762157  0.783045  0.848232    0.756367     0.745195   \n",
       "27   0.818975  0.779861  0.787500  0.849417    0.757798     0.747024   \n",
       "28   0.746221  0.767079  0.789481  0.854688    0.758976     0.744754   \n",
       "29   0.746756  0.767207  0.788975  0.856360    0.757521     0.763353   \n",
       "\n",
       "    c_recall      c_f1     c_auc     c_prc  a_accuracy  a_precision  a_recall  \\\n",
       "0   0.636919  0.681605  0.800321  0.738993    0.838238     0.668394  0.192633   \n",
       "1   0.589610  0.666219  0.799139  0.742328    0.842964     0.680758  0.232454   \n",
       "2   0.572067  0.655067  0.792440  0.738661    0.837346     0.633478  0.218517   \n",
       "3   0.581518  0.661006  0.795701  0.737423    0.832085     0.649289  0.136386   \n",
       "4   0.595439  0.668339  0.795673  0.741317    0.830212     0.623529  0.131906   \n",
       "5   0.598608  0.670130  0.797157  0.736921    0.832174     0.648712  0.137880   \n",
       "6   0.590289  0.665539  0.796941  0.742300    0.839576     0.670455  0.205575   \n",
       "7   0.587856  0.662479  0.797550  0.740648    0.833155     0.638554  0.158288   \n",
       "8   0.582197  0.661948  0.796065  0.734826    0.842162     0.690590  0.215530   \n",
       "9   0.603984  0.669489  0.798389  0.737658    0.829945     0.588235  0.169238   \n",
       "10  0.612246  0.673012  0.798502  0.742321    0.840913     0.641509  0.253858   \n",
       "11  0.597702  0.668989  0.801302  0.744136    0.845372     0.660070  0.282230   \n",
       "12  0.594364  0.669045  0.798076  0.739817    0.837525     0.633001  0.221503   \n",
       "13  0.600192  0.669824  0.799880  0.742206    0.834671     0.619414  0.200100   \n",
       "14  0.598608  0.669812  0.800161  0.744004    0.839754     0.644809  0.234943   \n",
       "15  0.610152  0.673622  0.799266  0.736607    0.834047     0.603352  0.215032   \n",
       "16  0.616377  0.673364  0.793855  0.735556    0.837435     0.641768  0.209557   \n",
       "17  0.616207  0.674054  0.797826  0.740073    0.826734     0.585492  0.112494   \n",
       "18  0.610775  0.672021  0.795835  0.734546    0.838060     0.643815  0.215032   \n",
       "19  0.605342  0.671395  0.796474  0.738633    0.834047     0.604520  0.213041   \n",
       "20  0.574104  0.659494  0.799513  0.743339    0.834136     0.625632  0.184669   \n",
       "21  0.611114  0.675360  0.800420  0.740190    0.837257     0.636095  0.214037   \n",
       "22  0.610775  0.672335  0.798636  0.739903    0.833244     0.613377  0.187158   \n",
       "23  0.629959  0.678429  0.796500  0.734808    0.832263     0.611888  0.174216   \n",
       "24  0.631939  0.676890  0.796518  0.740624    0.831639     0.637813  0.139373   \n",
       "25  0.584687  0.665122  0.801158  0.743272    0.836454     0.671233  0.170732   \n",
       "26  0.612189  0.672176  0.795352  0.731178    0.836811     0.669187  0.176207   \n",
       "27  0.614453  0.674284  0.796516  0.742561    0.841627     0.662031  0.236934   \n",
       "28  0.622659  0.678256  0.798056  0.743540    0.842875     0.649697  0.266799   \n",
       "29  0.587969  0.664280  0.797168  0.740944    0.836454     0.640902  0.198109   \n",
       "\n",
       "        a_f1     a_auc     a_prc  ag_accuracy  ag_precision  ag_recall  \\\n",
       "0   0.299073  0.634375  0.375421     0.727695      0.719218   0.487455   \n",
       "1   0.346568  0.666707  0.387560     0.723089      0.688836   0.520290   \n",
       "2   0.324944  0.652311  0.356423     0.726998      0.703709   0.510145   \n",
       "3   0.225422  0.683122  0.394668     0.728055      0.714532   0.496400   \n",
       "4   0.217749  0.668035  0.368827     0.727801      0.710362   0.502182   \n",
       "5   0.227422  0.690662  0.384192     0.728160      0.714040   0.497655   \n",
       "6   0.314667  0.670594  0.384964     0.726047      0.706570   0.500927   \n",
       "7   0.253690  0.672520  0.379256     0.725075      0.689305   0.528690   \n",
       "8   0.328528  0.661581  0.388873     0.722434      0.686197   0.522526   \n",
       "9   0.262853  0.677786  0.368462     0.726639      0.703729   0.508509   \n",
       "10  0.363766  0.661131  0.382044     0.727907      0.712208   0.499564   \n",
       "11  0.395397  0.657136  0.384524     0.724843      0.699632   0.507800   \n",
       "12  0.328171  0.701829  0.395069     0.724420      0.702626   0.500545   \n",
       "13  0.302483  0.669173  0.368005     0.721567      0.687318   0.516145   \n",
       "14  0.344400  0.658802  0.376387     0.724547      0.697209   0.510909   \n",
       "15  0.317064  0.657886  0.348134     0.724230      0.694150   0.515218   \n",
       "16  0.315947  0.674424  0.375045     0.723194      0.694972   0.508891   \n",
       "17  0.188727  0.674392  0.361391     0.725963      0.715156   0.486419   \n",
       "18  0.322388  0.649293  0.365778     0.725624      0.694659   0.520672   \n",
       "19  0.315053  0.652121  0.361519     0.726829      0.701528   0.513309   \n",
       "20  0.285165  0.683568  0.384783     0.718778      0.668116   0.544726   \n",
       "21  0.320298  0.671547  0.376606     0.725582      0.700450   0.509654   \n",
       "22  0.286804  0.678857  0.371743     0.723849      0.707519   0.489637   \n",
       "23  0.271213  0.666691  0.361607     0.720447      0.680580   0.524708   \n",
       "24  0.228758  0.665852  0.375989     0.723786      0.694854   0.511836   \n",
       "25  0.272222  0.647433  0.370908     0.726322      0.711513   0.493837   \n",
       "26  0.278960  0.663316  0.393596     0.717129      0.664999   0.543853   \n",
       "27  0.348974  0.621786  0.350799     0.724695      0.693367   0.518872   \n",
       "28  0.378264  0.685676  0.397624     0.726702      0.709552   0.498746   \n",
       "29  0.302662  0.654635  0.372474     0.725603      0.697162   0.515818   \n",
       "\n",
       "       ag_f1    ag_auc    ag_prc  g_accuracy  g_precision  g_recall      g_f1  \\\n",
       "0   0.581079  0.723755  0.641046    0.893874     0.715818  0.408361  0.520045   \n",
       "1   0.592816  0.725792  0.633825    0.885655     0.725382  0.302320  0.426772   \n",
       "2   0.591494  0.716615  0.636417    0.896099     0.707258  0.447107  0.547868   \n",
       "3   0.585820  0.729389  0.640742    0.888131     0.735673  0.320673  0.446654   \n",
       "4   0.588401  0.728742  0.641627    0.885619     0.718268  0.308692  0.431806   \n",
       "5   0.586526  0.729046  0.642184    0.893156     0.737688  0.374203  0.496533   \n",
       "6   0.586238  0.724761  0.635758    0.884722     0.701416  0.315575  0.435302   \n",
       "7   0.598407  0.732579  0.646612    0.888993     0.709384  0.358399  0.476207   \n",
       "8   0.593281  0.726169  0.637051    0.894376     0.701646  0.434616  0.536754   \n",
       "9   0.590400  0.726452  0.638917    0.894340     0.717459  0.411675  0.523162   \n",
       "10  0.587228  0.728175  0.645727    0.884937     0.709527  0.309457  0.430955   \n",
       "11  0.588477  0.728114  0.641855    0.895883     0.717262  0.430028  0.537689   \n",
       "12  0.584615  0.728032  0.639963    0.888777     0.728381  0.334948  0.458879   \n",
       "13  0.589558  0.725221  0.643619    0.885260     0.733591  0.290594  0.416286   \n",
       "14  0.589694  0.723831  0.634116    0.889100     0.708563  0.360693  0.478041   \n",
       "15  0.591447  0.726343  0.641917    0.896171     0.711586  0.441499  0.544911   \n",
       "16  0.587550  0.714588  0.634266    0.886229     0.710924  0.323477  0.444639   \n",
       "17  0.579016  0.727222  0.639543    0.890464     0.707678  0.378282  0.493023   \n",
       "18  0.595211  0.726719  0.639131    0.895130     0.723937  0.412439  0.525495   \n",
       "19  0.592838  0.725385  0.641270    0.891684     0.725911  0.370635  0.490719   \n",
       "20  0.600144  0.729366  0.640931    0.893048     0.714416  0.400459  0.513231   \n",
       "21  0.590011  0.725394  0.638063    0.894232     0.711255  0.418812  0.527194   \n",
       "22  0.578751  0.721789  0.628332    0.894412     0.709168  0.423910  0.530632   \n",
       "23  0.592565  0.723221  0.636695    0.888167     0.710485  0.347183  0.466438   \n",
       "24  0.589466  0.727110  0.640548    0.894376     0.725806  0.401478  0.516987   \n",
       "25  0.583019  0.725150  0.640177    0.891110     0.680178  0.427734  0.525196   \n",
       "26  0.598356  0.727150  0.637165    0.890679     0.721577  0.364007  0.483904   \n",
       "27  0.593561  0.728905  0.642344    0.894412     0.729313  0.397655  0.514682   \n",
       "28  0.585760  0.723791  0.637387    0.880415     0.735834  0.235024  0.356260   \n",
       "29  0.592934  0.729719  0.643113    0.894627     0.731581  0.397400  0.515031   \n",
       "\n",
       "       g_auc     g_prc  \n",
       "0   0.789589  0.498379  \n",
       "1   0.800713  0.514411  \n",
       "2   0.790840  0.504006  \n",
       "3   0.801806  0.520040  \n",
       "4   0.784160  0.489967  \n",
       "5   0.798591  0.513350  \n",
       "6   0.794709  0.489400  \n",
       "7   0.796082  0.490775  \n",
       "8   0.790194  0.500981  \n",
       "9   0.795693  0.511690  \n",
       "10  0.796375  0.491784  \n",
       "11  0.795656  0.508160  \n",
       "12  0.802961  0.509639  \n",
       "13  0.797918  0.507762  \n",
       "14  0.797425  0.493072  \n",
       "15  0.804700  0.516927  \n",
       "16  0.790178  0.496813  \n",
       "17  0.804738  0.498061  \n",
       "18  0.786691  0.500161  \n",
       "19  0.800041  0.503606  \n",
       "20  0.796573  0.492916  \n",
       "21  0.801888  0.502271  \n",
       "22  0.802770  0.514646  \n",
       "23  0.774073  0.487006  \n",
       "24  0.799259  0.510058  \n",
       "25  0.801187  0.491945  \n",
       "26  0.785937  0.494083  \n",
       "27  0.794877  0.506897  \n",
       "28  0.798764  0.506971  \n",
       "29  0.794317  0.513565  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_external_result_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6943fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_result_df.to_csv('model internal test performance file save path')\n",
    "performance_external_result_df1.to_csv('model external test performance file save path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5fbde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-cuda",
   "language": "python",
   "name": "tensorflow-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
