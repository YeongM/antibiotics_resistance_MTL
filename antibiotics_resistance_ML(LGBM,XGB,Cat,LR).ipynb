{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1776d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, mean_squared_error, accuracy_score, mean_absolute_error, precision_score, recall_score, f1_score\n",
    "from pickle import dump\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2731062",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital1 = 'Anam_hospital'\n",
    "hospital2 = 'Guro_hospital'\n",
    "hospital3 = 'Ansan_hospital'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e688db4",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93145296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_del(X, y):\n",
    "    na_index = np.where(np.isnan(y))[0]\n",
    "    del_na_X = np.delete(X, na_index,axis=0)\n",
    "    del_na_y = np.delete(y, na_index)\n",
    "    \n",
    "    return del_na_X, del_na_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "307ccbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performacne_model(Real_Test_y, y_pred, y_pred_prob):\n",
    "    accuracy= accuracy_score(Real_Test_y, y_pred)\n",
    "    precision = precision_score(Real_Test_y, y_pred)\n",
    "    recall = recall_score(Real_Test_y, y_pred)\n",
    "    f1 = f1_score(Real_Test_y, y_pred)\n",
    "    auc = roc_auc_score(Real_Test_y, y_pred_prob)\n",
    "    prc = average_precision_score(Real_Test_y, y_pred_prob)\n",
    "    confusion = confusion_matrix(Real_Test_y, y_pred)\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, auc, prc, confusion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9cb623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGBM_tuning_predict(Train_X_sc_MI, Train_y, Real_Test_X_sc, Real_Test_y, External_Test_X1, External_Test_y1):\n",
    "    test_auc_list = []\n",
    "\n",
    "    pram = {\"max_depth\":[15,20,25,30],\n",
    "                 \"n_estimators\": [100,200,300]}\n",
    "    \n",
    "    LGBM_model = LGBMClassifier(force_col_wise=True,verbose=-1)\n",
    "    \n",
    "    gscv = GridSearchCV(estimator=LGBM_model, param_grid=pram, scoring='roc_auc', cv=5, verbose=2)\n",
    "    \n",
    "    gscv.fit(Train_X_sc_MI, Train_y)\n",
    "    \n",
    "    external_y_pred1 = gscv.predict(External_Test_X1)\n",
    "    external_y_pred_prob1 = gscv.predict_proba(External_Test_X1)[:, 1]\n",
    "    external_performance = performacne_model(External_Test_y1, external_y_pred1, external_y_pred_prob1)\n",
    "    \n",
    "    return performance, external_performance1, gscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "113eb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cat_tuning_predict(Train_X_sc_MI, Train_y, Real_Test_X_sc, Real_Test_y, External_Test_X1, External_Test_y1):\n",
    "    test_auc_list = []\n",
    "\n",
    "    pram = {\"max_depth\":[6,8,10,12],\n",
    "                 \"n_estimators\": [100,200,300]}\n",
    "    \n",
    "    Cat_model = CatBoostClassifier(verbose=False)\n",
    "    \n",
    "    gscv = GridSearchCV(estimator=Cat_model, param_grid=pram, scoring='roc_auc', cv=5, verbose=2)\n",
    "    \n",
    "    gscv.fit(Train_X_sc_MI, Train_y)\n",
    "    \n",
    "    external_y_pred1 = gscv.predict(External_Test_X1)\n",
    "    external_y_pred_prob1 = gscv.predict_proba(External_Test_X1)[:, 1]\n",
    "    external_performance = performacne_model(External_Test_y1, external_y_pred1, external_y_pred_prob1)\n",
    "    \n",
    "    return performance, external_performance1, gscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28ac179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_tuning_predict(Train_X_sc_MI, Train_y, Real_Test_X_sc, Real_Test_y, External_Test_X1, External_Test_y1):\n",
    "    test_auc_list = []\n",
    "\n",
    "    pram = {\"max_depth\":[15,20,25,30],\n",
    "                 \"n_estimators\": [100,200,300]}\n",
    "    \n",
    "    XGB = XGBClassifier()\n",
    "    \n",
    "    gscv = GridSearchCV(estimator=XGB, param_grid=pram, scoring='roc_auc', cv=5, verbose=2)\n",
    "    \n",
    "    gscv.fit(Train_X_sc_MI, Train_y)\n",
    "    \n",
    "    y_pred = gscv.predict(Real_Test_X_sc)\n",
    "    y_pred_prob = gscv.predict_proba(Real_Test_X_sc)[:, 1]\n",
    "    performance = performacne_model(Real_Test_y, y_pred, y_pred_prob)\n",
    "    \n",
    "    external_y_pred1 = gscv.predict(External_Test_X1)\n",
    "    external_y_pred_prob1 = gscv.predict_proba(External_Test_X1)[:, 1]\n",
    "    external_performance = performacne_model(External_Test_y1, external_y_pred1, external_y_pred_prob1)\n",
    "    \n",
    "    return performance, external_performance1, gscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64ab23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_tuning_predict(Train_X_sc_MI, Train_y, Real_Test_X_sc, Real_Test_y, External_Test_X1, External_Test_y1):\n",
    "    test_auc_list = []\n",
    "\n",
    "    pram = {\"C\":[0.5, 1.0, 2, 3],\n",
    "                 \"max_iter\": [50,100,200,300]}\n",
    "    \n",
    "    LR = LogisticRegression()\n",
    "    \n",
    "    gscv = GridSearchCV(estimator=LR, param_grid=pram, scoring='roc_auc', cv=5, verbose=2)\n",
    "    \n",
    "    gscv.fit(Train_X_sc_MI, Train_y)\n",
    "    \n",
    "    y_pred = gscv.predict(Real_Test_X_sc)\n",
    "    y_pred_prob = gscv.predict_proba(Real_Test_X_sc)[:, 1]\n",
    "    performance = performacne_model(Real_Test_y, y_pred, y_pred_prob)\n",
    "    \n",
    "    external_y_pred1 = gscv.predict(External_Test_X1)\n",
    "    external_y_pred_prob1 = gscv.predict_proba(External_Test_X1)[:, 1]\n",
    "    external_performance = performacne_model(External_Test_y1, external_y_pred1, external_y_pred_prob1)\n",
    "    \n",
    "    return performance, external_performance1, gscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "027c8af9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END .....................max_depth=15, n_estimators=100; total time=   0.5s\n",
      "[CV] END .....................max_depth=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END .....................max_depth=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END .....................max_depth=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END .....................max_depth=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END .....................max_depth=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END .....................max_depth=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END .....................max_depth=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END .....................max_depth=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END .....................max_depth=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END .....................max_depth=15, n_estimators=300; total time=   0.7s\n",
      "[CV] END .....................max_depth=15, n_estimators=300; total time=   0.8s\n",
      "[CV] END .....................max_depth=15, n_estimators=300; total time=   0.8s\n",
      "[CV] END .....................max_depth=15, n_estimators=300; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "external_count=0\n",
    "target_name = ['tgc','m','fgc','f','cp','c','a','ag','ã…Ž']\n",
    "perform = ['accuracy','precision','recall','f1','auc','prc']\n",
    "target_list =['train_length','valid_length','test_length']\n",
    "for t in target_name:\n",
    "    for p in perform:\n",
    "        target_list.append(f'{t}_{p}')\n",
    "performance_result_df = pd.DataFrame(columns=target_list)\n",
    "performance_external_result_df1 = pd.DataFrame(columns=target_list)\n",
    "\n",
    "for seed in range(30):\n",
    "    Train_X_MI = np.load('Preprocessed training data X in .npy format')\n",
    "    Train_y = np.load('Preprocessed training data y in .npy format')\n",
    "    Test_X_MI= np.load('Preprocessed internal test data X in .npy format')\n",
    "    Test_y = np.load('Preprocessed internal test data y in .npy format')\n",
    "    external_test_X1 = np.load('Preprocessed external test data X in .npy format')\n",
    "    external_test_y1 = np.load('Preprocessed external test data y in .npy format')\n",
    "    \n",
    "    tgc_train_y = Train_y[:,0]\n",
    "    m_train_y = Train_y[:,1]\n",
    "    fgc_train_y = Train_y[:,2]\n",
    "    f_train_y = Train_y[:,3]\n",
    "    cp_train_y = Train_y[:,4]\n",
    "    c_train_y = Train_y[:,5]\n",
    "    a_train_y = Train_y[:,6]\n",
    "    ag_train_y = Train_y[:,7]\n",
    "    g_train_y = Train_y[:,8]\n",
    "\n",
    "    tgc_test_y = Test_y[:,0]\n",
    "    m_test_y = Test_y[:,1]\n",
    "    fgc_test_y = Test_y[:,2]\n",
    "    f_test_y = Test_y[:,3]\n",
    "    cp_test_y = Test_y[:,4]\n",
    "    c_test_y = Test_y[:,5]\n",
    "    a_test_y = Test_y[:,6]\n",
    "    ag_test_y = Test_y[:,7]\n",
    "    g_test_y = Test_y[:,8]\n",
    "\n",
    "    external_tgc_test_y1 = external_test_y1[:,0]\n",
    "    external_m_test_y1 = external_test_y1[:,1]\n",
    "    external_fgc_test_y1 = external_test_y1[:,2]\n",
    "    external_f_test_y1 = external_test_y1[:,3]\n",
    "    external_cp_test_y1 = external_test_y1[:,4]\n",
    "    external_c_test_y1 = external_test_y1[:,5]\n",
    "    external_a_test_y1 = external_test_y1[:,6]\n",
    "    external_ag_test_y1 = external_test_y1[:,7]\n",
    "    external_g_test_y1 = external_test_y1[:,8]\n",
    "\n",
    "    train_y_list = [tgc_train_y,m_train_y,fgc_train_y,f_train_y,cp_train_y,c_train_y,a_train_y,ag_train_y,g_train_y]\n",
    "    test_y_list = [tgc_test_y,m_test_y,fgc_test_y,f_test_y,cp_test_y,c_test_y,a_test_y,ag_test_y,g_test_y]\n",
    "    external_test_y1_list = [external_tgc_test_y1,external_m_test_y1,external_fgc_test_y1,external_f_test_y1,external_cp_test_y1,external_c_test_y1,external_a_test_y1,external_ag_test_y1,external_g_test_y1]\n",
    "\n",
    "    Train_index, Val_index = train_test_split(range(len(Train_X_MI)), test_size=0.3, random_state=seed)\n",
    "    X_val = Train_X_MI[Val_index]\n",
    "    Y_val_tgc = train_y_list[0][Val_index]\n",
    "    Y_val_m = train_y_list[1][Val_index]\n",
    "    Y_val_fgc = train_y_list[2][Val_index]\n",
    "    Y_val_f = train_y_list[3][Val_index]\n",
    "    Y_val_cp = train_y_list[4][Val_index]\n",
    "    Y_val_c = train_y_list[5][Val_index]\n",
    "    Y_val_a = train_y_list[6][Val_index]\n",
    "    Y_val_ag = train_y_list[7][Val_index]\n",
    "    Y_val_g = train_y_list[8][Val_index]\n",
    "\n",
    "\n",
    "    X_train = Train_X_MI[Train_index]\n",
    "    Y_train_tgc = train_y_list[0][Train_index]\n",
    "    Y_train_m = train_y_list[1][Train_index]\n",
    "    Y_train_fgc = train_y_list[2][Train_index]\n",
    "    Y_train_f = train_y_list[3][Train_index]\n",
    "    Y_train_cp = train_y_list[4][Train_index]\n",
    "    Y_train_c = train_y_list[5][Train_index]\n",
    "    Y_train_a = train_y_list[6][Train_index]\n",
    "    Y_train_ag = train_y_list[7][Train_index]\n",
    "    Y_train_g = train_y_list[8][Train_index]\n",
    "\n",
    "    X_test = Test_X_MI\n",
    "    Y_test_tgc = test_y_list[0]\n",
    "    Y_test_m = test_y_list[1]\n",
    "    Y_test_fgc = test_y_list[2]\n",
    "    Y_test_f = test_y_list[3]\n",
    "    Y_test_cp = test_y_list[4]\n",
    "    Y_test_c = test_y_list[5]\n",
    "    Y_test_a = test_y_list[6]\n",
    "    Y_test_ag = test_y_list[7]\n",
    "    Y_test_g = test_y_list[8]\n",
    "\n",
    "    Y_test_tgc = test_y_list[0]\n",
    "    Y_test_m = test_y_list[1]\n",
    "    Y_test_fgc = test_y_list[2]\n",
    "    Y_test_f = test_y_list[3]\n",
    "    Y_test_cp = test_y_list[4]\n",
    "    Y_test_c = test_y_list[5]\n",
    "    Y_test_a = test_y_list[6]\n",
    "    Y_test_ag = test_y_list[7]\n",
    "    Y_test_g = test_y_list[8]\n",
    "\n",
    "    external_Y_test1_tgc = external_test_y1_list[0]\n",
    "    external_Y_test1_m = external_test_y1_list[1]\n",
    "    external_Y_test1_fgc = external_test_y1_list[2]\n",
    "    external_Y_test1_f = external_test_y1_list[3]\n",
    "    external_Y_test1_cp = external_test_y1_list[4]\n",
    "    external_Y_test1_c = external_test_y1_list[5]\n",
    "    external_Y_test1_a = external_test_y1_list[6]\n",
    "    external_Y_test1_ag = external_test_y1_list[7]\n",
    "    external_Y_test1_g = external_test_y1_list[8]\n",
    "\n",
    "    feature_size = X_train.shape[1]\n",
    "\n",
    "    Y_train =[Y_train_tgc,Y_train_m,Y_train_fgc,Y_train_f,Y_train_cp,Y_train_c,Y_train_a,Y_train_ag,Y_train_g]\n",
    "    Y_val =[Y_val_tgc,Y_val_m,Y_val_fgc,Y_val_f,Y_val_cp,Y_val_c,Y_val_a,Y_val_ag,Y_val_g]\n",
    "    Y_test =[Y_test_tgc,Y_test_m,Y_test_fgc,Y_test_f,Y_test_cp,Y_test_c,Y_test_a,Y_test_ag,Y_test_g]\n",
    "    external_Y_test1 =[external_Y_test1_tgc,external_Y_test1_m,external_Y_test1_fgc,external_Y_test1_f,external_Y_test1_cp,external_Y_test1_c,external_Y_test1_a,external_Y_test1_ag,external_Y_test1_g]\n",
    "\n",
    "    performance_result_df.loc[count,'train_length'] = len(X_train)\n",
    "    performance_result_df.loc[count,'valid_length'] = len(X_val)\n",
    "    performance_result_df.loc[count,'test_length'] = len(X_test)\n",
    "\n",
    "    tmp_train_X = []\n",
    "    tmp_val_X = []\n",
    "    tmp_test_X = []\n",
    "    tmp_external_X1 = []\n",
    "    tmp_train_y = []\n",
    "    tmp_val_y = []\n",
    "    tmp_test_y = []\n",
    "    tmp_external_y1 = []\n",
    "\n",
    "    for i,(train, val, test, external_test1) in enumerate(zip(Y_train, Y_val, Y_test, external_Y_test1)):\n",
    "        tmp_X, tmp_y = nan_del(X_train, train)\n",
    "        tmp_train_X.append(tmp_X)\n",
    "        tmp_train_y.append(tmp_y)\n",
    "\n",
    "        tmp_X, tmp_y = nan_del(X_val, val)\n",
    "        tmp_val_X.append(tmp_X)\n",
    "        tmp_val_y.append(tmp_y)\n",
    "\n",
    "        tmp_X, tmp_y = nan_del(X_test, test)\n",
    "        tmp_test_X.append(tmp_X)\n",
    "        tmp_test_y.append(tmp_y)\n",
    "\n",
    "        tmp_X, tmp_y = nan_del(external_test_X1, external_test1)\n",
    "        tmp_external_X1.append(tmp_X)\n",
    "        tmp_external_y1.append(tmp_y)\n",
    "    \n",
    "    for i in range(len(target_name)):\n",
    "        tmp_val_train_X = np.concatenate([tmp_train_X[i], tmp_val_X[i]],axis=0)\n",
    "        tmp_val_train_y = np.concatenate([tmp_train_y[i], tmp_val_y[i]])\n",
    "\n",
    "        # LGBM\n",
    "        internal_performance, external_performance1, model_info = LGBM_tuning_predict(tmp_val_train_X, tmp_val_train_y, tmp_test_X[i], tmp_test_y[i], tmp_external_X1[i], tmp_external_y1[i])\n",
    "        filename = 'Model save path in .pkl format'\n",
    "        dump(model_info, open(filename, 'wb'))\n",
    "        for j, performance_name in enumerate(perform):\n",
    "            target_feature = target_name[i]+'_'+performance_name\n",
    "            performance_result_df.loc[count, target_feature] = internal_performance[j]\n",
    "            performance_external_result_df1.loc[count, target_feature] = external_performance1[j]\n",
    "\n",
    "        # CatBoost\n",
    "        internal_performance, external_performance1, model_info = Cat_tuning_predict(tmp_val_train_X, tmp_val_train_y, tmp_test_X[i], tmp_test_y[i], tmp_external_X1[i], tmp_external_y1[i])\n",
    "        filename = 'Model save path in .pkl format'\n",
    "        dump(model_info, open(filename, 'wb'))\n",
    "        for j, performance_name in enumerate(perform):\n",
    "            target_feature = target_name[i]+'_'+performance_name\n",
    "            performance_result_df.loc[count+1, target_feature] = internal_performance[j]\n",
    "            performance_external_result_df1.loc[count, target_feature] = external_performance1[j]\n",
    "\n",
    "        # XGB\n",
    "        internal_performance, external_performance1, model_info = XGB_tuning_predict(tmp_val_train_X, tmp_val_train_y, tmp_test_X[i], tmp_test_y[i], tmp_external_X1[i], tmp_external_y1[i])\n",
    "        filename = 'Model save path in .pkl format'\n",
    "        dump(model_info, open(filename, 'wb'))\n",
    "        for j, performance_name in enumerate(perform):\n",
    "            target_feature = target_name[i]+'_'+performance_name\n",
    "            performance_result_df.loc[count+2, target_feature] = internal_performance[j]\n",
    "            performance_external_result_df1.loc[count, target_feature] = external_performance1[j]\n",
    "\n",
    "        # LR\n",
    "        internal_performance, external_performance1, model_info = LR_tuning_predict(tmp_val_train_X, tmp_val_train_y, tmp_test_X[i], tmp_test_y[i], tmp_external_X1[i], tmp_external_y1[i])\n",
    "        filename = 'Model save path in .pkl format'\n",
    "        dump(model_info, open(filename, 'wb'))\n",
    "        for j, performance_name in enumerate(perform):\n",
    "            target_feature = target_name[i]+'_'+performance_name\n",
    "            performance_result_df.loc[count+3, target_feature] = internal_performance[j]\n",
    "            performance_external_result_df1.loc[count, target_feature] = external_performance1[j]\n",
    "    count+=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_result_df.to_csv('model internal test performance file save path')\n",
    "performance_external_result_df1.to_csv('model external test performance file save path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f818dc68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-cuda",
   "language": "python",
   "name": "tensorflow-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
